From e92a3465571b4f1215b1ba00c669f90dc78fd102 Mon Sep 17 00:00:00 2001
From: link <link@inventec.com>
Date: Tue, 25 Oct 2022 03:22:31 +0000
Subject: [PATCH] Kernel-sync - [Intel-BMC] branch dev-5.15-intel peci drivers

Symptom/Reason:
    Sync codebase with Intel-BMC/linux 7c1de25c06f31b04744beae891baf147af9ba0cb

Root Cause:
    N/A

Solution/Change:
    hwmon drivers
        - peci-cpupower
        - peci-cputemp
        - peci-dimmpower
        - peci-dimmtemp

    mfd driver
        - intel-peci-client

    peci
        - peci-aspeed
        - peci-mctp
        - peci-npcm

Entry Test:
    N/A
---
 drivers/Kconfig                       |    2 +
 drivers/Makefile                      |    1 +
 drivers/hwmon/Kconfig                 |   56 +
 drivers/hwmon/Makefile                |    4 +
 drivers/hwmon/peci-cpupower.c         |  754 +++++++++
 drivers/hwmon/peci-cputemp.c          |  550 +++++++
 drivers/hwmon/peci-dimmpower.c        |  673 ++++++++
 drivers/hwmon/peci-dimmtemp.c         |  554 +++++++
 drivers/hwmon/peci-hwmon.h            |  659 ++++++++
 drivers/mfd/Kconfig                   |   17 +
 drivers/mfd/Makefile                  |    1 +
 drivers/mfd/intel-peci-client.c       |  166 ++
 drivers/peci/Kconfig                  |   37 +
 drivers/peci/Makefile                 |   11 +
 drivers/peci/busses/Kconfig           |   60 +
 drivers/peci/busses/Makefile          |    9 +
 drivers/peci/busses/peci-aspeed.c     |  522 ++++++
 drivers/peci/busses/peci-mctp.c       |  450 +++++
 drivers/peci/busses/peci-npcm.c       |  406 +++++
 drivers/peci/peci-core.c              | 2194 +++++++++++++++++++++++++
 drivers/peci/peci-dev.c               |  359 ++++
 include/linux/mfd/intel-peci-client.h |  163 ++
 include/linux/peci.h                  |  153 ++
 include/uapi/linux/peci-ioctl.h       |  703 ++++++++
 24 files changed, 8504 insertions(+)
 create mode 100644 drivers/hwmon/peci-cpupower.c
 create mode 100644 drivers/hwmon/peci-cputemp.c
 create mode 100644 drivers/hwmon/peci-dimmpower.c
 create mode 100644 drivers/hwmon/peci-dimmtemp.c
 create mode 100644 drivers/hwmon/peci-hwmon.h
 create mode 100644 drivers/mfd/intel-peci-client.c
 create mode 100644 drivers/peci/Kconfig
 create mode 100644 drivers/peci/Makefile
 create mode 100644 drivers/peci/busses/Kconfig
 create mode 100644 drivers/peci/busses/Makefile
 create mode 100644 drivers/peci/busses/peci-aspeed.c
 create mode 100644 drivers/peci/busses/peci-mctp.c
 create mode 100644 drivers/peci/busses/peci-npcm.c
 create mode 100644 drivers/peci/peci-core.c
 create mode 100644 drivers/peci/peci-dev.c
 create mode 100644 include/linux/mfd/intel-peci-client.h
 create mode 100644 include/linux/peci.h
 create mode 100644 include/uapi/linux/peci-ioctl.h

diff --git a/drivers/Kconfig b/drivers/Kconfig
index 23954f66b6ef..279801e4b14e 100644
--- a/drivers/Kconfig
+++ b/drivers/Kconfig
@@ -237,5 +237,7 @@ source "drivers/counter/Kconfig"
 
 source "drivers/most/Kconfig"
 
+source "drivers/peci/Kconfig"
+
 source "drivers/jtag/Kconfig"
 endmenu
diff --git a/drivers/Makefile b/drivers/Makefile
index 3fbe9c5fc853..8ae56ee1c290 100644
--- a/drivers/Makefile
+++ b/drivers/Makefile
@@ -187,4 +187,5 @@ obj-$(CONFIG_GNSS)		+= gnss/
 obj-$(CONFIG_INTERCONNECT)	+= interconnect/
 obj-$(CONFIG_COUNTER)		+= counter/
 obj-$(CONFIG_MOST)		+= most/
+obj-$(CONFIG_PECI)		+= peci/
 obj-$(CONFIG_JTAG)		+= jtag/
diff --git a/drivers/hwmon/Kconfig b/drivers/hwmon/Kconfig
index eda867cffc82..337e575a919a 100644
--- a/drivers/hwmon/Kconfig
+++ b/drivers/hwmon/Kconfig
@@ -1536,6 +1536,62 @@ config SENSORS_PCF8591
 	  These devices are hard to detect and rarely found on mainstream
 	  hardware. If unsure, say N.
 
+config SENSORS_PECI_CPUTEMP
+	tristate "PECI CPU temperature monitoring client"
+	depends on PECI
+	select MFD_INTEL_PECI_CLIENT
+	help
+	  If you say yes here you get support for the generic Intel PECI
+	  cputemp driver which provides Digital Thermal Sensor (DTS) thermal
+	  readings of the CPU package and CPU cores that are accessible using
+	  the PECI Client Command Suite via the processor PECI client.
+	  Check <file:Documentation/hwmon/peci-cputemp.rst> for details.
+
+	  This driver can also be built as a module. If so, the module
+	  will be called peci-cputemp.
+
+config SENSORS_PECI_DIMMTEMP
+	tristate "PECI DIMM temperature monitoring client"
+	depends on PECI
+	select MFD_INTEL_PECI_CLIENT
+	help
+	  If you say yes here you get support for the generic Intel PECI hwmon
+	  driver which provides Digital Thermal Sensor (DTS) thermal readings of
+	  DIMM components that are accessible using the PECI Client Command
+	  Suite via the processor PECI client.
+	  Check <file:Documentation/hwmon/peci-dimmtemp.rst> for details.
+
+	  This driver can also be built as a module. If so, the module
+	  will be called peci-dimmtemp.
+
+config SENSORS_PECI_CPUPOWER
+	tristate "PECI CPU power monitoring support"
+	depends on PECI
+	select MFD_INTEL_PECI_CLIENT
+	help
+	  If you say yes here you get support for the generic Intel PECI
+	  cpupower driver which provides average engergy readings of the CPU package,
+	  current package power limit, maximal (TDP) and minimal power setting using
+	  the PECI Client Command Suite via the processor PECI client.
+	  Check Documentation/hwmon/peci-cpupower for details.
+
+	  This driver can also be built as a module. If so, the module
+	  will be called peci-cpupower.
+
+config SENSORS_PECI_DIMMPOWER
+	tristate "PECI DIMM power monitoring support"
+	depends on PECI
+	select MFD_INTEL_PECI_CLIENT
+	help
+	  If you say yes here you get support for the generic Intel PECI
+	  dimmpower driver which provides average engergy readings of the memory
+	  package, current power limit, maximal and minimal power setting using
+	  the PECI Client Command Suite via the processor PECI client.
+	  Check Documentation/hwmon/peci-dimmpower for details.
+
+	  This driver can also be built as a module. If so, the module
+	  will be called peci-dimmpower.
+
 source "drivers/hwmon/pmbus/Kconfig"
 
 config SENSORS_PWM_FAN
diff --git a/drivers/hwmon/Makefile b/drivers/hwmon/Makefile
index aec05cc007c2..d26b9da757db 100644
--- a/drivers/hwmon/Makefile
+++ b/drivers/hwmon/Makefile
@@ -161,6 +161,10 @@ obj-$(CONFIG_SENSORS_NZXT_KRAKEN2) += nzxt-kraken2.o
 obj-$(CONFIG_SENSORS_PC87360)	+= pc87360.o
 obj-$(CONFIG_SENSORS_PC87427)	+= pc87427.o
 obj-$(CONFIG_SENSORS_PCF8591)	+= pcf8591.o
+obj-$(CONFIG_SENSORS_PECI_CPUTEMP)	+= peci-cputemp.o
+obj-$(CONFIG_SENSORS_PECI_DIMMTEMP)	+= peci-dimmtemp.o
+obj-$(CONFIG_SENSORS_PECI_CPUPOWER)	+= peci-cpupower.o
+obj-$(CONFIG_SENSORS_PECI_DIMMPOWER)	+= peci-dimmpower.o
 obj-$(CONFIG_SENSORS_POWR1220)  += powr1220.o
 obj-$(CONFIG_SENSORS_PWM_FAN)	+= pwm-fan.o
 obj-$(CONFIG_SENSORS_RASPBERRYPI_HWMON)	+= raspberrypi-hwmon.o
diff --git a/drivers/hwmon/peci-cpupower.c b/drivers/hwmon/peci-cpupower.c
new file mode 100644
index 000000000000..8546cc1ff27c
--- /dev/null
+++ b/drivers/hwmon/peci-cpupower.c
@@ -0,0 +1,754 @@
+// SPDX-License-Identifier: GPL-2.0
+// Copyright (c) 2018-2020 Intel Corporation
+
+#include <linux/hwmon.h>
+#include <linux/jiffies.h>
+#include <linux/mfd/intel-peci-client.h>
+#include <linux/module.h>
+#include <linux/of_device.h>
+#include <linux/platform_device.h>
+#include "peci-hwmon.h"
+
+enum PECI_CPUPOWER_POWER_SENSOR_TYPES {
+	PECI_CPUPOWER_SENSOR_TYPE_POWER = 0,
+	PECI_CPUPOWER_SENSOR_TYPE_ENERGY,
+	PECI_CPUPOWER_SENSOR_TYPES_COUNT,
+};
+
+#define PECI_CPUPOWER_POWER_CHANNEL_COUNT	1 /* Supported channels number */
+#define PECI_CPUPOWER_ENERGY_CHANNEL_COUNT	1 /* Supported channels number */
+
+#define PECI_CPUPOWER_POWER_SENSOR_COUNT	4 /* Supported sensors number */
+#define PECI_CPUPOWER_ENERGY_SENSOR_COUNT	1 /* Supported sensors number */
+
+struct peci_cpupower {
+	struct device *dev;
+	struct peci_client_manager *mgr;
+	char name[PECI_NAME_SIZE];
+	u32 power_config[PECI_CPUPOWER_POWER_CHANNEL_COUNT + 1];
+	u32 energy_config[PECI_CPUPOWER_ENERGY_CHANNEL_COUNT + 1];
+
+	struct hwmon_channel_info power_info;
+	struct hwmon_channel_info energy_info;
+	const struct hwmon_channel_info *info[PECI_CPUPOWER_SENSOR_TYPES_COUNT + 1];
+	struct hwmon_chip_info chip;
+
+	struct peci_sensor_data
+		power_sensor_data_list[PECI_CPUPOWER_POWER_CHANNEL_COUNT]
+				      [PECI_CPUPOWER_POWER_SENSOR_COUNT];
+	struct peci_sensor_data
+		energy_sensor_data_list[PECI_CPUPOWER_ENERGY_CHANNEL_COUNT]
+				       [PECI_CPUPOWER_ENERGY_SENSOR_COUNT];
+
+	/* Below structs are not exposed to any sensor directly */
+	struct peci_sensor_data energy_cache; /* used to limit PECI communication */
+	struct peci_sensor_data power_sensor_prev_energy;
+	struct peci_sensor_data energy_sensor_prev_energy;
+
+	union peci_pkg_power_sku_unit units;
+	bool units_valid;
+
+	u32 ppl1_time_window;
+	u32 ppl2_time_window;
+	bool ppl_time_windows_valid;
+};
+
+static const char *peci_cpupower_labels[PECI_CPUPOWER_SENSOR_TYPES_COUNT] = {
+	"cpu power",
+	"cpu energy",
+};
+
+/**
+ * peci_cpupower_read_cpu_pkg_pwr_info_low - read PCS Platform Power SKU low.
+ * @peci_mgr: PECI client manager handle
+ * @reg: Pointer to the variable read value is going to be put
+ *
+ * Return: 0 if succeeded, other values in case an error.
+ */
+static inline int
+peci_cpupower_read_cpu_pkg_pwr_info_low(struct peci_client_manager *peci_mgr,
+					union peci_package_power_info_low *reg)
+{
+	return peci_pcs_read(peci_mgr, PECI_MBX_INDEX_TDP,
+			     PECI_PKG_ID_CPU_PACKAGE, &reg->value);
+}
+
+/**
+ * peci_cpupower_read_cpu_pkg_pwr_lim_low - read PCS Package Power Limit Low
+ * @peci_mgr: PECI client manager handle
+ * @reg: Pointer to the variable read value is going to be put
+ *
+ * Return: 0 if succeeded, other values in case an error.
+ */
+static inline int
+peci_cpupower_read_cpu_pkg_pwr_lim_low(struct peci_client_manager *peci_mgr,
+				       union peci_package_power_limit_low *reg)
+{
+	return peci_pcs_read(peci_mgr, PECI_MBX_INDEX_PKG_POWER_LIMIT1,
+			     PECI_PCS_PARAM_ZERO, &reg->value);
+}
+
+static int
+peci_cpupower_get_energy_counter(struct peci_cpupower *priv,
+				 struct peci_sensor_data *sensor_data,
+				 ulong update_interval)
+{
+	int ret = 0;
+
+	mutex_lock(&sensor_data->lock);
+	if (!peci_sensor_need_update_with_time(sensor_data,
+					       update_interval)) {
+		dev_dbg(priv->dev, "skip reading package energy over peci\n");
+		goto unlock;
+	}
+
+	ret = peci_pcs_read(priv->mgr, PECI_MBX_INDEX_ENERGY_COUNTER,
+			    PECI_PKG_ID_CPU_PACKAGE, &sensor_data->uvalue);
+	if (ret) {
+		dev_dbg(priv->dev, "not able to read package energy\n");
+		goto unlock;
+	}
+
+	peci_sensor_mark_updated(sensor_data);
+
+	dev_dbg(priv->dev,
+		"energy counter updated %duJ, jif %lu, HZ is %d jiffies\n",
+		sensor_data->uvalue, sensor_data->last_updated, HZ);
+
+unlock:
+	mutex_unlock(&sensor_data->lock);
+	return ret;
+}
+
+static int
+peci_cpupower_get_average_power(void *ctx,
+				struct peci_sensor_conf *sensor_conf,
+				struct peci_sensor_data *sensor_data)
+{
+	struct peci_cpupower *priv = (struct peci_cpupower *)ctx;
+	int ret = 0;
+
+	mutex_lock(&sensor_data->lock);
+	if (!peci_sensor_need_update_with_time(sensor_data,
+					       sensor_conf->update_interval)) {
+		dev_dbg(priv->dev,
+			"skip generating new power value %dmW jif %lu\n",
+			sensor_data->value, jiffies);
+		goto unlock;
+	}
+
+	ret = peci_cpupower_get_energy_counter(priv, &priv->energy_cache,
+					       sensor_conf->update_interval);
+	if (ret) {
+		dev_dbg(priv->dev, "cannot update energy counter\n");
+		goto unlock;
+	}
+
+	ret = peci_pcs_get_units(priv->mgr, &priv->units, &priv->units_valid);
+	if (ret) {
+		dev_dbg(priv->dev, "not able to read units\n");
+		goto unlock;
+	}
+
+	ret = peci_pcs_calc_pwr_from_eng(priv->dev,
+					 &priv->power_sensor_prev_energy,
+					 &priv->energy_cache,
+					 priv->units.bits.eng_unit,
+					 &sensor_data->value);
+	if (ret) {
+		dev_dbg(priv->dev, "power calculation failed\n");
+		goto unlock;
+	}
+
+	peci_sensor_mark_updated_with_time(sensor_data,
+					   priv->energy_cache.last_updated);
+
+	dev_dbg(priv->dev, "average power %dmW, jif %lu, HZ is %d jiffies\n",
+		sensor_data->value, sensor_data->last_updated, HZ);
+
+unlock:
+	mutex_unlock(&sensor_data->lock);
+	return ret;
+}
+
+static int
+peci_cpupower_get_power_limit(void *ctx, struct peci_sensor_conf *sensor_conf,
+			      struct peci_sensor_data *sensor_data)
+{
+	struct peci_cpupower *priv = (struct peci_cpupower *)ctx;
+	union peci_package_power_limit_low power_limit;
+	int ret = 0;
+
+	mutex_lock(&sensor_data->lock);
+	if (!peci_sensor_need_update_with_time(sensor_data,
+					       sensor_conf->update_interval)) {
+		dev_dbg(priv->dev, "skip reading peci, power limit %dmW\n",
+			sensor_data->value);
+		goto unlock;
+	}
+
+	ret = peci_pcs_get_units(priv->mgr, &priv->units, &priv->units_valid);
+	if (ret) {
+		dev_dbg(priv->dev, "not able to read units\n");
+		goto unlock;
+	}
+
+	ret = peci_cpupower_read_cpu_pkg_pwr_lim_low(priv->mgr, &power_limit);
+	if (ret) {
+		dev_dbg(priv->dev, "not able to read power limit\n");
+		goto unlock;
+	}
+
+	peci_sensor_mark_updated(sensor_data);
+	sensor_data->value = peci_pcs_xn_to_munits(power_limit.bits.pwr_lim_1,
+						   priv->units.bits.pwr_unit);
+
+	dev_dbg(priv->dev, "raw power limit %u, unit %u, power limit %d\n",
+		power_limit.bits.pwr_lim_1, priv->units.bits.pwr_unit,
+		sensor_data->value);
+
+unlock:
+	mutex_unlock(&sensor_data->lock);
+	return ret;
+}
+
+static int
+peci_cpupower_set_power_limit(void *ctx, struct peci_sensor_conf *sensor_conf,
+			      struct peci_sensor_data *sensor_data,
+			      s32 val)
+{
+	struct peci_cpupower *priv = (struct peci_cpupower *)ctx;
+	union peci_package_power_limit_high power_limit_high;
+	union peci_package_power_limit_low power_limit_low;
+	int ret;
+
+	ret = peci_pcs_get_units(priv->mgr, &priv->units, &priv->units_valid);
+	if (ret) {
+		dev_dbg(priv->dev, "not able to read units\n");
+		return ret;
+	}
+
+	ret = peci_cpupower_read_cpu_pkg_pwr_lim_low(priv->mgr,
+						     &power_limit_low);
+	if (ret) {
+		dev_dbg(priv->dev, "not able to read package power limit 1\n");
+		return ret;
+	}
+
+	ret = peci_pcs_read(priv->mgr, PECI_MBX_INDEX_PKG_POWER_LIMIT2,
+			    PECI_PCS_PARAM_ZERO, &power_limit_high.value);
+	if (ret) {
+		dev_dbg(priv->dev, "not able to read package power limit 2\n");
+		return ret;
+	}
+
+	/* Calculate PPL time windows if needed */
+	if (!priv->ppl_time_windows_valid) {
+		priv->ppl1_time_window =
+			peci_pcs_calc_plxy_time_window(peci_pcs_munits_to_xn(
+				PECI_PCS_PPL1_TIME_WINDOW,
+				priv->units.bits.tim_unit));
+		priv->ppl2_time_window =
+			peci_pcs_calc_plxy_time_window(peci_pcs_munits_to_xn(
+				PECI_PCS_PPL2_TIME_WINDOW,
+				priv->units.bits.tim_unit));
+		priv->ppl_time_windows_valid = true;
+	}
+
+	/* Enable or disable power limitation */
+	if (val > 0) {
+		/* Set PPL1 */
+		power_limit_low.bits.pwr_lim_1 =
+			peci_pcs_munits_to_xn(val, priv->units.bits.pwr_unit);
+		power_limit_low.bits.pwr_lim_1_en = 1u;
+		power_limit_low.bits.pwr_clmp_lim_1 = 1u;
+		power_limit_low.bits.pwr_lim_1_time = priv->ppl1_time_window;
+
+		/* Set PPL2 */
+		power_limit_high.bits.pwr_lim_2 =
+			peci_pcs_munits_to_xn(PECI_PCS_PPL1_TO_PPL2(val),
+					      priv->units.bits.pwr_unit);
+		power_limit_high.bits.pwr_lim_2_en = 1u;
+		power_limit_high.bits.pwr_clmp_lim_2 = 1u;
+		power_limit_high.bits.pwr_lim_2_time = priv->ppl2_time_window;
+	} else {
+		power_limit_low.bits.pwr_lim_1 = 0u;
+		power_limit_low.bits.pwr_lim_1_en = 0u;
+		power_limit_low.bits.pwr_clmp_lim_1 = 0u;
+		power_limit_low.bits.pwr_lim_1_time = 0u;
+		power_limit_high.bits.pwr_lim_2 = 0u;
+		power_limit_high.bits.pwr_lim_2_en = 0u;
+		power_limit_high.bits.pwr_clmp_lim_2 = 0u;
+		power_limit_high.bits.pwr_lim_2_time = 0u;
+	}
+
+	ret = peci_pcs_write(priv->mgr, PECI_MBX_INDEX_PKG_POWER_LIMIT1,
+			     PECI_PCS_PARAM_ZERO, power_limit_low.value);
+	if (ret) {
+		dev_dbg(priv->dev, "not able to write package power limit 1\n");
+		return ret;
+	}
+
+	ret = peci_pcs_write(priv->mgr, PECI_MBX_INDEX_PKG_POWER_LIMIT2,
+			     PECI_PCS_PARAM_ZERO, power_limit_high.value);
+	if (ret) {
+		dev_dbg(priv->dev, "not able to write package power limit 2\n");
+		return ret;
+	}
+
+	dev_dbg(priv->dev,
+		"power limit %d, unit %u, raw package power limit 1 %u,\n",
+		val, priv->units.bits.pwr_unit, power_limit_low.bits.pwr_lim_1);
+
+	return ret;
+}
+
+static int
+peci_cpupower_read_max_power(void *ctx, struct peci_sensor_conf *sensor_conf,
+			     struct peci_sensor_data *sensor_data)
+{
+	struct peci_cpupower *priv = (struct peci_cpupower *)ctx;
+	union peci_package_power_info_low power_info;
+	int ret = 0;
+
+	mutex_lock(&sensor_data->lock);
+	if (!peci_sensor_need_update_with_time(sensor_data,
+					       sensor_conf->update_interval)) {
+		dev_dbg(priv->dev, "skip reading peci, max power %dmW\n",
+			sensor_data->value);
+		goto unlock;
+	}
+
+	ret = peci_pcs_get_units(priv->mgr, &priv->units, &priv->units_valid);
+	if (ret) {
+		dev_dbg(priv->dev, "not able to read units\n");
+		goto unlock;
+	}
+
+	ret = peci_cpupower_read_cpu_pkg_pwr_info_low(priv->mgr, &power_info);
+	if (ret) {
+		dev_dbg(priv->dev, "not able to read package power info\n");
+		goto unlock;
+	}
+
+	peci_sensor_mark_updated(sensor_data);
+	sensor_data->value = peci_pcs_xn_to_munits(power_info.bits.pkg_tdp,
+						   priv->units.bits.pwr_unit);
+
+
+	dev_dbg(priv->dev, "raw max power %u, unit %u, max power %dmW\n",
+		power_info.bits.pkg_tdp, priv->units.bits.pwr_unit,
+		sensor_data->value);
+
+unlock:
+	mutex_unlock(&sensor_data->lock);
+	return ret;
+}
+
+static int
+peci_cpupower_read_min_power(void *ctx, struct peci_sensor_conf *sensor_conf,
+			     struct peci_sensor_data *sensor_data)
+{
+	struct peci_cpupower *priv = (struct peci_cpupower *)ctx;
+	union peci_package_power_info_low power_info;
+	int ret = 0;
+
+	mutex_lock(&sensor_data->lock);
+	if (!peci_sensor_need_update_with_time(sensor_data,
+					       sensor_conf->update_interval)) {
+		dev_dbg(priv->dev, "skip reading peci, min power %dmW\n",
+			sensor_data->value);
+		goto unlock;
+	}
+
+	ret = peci_pcs_get_units(priv->mgr, &priv->units, &priv->units_valid);
+	if (ret) {
+		dev_dbg(priv->dev, "not able to read units\n");
+		goto unlock;
+	}
+
+	ret = peci_cpupower_read_cpu_pkg_pwr_info_low(priv->mgr, &power_info);
+	if (ret) {
+		dev_dbg(priv->dev, "not able to read package power info\n");
+		goto unlock;
+	}
+
+	peci_sensor_mark_updated(sensor_data);
+	sensor_data->value = peci_pcs_xn_to_munits(power_info.bits.pkg_min_pwr,
+						   priv->units.bits.pwr_unit);
+
+	dev_dbg(priv->dev, "raw min power %u, unit %u, min power %dmW\n",
+		power_info.bits.pkg_min_pwr, priv->units.bits.pwr_unit,
+		sensor_data->value);
+
+unlock:
+	mutex_unlock(&sensor_data->lock);
+	return ret;
+}
+
+static int
+peci_cpupower_read_energy(void *ctx, struct peci_sensor_conf *sensor_conf,
+			  struct peci_sensor_data *sensor_data)
+{
+	struct peci_cpupower *priv = (struct peci_cpupower *)ctx;
+	int ret = 0;
+
+	mutex_lock(&sensor_data->lock);
+	if (!peci_sensor_need_update_with_time(sensor_data,
+					       sensor_conf->update_interval)) {
+		dev_dbg(priv->dev,
+			"skip generating new energy value %uuJ jif %lu\n",
+			sensor_data->uvalue, jiffies);
+		goto unlock;
+	}
+
+	ret = peci_cpupower_get_energy_counter(priv, &priv->energy_cache,
+					       sensor_conf->update_interval);
+	if (ret) {
+		dev_dbg(priv->dev, "cannot update energy counter\n");
+		goto unlock;
+	}
+
+	ret = peci_pcs_get_units(priv->mgr, &priv->units, &priv->units_valid);
+	if (ret) {
+		dev_dbg(priv->dev, "not able to read units\n");
+		goto unlock;
+	}
+
+	ret = peci_pcs_calc_acc_eng(priv->dev,
+				    &priv->energy_sensor_prev_energy,
+				    &priv->energy_cache,
+				    priv->units.bits.eng_unit,
+				    &sensor_data->uvalue);
+
+	if (ret) {
+		dev_dbg(priv->dev, "cumulative energy calculation failed\n");
+		goto unlock;
+	}
+
+	peci_sensor_mark_updated_with_time(sensor_data,
+					   priv->energy_cache.last_updated);
+
+	dev_dbg(priv->dev, "energy %duJ, jif %lu, HZ is %d jiffies\n",
+		sensor_data->uvalue, sensor_data->last_updated, HZ);
+
+unlock:
+	mutex_unlock(&sensor_data->lock);
+	return 0;
+}
+
+static struct peci_sensor_conf
+peci_cpupower_power_cfg[PECI_CPUPOWER_POWER_CHANNEL_COUNT]
+		       [PECI_CPUPOWER_POWER_SENSOR_COUNT] = {
+	/* Channel 0  - Power */
+	{
+		{
+			.attribute = hwmon_power_average,
+			.config = HWMON_P_AVERAGE,
+			.update_interval = UPDATE_INTERVAL_100MS,
+			.read = peci_cpupower_get_average_power,
+			.write = NULL,
+		},
+		{
+			.attribute = hwmon_power_cap,
+			.config = HWMON_P_CAP,
+			.update_interval = UPDATE_INTERVAL_100MS,
+			.read = peci_cpupower_get_power_limit,
+			.write = peci_cpupower_set_power_limit,
+		},
+		{
+			.attribute = hwmon_power_cap_max,
+			.config = HWMON_P_CAP_MAX,
+			.update_interval = UPDATE_INTERVAL_10S,
+			.read = peci_cpupower_read_max_power,
+			.write = NULL,
+		},
+		{
+			.attribute = hwmon_power_cap_min,
+			.config = HWMON_P_CAP_MIN,
+			.update_interval = UPDATE_INTERVAL_10S,
+			.read = peci_cpupower_read_min_power,
+			.write = NULL,
+		},
+	},
+};
+
+static struct peci_sensor_conf
+peci_cpupower_energy_cfg[PECI_CPUPOWER_ENERGY_CHANNEL_COUNT]
+		[PECI_CPUPOWER_ENERGY_SENSOR_COUNT] = {
+	/* Channel 0  - Energy */
+	{
+		{
+			.attribute = hwmon_energy_input,
+			.config = HWMON_E_INPUT,
+			.update_interval = UPDATE_INTERVAL_100MS,
+			.read = peci_cpupower_read_energy,
+			.write = NULL,
+		},
+	}
+};
+
+static bool
+peci_cpupower_is_channel_valid(enum hwmon_sensor_types type,
+			       int channel)
+{
+	if ((type == hwmon_power && channel < PECI_CPUPOWER_POWER_CHANNEL_COUNT) ||
+	    (type == hwmon_energy && channel < PECI_CPUPOWER_ENERGY_CHANNEL_COUNT))
+		return true;
+
+	return false;
+}
+
+static int
+peci_cpupower_read_string(struct device *dev, enum hwmon_sensor_types type,
+			  u32 attr, int channel, const char **str)
+{
+	if (!peci_cpupower_is_channel_valid(type, channel))
+		return -EOPNOTSUPP;
+
+	switch (attr) {
+	case hwmon_power_label:
+		*str = peci_cpupower_labels[PECI_CPUPOWER_SENSOR_TYPE_POWER];
+		break;
+	case hwmon_energy_label:
+		*str = peci_cpupower_labels[PECI_CPUPOWER_SENSOR_TYPE_ENERGY];
+		break;
+	default:
+		return -EOPNOTSUPP;
+	}
+
+	return 0;
+}
+
+static int
+peci_cpupower_read(struct device *dev, enum hwmon_sensor_types type,
+		   u32 attr, int channel, long *val)
+{
+	struct peci_cpupower *priv = dev_get_drvdata(dev);
+	struct peci_sensor_conf *sensor_conf;
+	struct peci_sensor_data *sensor_data;
+	int ret;
+
+	if (!priv || !val)
+		return -EINVAL;
+
+	if (!peci_cpupower_is_channel_valid(type, channel))
+		return -EOPNOTSUPP;
+
+	switch (type) {
+	case hwmon_power:
+		ret = peci_sensor_get_ctx(attr, peci_cpupower_power_cfg[channel],
+					  &sensor_conf,
+					  priv->power_sensor_data_list[channel],
+					  &sensor_data,
+					  ARRAY_SIZE(peci_cpupower_power_cfg[channel]));
+		break;
+	case hwmon_energy:
+		ret = peci_sensor_get_ctx(attr, peci_cpupower_energy_cfg[channel],
+					  &sensor_conf,
+					  priv->energy_sensor_data_list[channel],
+					  &sensor_data,
+					  ARRAY_SIZE(peci_cpupower_energy_cfg[channel]));
+		break;
+	default:
+		ret = -EOPNOTSUPP;
+	}
+
+	if (ret)
+		return ret;
+
+	if (sensor_conf->read) {
+		ret = sensor_conf->read(priv, sensor_conf, sensor_data);
+		if (!ret)
+			*val = (long)sensor_data->value;
+	} else {
+		ret = -EOPNOTSUPP;
+	}
+
+	return ret;
+}
+
+static int
+peci_cpupower_write(struct device *dev, enum hwmon_sensor_types type,
+		    u32 attr, int channel, long val)
+{
+	struct peci_cpupower *priv = dev_get_drvdata(dev);
+	struct peci_sensor_conf *sensor_conf;
+	struct peci_sensor_data *sensor_data;
+	int ret;
+
+	if (!priv)
+		return -EINVAL;
+
+	if (!peci_cpupower_is_channel_valid(type, channel))
+		return -EOPNOTSUPP;
+
+	switch (type) {
+	case hwmon_power:
+		ret = peci_sensor_get_ctx(attr, peci_cpupower_power_cfg[channel],
+					  &sensor_conf,
+					  priv->power_sensor_data_list[channel],
+					  &sensor_data,
+					  ARRAY_SIZE(peci_cpupower_power_cfg[channel]));
+		break;
+	case hwmon_energy:
+		ret = peci_sensor_get_ctx(attr, peci_cpupower_energy_cfg[channel],
+					  &sensor_conf,
+					  priv->energy_sensor_data_list[channel],
+					  &sensor_data,
+					  ARRAY_SIZE(peci_cpupower_energy_cfg[channel]));
+		break;
+	default:
+		ret = -EOPNOTSUPP;
+	}
+
+	if (ret)
+		return ret;
+
+	if (sensor_conf->write) {
+		ret = sensor_conf->write(priv, sensor_conf, sensor_data,
+					 (s32)val);
+	} else {
+		ret = -EOPNOTSUPP;
+	}
+
+	return ret;
+}
+
+static umode_t
+peci_cpupower_is_visible(const void *data, enum hwmon_sensor_types type,
+			 u32 attr, int channel)
+{
+	struct peci_sensor_conf *sensor_conf;
+	umode_t mode = 0;
+	int ret;
+
+	if (!peci_cpupower_is_channel_valid(type, channel))
+		return mode;
+
+	if (attr == hwmon_power_label || attr == hwmon_energy_label)
+		return 0444;
+
+	switch (type) {
+	case hwmon_power:
+		ret = peci_sensor_get_ctx(attr, peci_cpupower_power_cfg[channel],
+					  &sensor_conf, NULL, NULL,
+					  ARRAY_SIZE(peci_cpupower_power_cfg[channel]));
+		break;
+	case hwmon_energy:
+		ret = peci_sensor_get_ctx(attr, peci_cpupower_energy_cfg[channel],
+					  &sensor_conf, NULL, NULL,
+					  ARRAY_SIZE(peci_cpupower_energy_cfg[channel]));
+		break;
+	default:
+		return mode;
+	}
+
+	if (!ret) {
+		if (sensor_conf->read)
+			mode |= 0444;
+		if (sensor_conf->write)
+			mode |= 0200;
+	}
+
+	return mode;
+}
+
+static const struct hwmon_ops peci_cpupower_ops = {
+	.is_visible = peci_cpupower_is_visible,
+	.read_string = peci_cpupower_read_string,
+	.read = peci_cpupower_read,
+	.write = peci_cpupower_write,
+};
+
+static void peci_cpupower_sensor_init(struct peci_cpupower *priv)
+{
+	int i, j;
+
+	mutex_init(&priv->energy_cache.lock);
+
+	for (i = 0; i < PECI_CPUPOWER_POWER_CHANNEL_COUNT; i++) {
+		for (j = 0; j < PECI_CPUPOWER_POWER_SENSOR_COUNT; j++)
+			mutex_init(&priv->power_sensor_data_list[i][j].lock);
+	}
+
+	for (i = 0; i < PECI_CPUPOWER_ENERGY_CHANNEL_COUNT; i++) {
+		for (j = 0; j < PECI_CPUPOWER_ENERGY_SENSOR_COUNT; j++)
+			mutex_init(&priv->energy_sensor_data_list[i][j].lock);
+	}
+}
+
+static int peci_cpupower_probe(struct platform_device *pdev)
+{
+	struct peci_client_manager *mgr = dev_get_drvdata(pdev->dev.parent);
+	struct device *dev = &pdev->dev;
+	struct peci_cpupower *priv;
+	struct device *hwmon_dev;
+	u32 power_cfg_idx = 0;
+	u32 energy_cfg_idx = 0;
+	u32 cmd_mask;
+
+	cmd_mask = BIT(PECI_CMD_RD_PKG_CFG) | BIT(PECI_CMD_WR_PKG_CFG);
+	if ((mgr->client->adapter->cmd_mask & cmd_mask) != cmd_mask)
+		return -ENODEV;
+
+	priv = devm_kzalloc(dev, sizeof(*priv), GFP_KERNEL);
+	if (!priv)
+		return -ENOMEM;
+
+	dev_set_drvdata(dev, priv);
+	priv->mgr = mgr;
+	priv->dev = dev;
+
+	snprintf(priv->name, PECI_NAME_SIZE, "peci_cpupower.cpu%d.%d",
+		 mgr->client->addr - PECI_BASE_ADDR, mgr->client->domain_id);
+
+	priv->power_config[power_cfg_idx] = HWMON_P_LABEL |
+		peci_sensor_get_config(peci_cpupower_power_cfg[power_cfg_idx],
+				       ARRAY_SIZE(peci_cpupower_power_cfg[power_cfg_idx]));
+
+	priv->energy_config[energy_cfg_idx] = HWMON_E_LABEL |
+		peci_sensor_get_config(peci_cpupower_energy_cfg[energy_cfg_idx],
+				       ARRAY_SIZE(peci_cpupower_energy_cfg[energy_cfg_idx]));
+
+	priv->info[PECI_CPUPOWER_SENSOR_TYPE_POWER] = &priv->power_info;
+	priv->power_info.type = hwmon_power;
+	priv->power_info.config = priv->power_config;
+
+	priv->info[PECI_CPUPOWER_SENSOR_TYPE_ENERGY] = &priv->energy_info;
+	priv->energy_info.type = hwmon_energy;
+	priv->energy_info.config = priv->energy_config;
+
+	priv->chip.ops = &peci_cpupower_ops;
+	priv->chip.info = priv->info;
+
+	peci_cpupower_sensor_init(priv);
+
+	hwmon_dev = devm_hwmon_device_register_with_info(priv->dev, priv->name,
+							 priv, &priv->chip,
+							 NULL);
+
+	if (IS_ERR(hwmon_dev))
+		return PTR_ERR(hwmon_dev);
+
+	dev_dbg(dev, "%s: sensor '%s'\n", dev_name(hwmon_dev), priv->name);
+
+	return 0;
+}
+
+static const struct platform_device_id peci_cpupower_ids[] = {
+	{ .name = "peci-cpupower", .driver_data = 0 },
+	{ }
+};
+MODULE_DEVICE_TABLE(platform, peci_cpupower_ids);
+
+static struct platform_driver peci_cpupower_driver = {
+	.probe    = peci_cpupower_probe,
+	.id_table = peci_cpupower_ids,
+	.driver   = { .name = KBUILD_MODNAME, },
+};
+module_platform_driver(peci_cpupower_driver);
+
+MODULE_AUTHOR("Zhikui Ren <zhikui.ren@intel.com>");
+MODULE_DESCRIPTION("PECI cpupower driver");
+MODULE_LICENSE("GPL v2");
diff --git a/drivers/hwmon/peci-cputemp.c b/drivers/hwmon/peci-cputemp.c
new file mode 100644
index 000000000000..37ba56838aae
--- /dev/null
+++ b/drivers/hwmon/peci-cputemp.c
@@ -0,0 +1,550 @@
+// SPDX-License-Identifier: GPL-2.0
+// Copyright (c) 2018-2019 Intel Corporation
+
+#include <linux/hwmon.h>
+#include <linux/jiffies.h>
+#include <linux/mfd/intel-peci-client.h>
+#include <linux/module.h>
+#include <linux/of_device.h>
+#include <linux/platform_device.h>
+#include "peci-hwmon.h"
+
+#define DEFAULT_CHANNEL_NUMS	5
+#define MODTEMP_CHANNEL_NUMS	CORE_MASK_BITS_MAX
+#define CPUTEMP_CHANNEL_NUMS	(DEFAULT_CHANNEL_NUMS + MODTEMP_CHANNEL_NUMS)
+#define BIOS_RST_CPL3		BIT(3)
+
+struct temp_group {
+	struct peci_sensor_data		die;
+	struct peci_sensor_data		dts;
+	struct peci_sensor_data		tcontrol;
+	struct peci_sensor_data		tthrottle;
+	struct peci_sensor_data		tjmax;
+	struct peci_sensor_data		module[MODTEMP_CHANNEL_NUMS];
+};
+
+struct peci_cputemp {
+	struct peci_client_manager	*mgr;
+	struct device			*dev;
+	char				name[PECI_NAME_SIZE];
+	const struct cpu_gen_info	*gen_info;
+	struct temp_group		temp;
+	u64				core_mask;
+	u32				temp_config[CPUTEMP_CHANNEL_NUMS + 1];
+	uint				config_idx;
+	struct hwmon_channel_info	temp_info;
+	const struct hwmon_channel_info	*info[2];
+	struct hwmon_chip_info		chip;
+	char				**module_temp_label;
+};
+
+enum cputemp_channels {
+	channel_die,
+	channel_dts,
+	channel_tcontrol,
+	channel_tthrottle,
+	channel_tjmax,
+	channel_core,
+};
+
+static const u32 config_table[] = {
+	/* Die temperature */
+	HWMON_T_LABEL | HWMON_T_INPUT | HWMON_T_MAX | HWMON_T_CRIT |
+	HWMON_T_CRIT_HYST,
+
+	/* DTS margin */
+	HWMON_T_LABEL | HWMON_T_INPUT | HWMON_T_MAX | HWMON_T_CRIT |
+	HWMON_T_CRIT_HYST,
+
+	/* Tcontrol temperature */
+	HWMON_T_LABEL | HWMON_T_INPUT | HWMON_T_CRIT,
+
+	/* Tthrottle temperature */
+	HWMON_T_LABEL | HWMON_T_INPUT,
+
+	/* Tjmax temperature */
+	HWMON_T_LABEL | HWMON_T_INPUT,
+
+	/* Core temperature - for all core channels */
+	HWMON_T_LABEL | HWMON_T_INPUT,
+};
+
+static const char *cputemp_label[DEFAULT_CHANNEL_NUMS] = {
+	"Die",
+	"DTS",
+	"Tcontrol",
+	"Tthrottle",
+	"Tjmax"
+};
+
+static s32 ten_dot_six_to_millidegree(s32 val)
+{
+	return ((val ^ 0x8000) - 0x8000) * 1000 / 64;
+}
+
+static int get_temp_targets(struct peci_cputemp *priv)
+{
+	struct peci_rd_end_pt_cfg_msg re_msg;
+	u32 bios_reset_cpl_cfg;
+	s32 tthrottle_offset;
+	s32 tcontrol_margin;
+	u8  pkg_cfg[4];
+	int ret;
+
+	/*
+	 * Just use only the tcontrol marker to determine if target values need
+	 * update.
+	 */
+	if (!peci_sensor_need_update(&priv->temp.tcontrol))
+		return 0;
+
+	/*
+	 * CPU can return invalid temperatures prior to BIOS-PCU handshake
+	 * RST_CPL3 completion so filter the invalid readings out.
+	 */
+	switch (priv->gen_info->model) {
+	case INTEL_FAM6_ICELAKE_X:
+	case INTEL_FAM6_ICELAKE_XD:
+		re_msg.addr = priv->mgr->client->addr;
+		re_msg.msg_type = PECI_ENDPTCFG_TYPE_LOCAL_PCI;
+		re_msg.params.pci_cfg.seg = 0;
+		re_msg.params.pci_cfg.bus = 31;
+		re_msg.params.pci_cfg.device = 30;
+		re_msg.params.pci_cfg.function = 1;
+		re_msg.params.pci_cfg.reg = 0x94;
+		re_msg.rx_len = 4;
+		re_msg.domain_id = priv->mgr->client->domain_id;
+
+		ret = peci_command(priv->mgr->client->adapter,
+				   PECI_CMD_RD_END_PT_CFG, sizeof(re_msg), &re_msg);
+		if (ret || re_msg.cc != PECI_DEV_CC_SUCCESS)
+			ret = -EAGAIN;
+		if (ret)
+			return ret;
+
+		bios_reset_cpl_cfg = le32_to_cpup((__le32 *)re_msg.data);
+		if (!(bios_reset_cpl_cfg & BIOS_RST_CPL3)) {
+			dev_dbg(priv->dev, "BIOS and Pcode Node ID isn't configured, BIOS_RESET_CPL_CFG: 0x%x\n",
+				bios_reset_cpl_cfg);
+			return -EAGAIN;
+		}
+
+		break;
+	default:
+		/* TODO: Check reset completion for other CPUs if needed */
+		break;
+	}
+
+	ret = peci_client_read_package_config(priv->mgr,
+					      PECI_MBX_INDEX_TEMP_TARGET, 0,
+					      pkg_cfg);
+	if (ret)
+		return ret;
+
+	priv->temp.tjmax.value = pkg_cfg[2] * 1000;
+
+	tcontrol_margin = pkg_cfg[1];
+	tcontrol_margin = ((tcontrol_margin ^ 0x80) - 0x80) * 1000;
+	priv->temp.tcontrol.value = priv->temp.tjmax.value - tcontrol_margin;
+
+	tthrottle_offset = (pkg_cfg[3] & 0x2f) * 1000;
+	priv->temp.tthrottle.value = priv->temp.tjmax.value - tthrottle_offset;
+
+	peci_sensor_mark_updated(&priv->temp.tcontrol);
+
+	return 0;
+}
+
+static int get_die_temp(struct peci_cputemp *priv)
+{
+	struct peci_get_temp_msg msg;
+	int ret;
+
+	if (!peci_sensor_need_update(&priv->temp.die))
+		return 0;
+
+	msg.addr = priv->mgr->client->addr;
+
+	ret = peci_command(priv->mgr->client->adapter, PECI_CMD_GET_TEMP, sizeof(msg), &msg);
+	if (ret)
+		return ret;
+
+	/* Note that the tjmax should be available before calling it */
+	priv->temp.die.value = priv->temp.tjmax.value +
+			       (msg.temp_raw * 1000 / 64);
+
+	peci_sensor_mark_updated(&priv->temp.die);
+
+	return 0;
+}
+
+static int get_dts(struct peci_cputemp *priv)
+{
+	s32 dts_margin;
+	u8  pkg_cfg[4];
+	int ret;
+
+	if (!peci_sensor_need_update(&priv->temp.dts))
+		return 0;
+
+	ret = peci_client_read_package_config(priv->mgr,
+					      PECI_MBX_INDEX_DTS_MARGIN, 0,
+					      pkg_cfg);
+
+	if (ret)
+		return ret;
+
+	dts_margin = le16_to_cpup((__le16 *)pkg_cfg);
+
+	/**
+	 * Processors return a value of DTS reading in 10.6 format
+	 * (10 bits signed decimal, 6 bits fractional).
+	 * Error codes:
+	 *   0x8000: General sensor error
+	 *   0x8001: Reserved
+	 *   0x8002: Underflow on reading value
+	 *   0x8003-0x81ff: Reserved
+	 */
+	if (dts_margin >= 0x8000 && dts_margin <= 0x81ff)
+		return -EIO;
+
+	dts_margin = ten_dot_six_to_millidegree(dts_margin);
+
+	/* Note that the tcontrol should be available before calling it */
+	priv->temp.dts.value = priv->temp.tcontrol.value - dts_margin;
+
+	peci_sensor_mark_updated(&priv->temp.dts);
+
+	return 0;
+}
+
+static int get_module_temp(struct peci_cputemp *priv, int index)
+{
+	s32 module_dts_margin;
+	u8  pkg_cfg[4];
+	int ret;
+
+	if (!peci_sensor_need_update(&priv->temp.module[index]))
+		return 0;
+
+	ret = peci_client_read_package_config(priv->mgr,
+					      PECI_MBX_INDEX_MODULE_TEMP,
+					      index, pkg_cfg);
+	if (ret)
+		return ret;
+
+	module_dts_margin = le16_to_cpup((__le16 *)pkg_cfg);
+
+	/*
+	 * Processors return a value of the DTS reading in 10.6 format
+	 * (10 bits signed decimal, 6 bits fractional).
+	 * Error codes:
+	 *   0x8000: General sensor error
+	 *   0x8001: Reserved
+	 *   0x8002: Underflow on reading value
+	 *   0x8003-0x81ff: Reserved
+	 */
+	if (module_dts_margin >= 0x8000 && module_dts_margin <= 0x81ff)
+		return -EIO;
+
+	module_dts_margin = ten_dot_six_to_millidegree(module_dts_margin);
+
+	/* Note that the tjmax should be available before calling it */
+	priv->temp.module[index].value = priv->temp.tjmax.value +
+					 module_dts_margin;
+
+	peci_sensor_mark_updated(&priv->temp.module[index]);
+
+	return 0;
+}
+
+static int cputemp_read_string(struct device *dev,
+			       enum hwmon_sensor_types type,
+			       u32 attr, int channel, const char **str)
+{
+	struct peci_cputemp *priv = dev_get_drvdata(dev);
+
+	if (attr != hwmon_temp_label)
+		return -EOPNOTSUPP;
+
+	*str = (channel < DEFAULT_CHANNEL_NUMS) ?
+	       cputemp_label[channel] :
+	       (const char *)priv->module_temp_label[channel -
+						     DEFAULT_CHANNEL_NUMS];
+
+	return 0;
+}
+
+static int cputemp_read(struct device *dev,
+			enum hwmon_sensor_types type,
+			u32 attr, int channel, long *val)
+{
+	struct peci_cputemp *priv = dev_get_drvdata(dev);
+	int ret, module_index;
+
+	if (channel >= CPUTEMP_CHANNEL_NUMS ||
+	    !(priv->temp_config[channel] & BIT(attr)))
+		return -EOPNOTSUPP;
+
+	ret = get_temp_targets(priv);
+	if (ret)
+		return ret;
+
+	switch (attr) {
+	case hwmon_temp_input:
+		switch (channel) {
+		case channel_die:
+			ret = get_die_temp(priv);
+			if (ret)
+				break;
+
+			*val = priv->temp.die.value;
+			break;
+		case channel_dts:
+			ret = get_dts(priv);
+			if (ret)
+				break;
+
+			*val = priv->temp.dts.value;
+			break;
+		case channel_tcontrol:
+			*val = priv->temp.tcontrol.value;
+			break;
+		case channel_tthrottle:
+			*val = priv->temp.tthrottle.value;
+			break;
+		case channel_tjmax:
+			*val = priv->temp.tjmax.value;
+			break;
+		default:
+			module_index = channel - DEFAULT_CHANNEL_NUMS;
+			ret = get_module_temp(priv, module_index);
+			if (ret)
+				break;
+
+			*val = priv->temp.module[module_index].value;
+			break;
+		}
+		break;
+	case hwmon_temp_max:
+		*val = priv->temp.tcontrol.value;
+		break;
+	case hwmon_temp_crit:
+		*val = priv->temp.tjmax.value;
+		break;
+	case hwmon_temp_crit_hyst:
+		*val = priv->temp.tjmax.value - priv->temp.tcontrol.value;
+		break;
+	default:
+		ret = -EOPNOTSUPP;
+		break;
+	}
+
+	return ret;
+}
+
+static umode_t cputemp_is_visible(const void *data,
+				  enum hwmon_sensor_types type,
+				  u32 attr, int channel)
+{
+	const struct peci_cputemp *priv = data;
+
+	if (channel < ARRAY_SIZE(priv->temp_config) &&
+	    (priv->temp_config[channel] & BIT(attr)) &&
+	    (channel < DEFAULT_CHANNEL_NUMS ||
+	     (channel >= DEFAULT_CHANNEL_NUMS &&
+	      (priv->core_mask & BIT(channel - DEFAULT_CHANNEL_NUMS)))))
+		return 0444;
+
+	return 0;
+}
+
+static const struct hwmon_ops cputemp_ops = {
+	.is_visible = cputemp_is_visible,
+	.read_string = cputemp_read_string,
+	.read = cputemp_read,
+};
+
+static int check_resolved_cores(struct peci_cputemp *priv)
+{
+	struct peci_rd_pci_cfg_local_msg msg;
+	int ret;
+
+	/* Get the RESOLVED_CORES register value */
+	switch (priv->gen_info->model) {
+	case INTEL_FAM6_ICELAKE_X:
+	case INTEL_FAM6_ICELAKE_XD:
+		msg.addr = priv->mgr->client->addr;
+		msg.device = 30;
+		msg.function = 3;
+		msg.bus = 14;
+		msg.reg = 0xd4;
+		msg.rx_len = 4;
+		msg.domain_id = priv->mgr->client->domain_id;
+
+		ret = peci_command(priv->mgr->client->adapter,
+				   PECI_CMD_RD_PCI_CFG_LOCAL, sizeof(msg), &msg);
+		if (msg.cc != PECI_DEV_CC_SUCCESS)
+			ret = -EAGAIN;
+		if (ret)
+			return ret;
+
+		priv->core_mask = le32_to_cpup((__le32 *)msg.pci_config);
+		priv->core_mask <<= 32;
+
+		msg.reg = 0xd0;
+
+		ret = peci_command(priv->mgr->client->adapter,
+				   PECI_CMD_RD_PCI_CFG_LOCAL, sizeof(msg), &msg);
+
+		if (msg.cc != PECI_DEV_CC_SUCCESS)
+			ret = -EAGAIN;
+		if (ret) {
+			priv->core_mask = 0;
+			return ret;
+		}
+
+		priv->core_mask |= le32_to_cpup((__le32 *)msg.pci_config);
+		break;
+	default:
+		msg.addr = priv->mgr->client->addr;
+		msg.device = 30;
+		msg.function = 3;
+		msg.bus = 1;
+		msg.reg = 0xb4;
+		msg.rx_len = 4;
+		msg.domain_id = priv->mgr->client->domain_id;
+
+		ret = peci_command(priv->mgr->client->adapter,
+				   PECI_CMD_RD_PCI_CFG_LOCAL, sizeof(msg), &msg);
+		if (msg.cc != PECI_DEV_CC_SUCCESS)
+			ret = -EAGAIN;
+		if (ret)
+			return ret;
+
+		priv->core_mask = le32_to_cpup((__le32 *)msg.pci_config);
+		break;
+	}
+
+	if (!priv->core_mask)
+		return -EAGAIN;
+
+	dev_dbg(priv->dev, "Scanned resolved cores: 0x%llx\n", priv->core_mask);
+
+	return 0;
+}
+
+static int create_module_temp_label(struct peci_cputemp *priv, int idx)
+{
+	priv->module_temp_label[idx] = devm_kzalloc(priv->dev,
+						    PECI_HWMON_LABEL_STR_LEN,
+						    GFP_KERNEL);
+	if (!priv->module_temp_label[idx])
+		return -ENOMEM;
+
+	sprintf(priv->module_temp_label[idx], "Core %d", idx);
+
+	return 0;
+}
+
+static int create_module_temp_info(struct peci_cputemp *priv)
+{
+	int ret, i;
+
+	ret = check_resolved_cores(priv);
+	if (ret)
+		return ret;
+
+	priv->module_temp_label = devm_kzalloc(priv->dev,
+					       MODTEMP_CHANNEL_NUMS *
+					       sizeof(char *),
+					       GFP_KERNEL);
+	if (!priv->module_temp_label)
+		return -ENOMEM;
+
+	for (i = 0; i < MODTEMP_CHANNEL_NUMS; i++) {
+		priv->temp_config[priv->config_idx++] = config_table[channel_core];
+
+		if (i < priv->gen_info->core_mask_bits && priv->core_mask & BIT(i)) {
+			ret = create_module_temp_label(priv, i);
+			if (ret)
+				return ret;
+		}
+	}
+
+	return 0;
+}
+
+static int peci_cputemp_probe(struct platform_device *pdev)
+{
+	struct peci_client_manager *mgr = dev_get_drvdata(pdev->dev.parent);
+	struct device *dev = &pdev->dev;
+	struct peci_cputemp *priv;
+	struct device *hwmon_dev;
+	int ret;
+
+	if ((mgr->client->adapter->cmd_mask &
+	    (BIT(PECI_CMD_GET_TEMP) | BIT(PECI_CMD_RD_PKG_CFG))) !=
+	    (BIT(PECI_CMD_GET_TEMP) | BIT(PECI_CMD_RD_PKG_CFG)))
+		return -ENODEV;
+
+	priv = devm_kzalloc(dev, sizeof(*priv), GFP_KERNEL);
+	if (!priv)
+		return -ENOMEM;
+
+	dev_set_drvdata(dev, priv);
+	priv->mgr = mgr;
+	priv->dev = dev;
+	priv->gen_info = mgr->gen_info;
+
+	snprintf(priv->name, PECI_NAME_SIZE, "peci_cputemp.cpu%d.%d",
+		 mgr->client->addr - PECI_BASE_ADDR, mgr->client->domain_id);
+
+	priv->temp_config[priv->config_idx++] = config_table[channel_die];
+	priv->temp_config[priv->config_idx++] = config_table[channel_dts];
+	priv->temp_config[priv->config_idx++] = config_table[channel_tcontrol];
+	priv->temp_config[priv->config_idx++] = config_table[channel_tthrottle];
+	priv->temp_config[priv->config_idx++] = config_table[channel_tjmax];
+
+	ret = create_module_temp_info(priv);
+	if (ret)
+		dev_dbg(dev, "Skipped creating core temp info\n");
+
+	priv->chip.ops = &cputemp_ops;
+	priv->chip.info = priv->info;
+
+	priv->info[0] = &priv->temp_info;
+
+	priv->temp_info.type = hwmon_temp;
+	priv->temp_info.config = priv->temp_config;
+
+	hwmon_dev = devm_hwmon_device_register_with_info(priv->dev,
+							 priv->name,
+							 priv,
+							 &priv->chip,
+							 NULL);
+
+	if (IS_ERR(hwmon_dev))
+		return PTR_ERR(hwmon_dev);
+
+	dev_dbg(dev, "%s: sensor '%s'\n", dev_name(hwmon_dev), priv->name);
+
+	return 0;
+}
+
+static const struct platform_device_id peci_cputemp_ids[] = {
+	{ .name = "peci-cputemp", .driver_data = 0 },
+	{ }
+};
+MODULE_DEVICE_TABLE(platform, peci_cputemp_ids);
+
+static struct platform_driver peci_cputemp_driver = {
+	.probe		= peci_cputemp_probe,
+	.id_table	= peci_cputemp_ids,
+	.driver		= { .name = KBUILD_MODNAME, },
+};
+module_platform_driver(peci_cputemp_driver);
+
+MODULE_AUTHOR("Jae Hyun Yoo <jae.hyun.yoo@linux.intel.com>");
+MODULE_DESCRIPTION("PECI cputemp driver");
+MODULE_LICENSE("GPL v2");
diff --git a/drivers/hwmon/peci-dimmpower.c b/drivers/hwmon/peci-dimmpower.c
new file mode 100644
index 000000000000..ee59096d9258
--- /dev/null
+++ b/drivers/hwmon/peci-dimmpower.c
@@ -0,0 +1,673 @@
+// SPDX-License-Identifier: GPL-2.0
+// Copyright (c) 2020 Intel Corporation
+
+#include <linux/hwmon.h>
+#include <linux/jiffies.h>
+#include <linux/mfd/intel-peci-client.h>
+#include <linux/module.h>
+#include <linux/of_device.h>
+#include <linux/platform_device.h>
+#include "peci-hwmon.h"
+
+enum PECI_DIMMPOWER_SENSOR_TYPES {
+	PECI_DIMMPOWER_SENSOR_TYPE_POWER = 0,
+	PECI_DIMMPOWER_SENSOR_TYPE_ENERGY,
+	PECI_DIMMPOWER_SENSOR_TYPES_COUNT,
+};
+
+#define PECI_DIMMPOWER_POWER_CHANNEL_COUNT	1 /* Supported channels number */
+#define PECI_DIMMPOWER_ENERGY_CHANNEL_COUNT	1 /* Supported channels number */
+
+#define PECI_DIMMPOWER_POWER_SENSOR_COUNT	4 /* Supported sensors/readings number */
+#define PECI_DIMMPOWER_ENERGY_SENSOR_COUNT	1 /* Supported sensors/readings number */
+
+struct peci_dimmpower {
+	struct device *dev;
+	struct peci_client_manager *mgr;
+	char name[PECI_NAME_SIZE];
+	u32 power_config[PECI_DIMMPOWER_POWER_CHANNEL_COUNT + 1];
+	u32 energy_config[PECI_DIMMPOWER_ENERGY_CHANNEL_COUNT + 1];
+
+	struct hwmon_channel_info power_info;
+	struct hwmon_channel_info energy_info;
+	const struct hwmon_channel_info *info[PECI_DIMMPOWER_SENSOR_TYPES_COUNT + 1];
+	struct hwmon_chip_info chip;
+
+	struct peci_sensor_data
+		power_sensor_data_list[PECI_DIMMPOWER_POWER_CHANNEL_COUNT]
+				      [PECI_DIMMPOWER_POWER_SENSOR_COUNT];
+	struct peci_sensor_data
+		energy_sensor_data_list[PECI_DIMMPOWER_ENERGY_CHANNEL_COUNT]
+				       [PECI_DIMMPOWER_ENERGY_SENSOR_COUNT];
+
+	/* Below structs are not exposed to any sensor directly */
+	struct peci_sensor_data energy_cache; /* used to limit PECI communication */
+	struct peci_sensor_data power_sensor_prev_energy;
+	struct peci_sensor_data energy_sensor_prev_energy;
+
+	union peci_pkg_power_sku_unit units;
+	bool units_valid;
+
+	u32 dpl_time_window;
+	bool dpl_time_window_valid;
+};
+
+static const char *peci_dimmpower_labels[PECI_DIMMPOWER_SENSOR_TYPES_COUNT] = {
+	"dimm power",
+	"dimm energy",
+};
+
+/**
+ * peci_dimmpower_read_dram_power_limit - read PCS DRAM Power Limit
+ * @peci_mgr: PECI client manager handle
+ * @reg: Pointer to the variable read value is going to be put
+ *
+ * Return: 0 if succeeded, other values in case an error.
+ */
+static inline int
+peci_dimmpower_read_dram_power_limit(struct peci_client_manager *peci_mgr,
+				     union peci_dram_power_limit *reg)
+{
+	return peci_pcs_read(peci_mgr, PECI_MBX_INDEX_DDR_RAPL_PL1,
+			     PECI_PCS_PARAM_ZERO, &reg->value);
+}
+
+static int
+peci_dimmpower_get_energy_counter(struct peci_dimmpower *priv,
+				  struct peci_sensor_data *sensor_data,
+				  ulong update_interval)
+{
+	int ret = 0;
+
+	mutex_lock(&sensor_data->lock);
+	if (!peci_sensor_need_update_with_time(sensor_data,
+					       update_interval)) {
+		dev_dbg(priv->dev, "skip reading dimm energy over peci\n");
+		goto unlock;
+	}
+
+	ret = peci_pcs_read(priv->mgr, PECI_MBX_INDEX_ENERGY_STATUS,
+			    PECI_PKG_ID_DIMM, &sensor_data->uvalue);
+	if (ret) {
+		dev_dbg(priv->dev, "not able to read dimm energy\n");
+		goto unlock;
+	}
+
+	peci_sensor_mark_updated(sensor_data);
+
+	dev_dbg(priv->dev,
+		"energy counter updated %duJ, jif %lu, HZ is %d jiffies\n",
+		sensor_data->uvalue, sensor_data->last_updated, HZ);
+
+unlock:
+	mutex_unlock(&sensor_data->lock);
+	return ret;
+}
+
+static int
+peci_dimmpower_get_avg_power(void *ctx, struct peci_sensor_conf *sensor_conf,
+			     struct peci_sensor_data *sensor_data)
+{
+	struct peci_dimmpower *priv = (struct peci_dimmpower *)ctx;
+	int ret = 0;
+
+	mutex_lock(&sensor_data->lock);
+	if (!peci_sensor_need_update_with_time(sensor_data,
+					       sensor_conf->update_interval)) {
+		dev_dbg(priv->dev, "skip reading peci, average power %dmW jif %lu\n",
+			sensor_data->value, jiffies);
+		goto unlock;
+	}
+
+	ret = peci_dimmpower_get_energy_counter(priv, &priv->energy_cache,
+						sensor_conf->update_interval);
+	if (ret) {
+		dev_dbg(priv->dev, "cannot update energy counter\n");
+		goto unlock;
+	}
+
+	ret = peci_pcs_get_units(priv->mgr, &priv->units, &priv->units_valid);
+	if (ret) {
+		dev_dbg(priv->dev, "not able to read units\n");
+		goto unlock;
+	}
+
+	ret = peci_pcs_calc_pwr_from_eng(priv->dev,
+					 &priv->power_sensor_prev_energy,
+					 &priv->energy_cache,
+					 priv->units.bits.eng_unit,
+					 &sensor_data->value);
+	if (ret) {
+		dev_dbg(priv->dev, "power calculation failed\n");
+		goto unlock;
+	}
+
+	peci_sensor_mark_updated_with_time(sensor_data, priv->energy_cache.last_updated);
+
+	dev_dbg(priv->dev, "average power %dmW, jif %lu, HZ is %d jiffies\n",
+		sensor_data->value, sensor_data->last_updated, HZ);
+
+unlock:
+	mutex_unlock(&sensor_data->lock);
+	return ret;
+}
+
+static int
+peci_dimmpower_get_power_limit(void *ctx, struct peci_sensor_conf *sensor_conf,
+			       struct peci_sensor_data *sensor_data)
+{
+	struct peci_dimmpower *priv = (struct peci_dimmpower *)ctx;
+	union peci_dram_power_limit power_limit;
+	int ret = 0;
+
+	mutex_lock(&sensor_data->lock);
+	if (!peci_sensor_need_update_with_time(sensor_data,
+					       sensor_conf->update_interval)) {
+		dev_dbg(priv->dev, "skip reading peci, power limit %dmW\n",
+			sensor_data->value);
+		goto unlock;
+	}
+
+	ret = peci_pcs_get_units(priv->mgr, &priv->units, &priv->units_valid);
+	if (ret) {
+		dev_dbg(priv->dev, "not able to read units\n");
+		goto unlock;
+	}
+
+	ret = peci_dimmpower_read_dram_power_limit(priv->mgr, &power_limit);
+	if (ret) {
+		dev_dbg(priv->dev, "not able to read power limit\n");
+		goto unlock;
+	}
+
+	peci_sensor_mark_updated(sensor_data);
+	sensor_data->value = peci_pcs_xn_to_munits(power_limit.bits.pp_pwr_lim,
+						   priv->units.bits.pwr_unit);
+
+	dev_dbg(priv->dev, "raw power limit %u, unit %u, power limit %d\n",
+		power_limit.bits.pp_pwr_lim, priv->units.bits.pwr_unit,
+		sensor_data->value);
+
+unlock:
+	mutex_unlock(&sensor_data->lock);
+	return ret;
+}
+
+static int
+peci_dimmpower_set_power_limit(void *ctx, struct peci_sensor_conf *sensor_conf,
+			       struct peci_sensor_data *sensor_data,
+			       s32 val)
+{
+	struct peci_dimmpower *priv = (struct peci_dimmpower *)ctx;
+	union peci_dram_power_limit power_limit;
+	int ret;
+
+	ret = peci_pcs_get_units(priv->mgr, &priv->units, &priv->units_valid);
+	if (ret) {
+		dev_dbg(priv->dev, "not able to read units\n");
+		return ret;
+	}
+
+	ret = peci_dimmpower_read_dram_power_limit(priv->mgr, &power_limit);
+	if (ret) {
+		dev_dbg(priv->dev, "not able to read power limit\n");
+		return ret;
+	}
+
+	/* Calculate DPL time window if needed */
+	if (!priv->dpl_time_window_valid) {
+		priv->dpl_time_window =
+			peci_pcs_calc_plxy_time_window(peci_pcs_munits_to_xn(
+				PECI_PCS_PPL1_TIME_WINDOW,
+				priv->units.bits.tim_unit));
+		priv->dpl_time_window_valid = true;
+	}
+
+	/* Enable or disable power limitation */
+	if (val > 0) {
+		power_limit.bits.pp_pwr_lim =
+			peci_pcs_munits_to_xn(val, priv->units.bits.pwr_unit);
+		power_limit.bits.pwr_lim_ctrl_en = 1u;
+		power_limit.bits.ctrl_time_win = priv->dpl_time_window;
+	} else {
+		power_limit.bits.pp_pwr_lim = 0u;
+		power_limit.bits.pwr_lim_ctrl_en = 0u;
+		power_limit.bits.ctrl_time_win = 0u;
+	}
+
+	ret = peci_pcs_write(priv->mgr, PECI_MBX_INDEX_DDR_RAPL_PL1,
+			     PECI_PCS_PARAM_ZERO, power_limit.value);
+	if (ret) {
+		dev_dbg(priv->dev, "not able to write power limit\n");
+		return ret;
+	}
+
+	dev_dbg(priv->dev, "power limit %d, unit %u, raw power limit %u,\n",
+		val, priv->units.bits.pwr_unit, power_limit.bits.pp_pwr_lim);
+
+	return ret;
+}
+
+static int
+peci_dimmpower_read_max_power(void *ctx, struct peci_sensor_conf *sensor_conf,
+			      struct peci_sensor_data *sensor_data)
+{
+	struct peci_dimmpower *priv = (struct peci_dimmpower *)ctx;
+	union peci_dram_power_info_low power_info;
+	int ret = 0;
+
+	mutex_lock(&sensor_data->lock);
+	if (!peci_sensor_need_update_with_time(sensor_data,
+					       sensor_conf->update_interval)) {
+		dev_dbg(priv->dev, "skip reading peci, max power %dmW\n",
+			sensor_data->value);
+		goto unlock;
+	}
+
+	ret = peci_pcs_get_units(priv->mgr, &priv->units, &priv->units_valid);
+	if (ret) {
+		dev_dbg(priv->dev, "not able to read units\n");
+		goto unlock;
+	}
+
+	ret = peci_pcs_read(priv->mgr, PECI_MBX_INDEX_DDR_PWR_INFO_LOW,
+			    PECI_PCS_PARAM_ZERO, &power_info.value);
+	if (ret) {
+		dev_dbg(priv->dev, "not able to read power info\n");
+		goto unlock;
+	}
+
+	peci_sensor_mark_updated(sensor_data);
+	sensor_data->value = peci_pcs_xn_to_munits(power_info.bits.tdp,
+						   priv->units.bits.pwr_unit);
+
+	dev_dbg(priv->dev, "raw max power %u, unit %u, max power %dmW\n",
+		power_info.bits.tdp, priv->units.bits.pwr_unit,
+		sensor_data->value);
+unlock:
+	mutex_unlock(&sensor_data->lock);
+	return ret;
+}
+
+static int
+peci_dimmpower_read_min_power(void *ctx, struct peci_sensor_conf *sensor_conf,
+			      struct peci_sensor_data *sensor_data)
+{
+	struct peci_dimmpower *priv = (struct peci_dimmpower *)ctx;
+
+	/* DRAM_POWER_INFO.DRAM_MIN_PWR is no more supported in CPU starting from
+	 * SPR. So BIOS doesn't update this. That's why there is still default
+	 * value (15W) which doesn't make sense. There should be a case when
+	 * MAX_PWR/TDP is smaller than 15W.
+	 * 0 seems to be a reasonable value for that parameter.
+	 */
+	sensor_data->value = 0;
+	dev_dbg(priv->dev, "min power %dmW\n", sensor_data->value);
+	return 0;
+}
+
+static int
+peci_dimmpower_read_energy(void *ctx, struct peci_sensor_conf *sensor_conf,
+			   struct peci_sensor_data *sensor_data)
+{
+	struct peci_dimmpower *priv = (struct peci_dimmpower *)ctx;
+	int ret = 0;
+
+	mutex_lock(&sensor_data->lock);
+	if (!peci_sensor_need_update_with_time(sensor_data,
+					       sensor_conf->update_interval)) {
+		dev_dbg(priv->dev,
+			"skip generating new energy value %duJ jif %lu\n",
+			sensor_data->uvalue, jiffies);
+		goto unlock;
+	}
+
+	ret = peci_dimmpower_get_energy_counter(priv, &priv->energy_cache,
+						sensor_conf->update_interval);
+	if (ret) {
+		dev_dbg(priv->dev, "cannot update energy counter\n");
+		goto unlock;
+	}
+
+	ret = peci_pcs_get_units(priv->mgr, &priv->units, &priv->units_valid);
+	if (ret) {
+		dev_dbg(priv->dev, "not able to read units\n");
+		goto unlock;
+	}
+
+	ret = peci_pcs_calc_acc_eng(priv->dev,
+				    &priv->energy_sensor_prev_energy,
+				    &priv->energy_cache,
+				    priv->units.bits.eng_unit,
+				    &sensor_data->uvalue);
+
+	if (ret) {
+		dev_dbg(priv->dev, "cumulative energy calculation failed\n");
+		goto unlock;
+	}
+	peci_sensor_mark_updated_with_time(sensor_data,
+					   priv->energy_cache.last_updated);
+
+	dev_dbg(priv->dev, "energy %duJ, jif %lu, HZ is %d jiffies\n",
+		sensor_data->uvalue, sensor_data->last_updated, HZ);
+
+unlock:
+	mutex_unlock(&sensor_data->lock);
+	return ret;
+}
+
+static struct peci_sensor_conf
+peci_dimmpower_power_cfg[PECI_DIMMPOWER_POWER_CHANNEL_COUNT]
+			[PECI_DIMMPOWER_POWER_SENSOR_COUNT] = {
+	/* Channel 0  - Power */
+	{
+		{
+			.attribute = hwmon_power_average,
+			.config = HWMON_P_AVERAGE,
+			.update_interval = UPDATE_INTERVAL_100MS,
+			.read = peci_dimmpower_get_avg_power,
+			.write = NULL,
+		},
+		{
+			.attribute = hwmon_power_cap,
+			.config = HWMON_P_CAP,
+			.update_interval = UPDATE_INTERVAL_100MS,
+			.read = peci_dimmpower_get_power_limit,
+			.write = peci_dimmpower_set_power_limit,
+		},
+		{
+			.attribute = hwmon_power_cap_max,
+			.config = HWMON_P_CAP_MAX,
+			.update_interval = UPDATE_INTERVAL_10S,
+			.read = peci_dimmpower_read_max_power,
+			.write = NULL,
+		},
+		{
+			.attribute = hwmon_power_cap_min,
+			.config = HWMON_P_CAP_MIN,
+			.update_interval = UPDATE_INTERVAL_10S,
+			.read = peci_dimmpower_read_min_power,
+			.write = NULL,
+		},
+	},
+};
+
+static struct peci_sensor_conf
+peci_dimmpower_energy_cfg[PECI_DIMMPOWER_ENERGY_CHANNEL_COUNT]
+			 [PECI_DIMMPOWER_ENERGY_SENSOR_COUNT] = {
+	/* Channel 0  - Energy */
+	{
+		{
+			.attribute = hwmon_energy_input,
+			.config = HWMON_E_INPUT,
+			.update_interval = UPDATE_INTERVAL_100MS,
+			.read = peci_dimmpower_read_energy,
+			.write = NULL,
+		},
+	}
+};
+
+static bool
+peci_dimmpower_is_channel_valid(enum hwmon_sensor_types type,
+				int channel)
+{
+	if ((type == hwmon_power && channel < PECI_DIMMPOWER_POWER_CHANNEL_COUNT) ||
+	    (type == hwmon_energy && channel < PECI_DIMMPOWER_ENERGY_CHANNEL_COUNT))
+		return true;
+
+	return false;
+}
+
+static int
+peci_dimmpower_read_string(struct device *dev, enum hwmon_sensor_types type,
+			   u32 attr, int channel, const char **str)
+{
+	if (!peci_dimmpower_is_channel_valid(type, channel))
+		return -EOPNOTSUPP;
+
+	switch (attr) {
+	case hwmon_power_label:
+		*str = peci_dimmpower_labels[PECI_DIMMPOWER_SENSOR_TYPE_POWER];
+		break;
+	case hwmon_energy_label:
+		*str = peci_dimmpower_labels[PECI_DIMMPOWER_SENSOR_TYPE_ENERGY];
+		break;
+	default:
+		return -EOPNOTSUPP;
+	}
+
+	return 0;
+}
+
+static int
+peci_dimmpower_read(struct device *dev, enum hwmon_sensor_types type,
+		    u32 attr, int channel, long *val)
+{
+	struct peci_dimmpower *priv = dev_get_drvdata(dev);
+	struct peci_sensor_conf *sensor_conf;
+	struct peci_sensor_data *sensor_data;
+	int ret;
+
+	if (!priv || !val)
+		return -EINVAL;
+
+	if (!peci_dimmpower_is_channel_valid(type, channel))
+		return -EOPNOTSUPP;
+
+	switch (type) {
+	case hwmon_power:
+		ret = peci_sensor_get_ctx(attr, peci_dimmpower_power_cfg[channel],
+					  &sensor_conf,
+					  priv->power_sensor_data_list[channel],
+					  &sensor_data,
+					  ARRAY_SIZE(peci_dimmpower_power_cfg[channel]));
+		break;
+	case hwmon_energy:
+		ret = peci_sensor_get_ctx(attr, peci_dimmpower_energy_cfg[channel],
+					  &sensor_conf,
+					  priv->energy_sensor_data_list[channel],
+					  &sensor_data,
+					  ARRAY_SIZE(peci_dimmpower_energy_cfg[channel]));
+		break;
+	default:
+		ret = -EOPNOTSUPP;
+	}
+
+	if (ret)
+		return ret;
+
+	if (sensor_conf->read) {
+		ret = sensor_conf->read(priv, sensor_conf, sensor_data);
+		if (!ret)
+			*val = (long)sensor_data->value;
+	} else {
+		ret = -EOPNOTSUPP;
+	}
+
+	return ret;
+}
+
+static int
+peci_dimmpower_write(struct device *dev, enum hwmon_sensor_types type,
+		     u32 attr, int channel, long val)
+{
+	struct peci_dimmpower *priv = dev_get_drvdata(dev);
+	struct peci_sensor_conf *sensor_conf;
+	struct peci_sensor_data *sensor_data;
+	int ret;
+
+	if (!priv)
+		return -EINVAL;
+
+	if (!peci_dimmpower_is_channel_valid(type, channel))
+		return -EOPNOTSUPP;
+
+	switch (type) {
+	case hwmon_power:
+		ret = peci_sensor_get_ctx(attr, peci_dimmpower_power_cfg[channel],
+					  &sensor_conf,
+					  priv->power_sensor_data_list[channel],
+					  &sensor_data,
+					  ARRAY_SIZE(peci_dimmpower_power_cfg[channel]));
+		break;
+	case hwmon_energy:
+		ret = peci_sensor_get_ctx(attr, peci_dimmpower_energy_cfg[channel],
+					  &sensor_conf,
+					  priv->energy_sensor_data_list[channel],
+					  &sensor_data,
+					  ARRAY_SIZE(peci_dimmpower_energy_cfg[channel]));
+		break;
+	default:
+		ret = -EOPNOTSUPP;
+	}
+
+	if (ret)
+		return ret;
+
+	if (sensor_conf->write) {
+		ret = sensor_conf->write(priv, sensor_conf, sensor_data,
+					 (s32)val);
+	} else {
+		ret = -EOPNOTSUPP;
+	}
+
+	return ret;
+}
+
+static umode_t
+peci_dimmpower_is_visible(const void *data, enum hwmon_sensor_types type,
+			  u32 attr, int channel)
+{
+	struct peci_sensor_conf *sensor_conf;
+	umode_t mode = 0;
+	int ret;
+
+	if (!peci_dimmpower_is_channel_valid(type, channel))
+		return mode;
+
+	if (attr == hwmon_power_label || attr == hwmon_energy_label)
+		return 0444;
+
+	switch (type) {
+	case hwmon_power:
+		ret = peci_sensor_get_ctx(attr, peci_dimmpower_power_cfg[channel],
+					  &sensor_conf, NULL, NULL,
+					  ARRAY_SIZE(peci_dimmpower_power_cfg[channel]));
+		break;
+	case hwmon_energy:
+		ret = peci_sensor_get_ctx(attr, peci_dimmpower_energy_cfg[channel],
+					  &sensor_conf, NULL, NULL,
+					  ARRAY_SIZE(peci_dimmpower_energy_cfg[channel]));
+		break;
+	default:
+		return mode;
+	}
+
+	if (!ret) {
+		if (sensor_conf->read)
+			mode |= 0444;
+		if (sensor_conf->write)
+			mode |= 0200;
+	}
+
+	return mode;
+}
+
+static const struct hwmon_ops peci_dimmpower_ops = {
+	.is_visible = peci_dimmpower_is_visible,
+	.read_string = peci_dimmpower_read_string,
+	.read = peci_dimmpower_read,
+	.write = peci_dimmpower_write,
+};
+
+static void peci_dimmpower_sensor_init(struct peci_dimmpower *priv)
+{
+	int i, j;
+
+	mutex_init(&priv->energy_cache.lock);
+
+	for (i = 0; i < PECI_DIMMPOWER_POWER_CHANNEL_COUNT; i++) {
+		for (j = 0; j < PECI_DIMMPOWER_POWER_SENSOR_COUNT; j++)
+			mutex_init(&priv->power_sensor_data_list[i][j].lock);
+	}
+
+	for (i = 0; i < PECI_DIMMPOWER_ENERGY_CHANNEL_COUNT; i++) {
+		for (j = 0; j < PECI_DIMMPOWER_ENERGY_SENSOR_COUNT; j++)
+			mutex_init(&priv->energy_sensor_data_list[i][j].lock);
+	}
+}
+
+static int peci_dimmpower_probe(struct platform_device *pdev)
+{
+	struct peci_client_manager *mgr = dev_get_drvdata(pdev->dev.parent);
+	struct device *dev = &pdev->dev;
+	struct peci_dimmpower *priv;
+	struct device *hwmon_dev;
+	u32 power_config_idx = 0;
+	u32 energy_config_idx = 0;
+	u32 cmd_mask;
+
+	cmd_mask = BIT(PECI_CMD_RD_PKG_CFG) | BIT(PECI_CMD_WR_PKG_CFG);
+	if ((mgr->client->adapter->cmd_mask & cmd_mask) != cmd_mask)
+		return -ENODEV;
+
+	priv = devm_kzalloc(dev, sizeof(*priv), GFP_KERNEL);
+	if (!priv)
+		return -ENOMEM;
+
+	dev_set_drvdata(dev, priv);
+	priv->mgr = mgr;
+	priv->dev = dev;
+
+	snprintf(priv->name, PECI_NAME_SIZE, "peci_dimmpower.cpu%d.%d",
+		 mgr->client->addr - PECI_BASE_ADDR, mgr->client->domain_id);
+
+	priv->power_config[power_config_idx] = HWMON_P_LABEL |
+		peci_sensor_get_config(peci_dimmpower_power_cfg[power_config_idx],
+				       ARRAY_SIZE(peci_dimmpower_power_cfg[power_config_idx]));
+
+	priv->energy_config[energy_config_idx] = HWMON_E_LABEL |
+		peci_sensor_get_config(peci_dimmpower_energy_cfg[energy_config_idx],
+				       ARRAY_SIZE(peci_dimmpower_energy_cfg[energy_config_idx]));
+
+	priv->info[PECI_DIMMPOWER_SENSOR_TYPE_POWER] = &priv->power_info;
+	priv->power_info.type = hwmon_power;
+	priv->power_info.config = priv->power_config;
+
+	priv->info[PECI_DIMMPOWER_SENSOR_TYPE_ENERGY] = &priv->energy_info;
+	priv->energy_info.type = hwmon_energy;
+	priv->energy_info.config = priv->energy_config;
+
+	priv->chip.ops = &peci_dimmpower_ops;
+	priv->chip.info = priv->info;
+
+	peci_dimmpower_sensor_init(priv);
+
+	hwmon_dev = devm_hwmon_device_register_with_info(priv->dev, priv->name,
+							 priv, &priv->chip,
+							 NULL);
+
+	if (IS_ERR(hwmon_dev))
+		return PTR_ERR(hwmon_dev);
+
+	dev_dbg(dev, "%s: sensor '%s'\n", dev_name(hwmon_dev), priv->name);
+
+	return 0;
+}
+
+static const struct platform_device_id peci_dimmpower_ids[] = {
+	{ .name = "peci-dimmpower", .driver_data = 0 },
+	{ }
+};
+MODULE_DEVICE_TABLE(platform, peci_dimmpower_ids);
+
+static struct platform_driver peci_dimmpower_driver = {
+	.probe    = peci_dimmpower_probe,
+	.id_table = peci_dimmpower_ids,
+	.driver   = { .name = KBUILD_MODNAME, },
+};
+module_platform_driver(peci_dimmpower_driver);
+
+MODULE_AUTHOR("Zbigniew Lukwinski <zbigniew.lukwinski@linux.intel.com>");
+MODULE_DESCRIPTION("PECI dimmpower driver");
+MODULE_LICENSE("GPL v2");
diff --git a/drivers/hwmon/peci-dimmtemp.c b/drivers/hwmon/peci-dimmtemp.c
new file mode 100644
index 000000000000..456991169716
--- /dev/null
+++ b/drivers/hwmon/peci-dimmtemp.c
@@ -0,0 +1,554 @@
+// SPDX-License-Identifier: GPL-2.0
+// Copyright (c) 2018-2019 Intel Corporation
+
+#include <linux/hwmon.h>
+#include <linux/jiffies.h>
+#include <linux/mfd/intel-peci-client.h>
+#include <linux/module.h>
+#include <linux/of_device.h>
+#include <linux/platform_device.h>
+#include <linux/workqueue.h>
+#include "peci-hwmon.h"
+
+#define DIMM_MASK_CHECK_DELAY_JIFFIES	msecs_to_jiffies(5000)
+#define DIMM_MASK_CHECK_RETRY_MAX	-1 /* 60 x 5 secs = 5 minutes */
+					   /* -1 = no timeout */
+#define DIMM_TEMP_MAX_DEFAULT		90000
+#define DIMM_TEMP_CRIT_DEFAULT		100000
+#define BIOS_RST_CPL4			BIT(4)
+
+struct peci_dimmtemp {
+	struct peci_client_manager	*mgr;
+	struct device			*dev;
+	char				name[PECI_NAME_SIZE];
+	const struct cpu_gen_info	*gen_info;
+	struct workqueue_struct		*work_queue;
+	struct delayed_work		work_handler;
+	struct peci_sensor_data		temp[DIMM_NUMS_MAX];
+	long				temp_max[DIMM_NUMS_MAX];
+	long				temp_crit[DIMM_NUMS_MAX];
+	u32				dimm_mask;
+	int				retry_count;
+	u32				temp_config[DIMM_NUMS_MAX + 1];
+	struct hwmon_channel_info	temp_info;
+	const struct hwmon_channel_info	*info[2];
+	struct hwmon_chip_info		chip;
+	char				**dimmtemp_label;
+};
+
+static const u8 support_model[] = {
+	INTEL_FAM6_HASWELL_X,
+	INTEL_FAM6_BROADWELL_X,
+	INTEL_FAM6_SKYLAKE_X,
+	INTEL_FAM6_SKYLAKE_XD,
+	INTEL_FAM6_ICELAKE_X,
+	INTEL_FAM6_ICELAKE_XD,
+};
+
+static inline int read_ddr_dimm_temp_config(struct peci_dimmtemp *priv,
+					    int chan_rank,
+					    u8 *cfg_data)
+{
+	return peci_client_read_package_config(priv->mgr,
+					       PECI_MBX_INDEX_DDR_DIMM_TEMP,
+					       chan_rank, cfg_data);
+}
+
+static int get_dimm_temp(struct peci_dimmtemp *priv, int dimm_no)
+{
+	int dimm_order = dimm_no % priv->gen_info->dimm_idx_max;
+	int chan_rank = dimm_no / priv->gen_info->dimm_idx_max;
+	struct peci_rd_pci_cfg_local_msg rp_msg;
+	struct peci_rd_end_pt_cfg_msg re_msg;
+	u32 bios_reset_cpl_cfg;
+	u8  cfg_data[4];
+	u8  cpu_seg, cpu_bus;
+	int ret;
+
+	if (!peci_sensor_need_update(&priv->temp[dimm_no]))
+		return 0;
+
+	ret = read_ddr_dimm_temp_config(priv, chan_rank, cfg_data);
+	if (ret || cfg_data[dimm_order] == 0 || cfg_data[dimm_order] == 0xff)
+		return -ENODATA;
+
+	priv->temp[dimm_no].value = cfg_data[dimm_order] * 1000;
+
+	/*
+	 * CPU can return invalid temperatures prior to BIOS-PCU handshake
+	 * RST_CPL4 completion so filter the invalid readings out.
+	 */
+	switch (priv->gen_info->model) {
+	case INTEL_FAM6_ICELAKE_X:
+	case INTEL_FAM6_ICELAKE_XD:
+		re_msg.addr = priv->mgr->client->addr;
+		re_msg.msg_type = PECI_ENDPTCFG_TYPE_LOCAL_PCI;
+		re_msg.params.pci_cfg.seg = 0;
+		re_msg.params.pci_cfg.bus = 31;
+		re_msg.params.pci_cfg.device = 30;
+		re_msg.params.pci_cfg.function = 1;
+		re_msg.params.pci_cfg.reg = 0x94;
+		re_msg.rx_len = 4;
+		re_msg.domain_id = priv->mgr->client->domain_id;
+
+		ret = peci_command(priv->mgr->client->adapter,
+				   PECI_CMD_RD_END_PT_CFG, sizeof(re_msg), &re_msg);
+		if (ret || re_msg.cc != PECI_DEV_CC_SUCCESS)
+			ret = -EAGAIN;
+		if (ret)
+			return ret;
+
+		bios_reset_cpl_cfg = le32_to_cpup((__le32 *)re_msg.data);
+		if (!(bios_reset_cpl_cfg & BIOS_RST_CPL4)) {
+			dev_dbg(priv->dev, "DRAM parameters aren't calibrated, BIOS_RESET_CPL_CFG: 0x%x\n",
+				bios_reset_cpl_cfg);
+			return -EAGAIN;
+		}
+
+		break;
+	default:
+		/* TODO: Check reset completion for other CPUs if needed */
+		break;
+	}
+
+	switch (priv->gen_info->model) {
+	case INTEL_FAM6_ICELAKE_X:
+	case INTEL_FAM6_ICELAKE_XD:
+		re_msg.addr = priv->mgr->client->addr;
+		re_msg.rx_len = 4;
+		re_msg.msg_type = PECI_ENDPTCFG_TYPE_LOCAL_PCI;
+		re_msg.params.pci_cfg.seg = 0;
+		re_msg.params.pci_cfg.bus = 13;
+		re_msg.params.pci_cfg.device = 0;
+		re_msg.params.pci_cfg.function = 2;
+		re_msg.params.pci_cfg.reg = 0xd4;
+		re_msg.domain_id = priv->mgr->client->domain_id;
+
+		ret = peci_command(priv->mgr->client->adapter,
+				   PECI_CMD_RD_END_PT_CFG, sizeof(re_msg), &re_msg);
+		if (ret || re_msg.cc != PECI_DEV_CC_SUCCESS ||
+		    !(re_msg.data[3] & BIT(7))) {
+			/* Use default or previous value */
+			ret = 0;
+			break;
+		}
+
+		re_msg.msg_type = PECI_ENDPTCFG_TYPE_LOCAL_PCI;
+		re_msg.params.pci_cfg.reg = 0xd0;
+
+		ret = peci_command(priv->mgr->client->adapter,
+				   PECI_CMD_RD_END_PT_CFG, sizeof(re_msg), &re_msg);
+		if (ret || re_msg.cc != PECI_DEV_CC_SUCCESS) {
+			/* Use default or previous value */
+			ret = 0;
+			break;
+		}
+
+		cpu_seg = re_msg.data[2];
+		cpu_bus = re_msg.data[0];
+
+		re_msg.addr = priv->mgr->client->addr;
+		re_msg.msg_type = PECI_ENDPTCFG_TYPE_MMIO;
+		re_msg.params.mmio.seg = cpu_seg;
+		re_msg.params.mmio.bus = cpu_bus;
+		/*
+		 * Device 26, Offset 224e0: IMC 0 channel 0 -> rank 0
+		 * Device 26, Offset 264e0: IMC 0 channel 1 -> rank 1
+		 * Device 27, Offset 224e0: IMC 1 channel 0 -> rank 2
+		 * Device 27, Offset 264e0: IMC 1 channel 1 -> rank 3
+		 * Device 28, Offset 224e0: IMC 2 channel 0 -> rank 4
+		 * Device 28, Offset 264e0: IMC 2 channel 1 -> rank 5
+		 * Device 29, Offset 224e0: IMC 3 channel 0 -> rank 6
+		 * Device 29, Offset 264e0: IMC 3 channel 1 -> rank 7
+		 */
+		re_msg.params.mmio.device = 0x1a + chan_rank / 2;
+		re_msg.params.mmio.function = 0;
+		re_msg.params.mmio.bar = 0;
+		re_msg.params.mmio.addr_type = PECI_ENDPTCFG_ADDR_TYPE_MMIO_Q;
+		re_msg.params.mmio.offset = 0x224e0 + dimm_order * 4;
+		if (chan_rank % 2)
+			re_msg.params.mmio.offset += 0x4000;
+
+		ret = peci_command(priv->mgr->client->adapter,
+				   PECI_CMD_RD_END_PT_CFG, sizeof(re_msg), &re_msg);
+		if (ret || re_msg.cc != PECI_DEV_CC_SUCCESS ||
+		    re_msg.data[1] == 0 || re_msg.data[2] == 0) {
+			/* Use default or previous value */
+			ret = 0;
+			break;
+		}
+
+		priv->temp_max[dimm_no] = re_msg.data[1] * 1000;
+		priv->temp_crit[dimm_no] = re_msg.data[2] * 1000;
+		break;
+	case INTEL_FAM6_SKYLAKE_X:
+		rp_msg.addr = priv->mgr->client->addr;
+		rp_msg.bus = 2;
+		/*
+		 * Device 10, Function 2: IMC 0 channel 0 -> rank 0
+		 * Device 10, Function 6: IMC 0 channel 1 -> rank 1
+		 * Device 11, Function 2: IMC 0 channel 2 -> rank 2
+		 * Device 12, Function 2: IMC 1 channel 0 -> rank 3
+		 * Device 12, Function 6: IMC 1 channel 1 -> rank 4
+		 * Device 13, Function 2: IMC 1 channel 2 -> rank 5
+		 */
+		rp_msg.device = 10 + chan_rank / 3 * 2 +
+			     (chan_rank % 3 == 2 ? 1 : 0);
+		rp_msg.function = chan_rank % 3 == 1 ? 6 : 2;
+		rp_msg.reg = 0x120 + dimm_order * 4;
+		rp_msg.rx_len = 4;
+
+		ret = peci_command(priv->mgr->client->adapter,
+				   PECI_CMD_RD_PCI_CFG_LOCAL, sizeof(rp_msg), &rp_msg);
+		if (ret || rp_msg.cc != PECI_DEV_CC_SUCCESS ||
+		    rp_msg.pci_config[1] == 0 || rp_msg.pci_config[2] == 0) {
+			/* Use default or previous value */
+			ret = 0;
+			break;
+		}
+
+		priv->temp_max[dimm_no] = rp_msg.pci_config[1] * 1000;
+		priv->temp_crit[dimm_no] = rp_msg.pci_config[2] * 1000;
+		break;
+	case INTEL_FAM6_SKYLAKE_XD:
+		rp_msg.addr = priv->mgr->client->addr;
+		rp_msg.bus = 2;
+		/*
+		 * Device 10, Function 2: IMC 0 channel 0 -> rank 0
+		 * Device 10, Function 6: IMC 0 channel 1 -> rank 1
+		 * Device 12, Function 2: IMC 1 channel 0 -> rank 2
+		 * Device 12, Function 6: IMC 1 channel 1 -> rank 3
+		 */
+		rp_msg.device = 10 + chan_rank / 2 * 2;
+		rp_msg.function = (chan_rank % 2) ? 6 : 2;
+		rp_msg.reg = 0x120 + dimm_order * 4;
+		rp_msg.rx_len = 4;
+
+		ret = peci_command(priv->mgr->client->adapter,
+				   PECI_CMD_RD_PCI_CFG_LOCAL, sizeof(rp_msg), &rp_msg);
+		if (ret || rp_msg.cc != PECI_DEV_CC_SUCCESS ||
+		    rp_msg.pci_config[1] == 0 || rp_msg.pci_config[2] == 0) {
+			/* Use default or previous value */
+			ret = 0;
+			break;
+		}
+
+		priv->temp_max[dimm_no] = rp_msg.pci_config[1] * 1000;
+		priv->temp_crit[dimm_no] = rp_msg.pci_config[2] * 1000;
+		break;
+	case INTEL_FAM6_HASWELL_X:
+	case INTEL_FAM6_BROADWELL_X:
+		rp_msg.addr = priv->mgr->client->addr;
+		rp_msg.bus = 1;
+		/*
+		 * Device 20, Function 0: IMC 0 channel 0 -> rank 0
+		 * Device 20, Function 1: IMC 0 channel 1 -> rank 1
+		 * Device 21, Function 0: IMC 0 channel 2 -> rank 2
+		 * Device 21, Function 1: IMC 0 channel 3 -> rank 3
+		 * Device 23, Function 0: IMC 1 channel 0 -> rank 4
+		 * Device 23, Function 1: IMC 1 channel 1 -> rank 5
+		 * Device 24, Function 0: IMC 1 channel 2 -> rank 6
+		 * Device 24, Function 1: IMC 1 channel 3 -> rank 7
+		 */
+		rp_msg.device = 20 + chan_rank / 2 + chan_rank / 4;
+		rp_msg.function = chan_rank % 2;
+		rp_msg.reg = 0x120 + dimm_order * 4;
+		rp_msg.rx_len = 4;
+
+		ret = peci_command(priv->mgr->client->adapter,
+				   PECI_CMD_RD_PCI_CFG_LOCAL, sizeof(rp_msg), &rp_msg);
+		if (ret || rp_msg.cc != PECI_DEV_CC_SUCCESS ||
+		    rp_msg.pci_config[1] == 0 || rp_msg.pci_config[2] == 0) {
+			/* Use default or previous value */
+			ret = 0;
+			break;
+		}
+
+		priv->temp_max[dimm_no] = rp_msg.pci_config[1] * 1000;
+		priv->temp_crit[dimm_no] = rp_msg.pci_config[2] * 1000;
+		break;
+	default:
+		return -EOPNOTSUPP;
+	}
+
+	peci_sensor_mark_updated(&priv->temp[dimm_no]);
+
+	return 0;
+}
+
+static int dimmtemp_read_string(struct device *dev,
+				enum hwmon_sensor_types type,
+				u32 attr, int channel, const char **str)
+{
+	struct peci_dimmtemp *priv = dev_get_drvdata(dev);
+
+	if (attr != hwmon_temp_label)
+		return -EOPNOTSUPP;
+
+	*str = (const char *)priv->dimmtemp_label[channel];
+
+	return 0;
+}
+
+static int dimmtemp_read(struct device *dev, enum hwmon_sensor_types type,
+			 u32 attr, int channel, long *val)
+{
+	struct peci_dimmtemp *priv = dev_get_drvdata(dev);
+	int ret;
+
+	ret = get_dimm_temp(priv, channel);
+	if (ret)
+		return ret;
+
+	switch (attr) {
+	case hwmon_temp_input:
+		*val = priv->temp[channel].value;
+		break;
+	case hwmon_temp_max:
+		*val = priv->temp_max[channel];
+		break;
+	case hwmon_temp_crit:
+		*val = priv->temp_crit[channel];
+		break;
+	default:
+		ret = -EOPNOTSUPP;
+		break;
+	}
+
+	return ret;
+}
+
+static umode_t dimmtemp_is_visible(const void *data,
+				   enum hwmon_sensor_types type,
+				   u32 attr, int channel)
+{
+	const struct peci_dimmtemp *priv = data;
+
+	if (priv->temp_config[channel] & BIT(attr) &&
+	    priv->dimm_mask & BIT(channel))
+		return 0444;
+
+	return 0;
+}
+
+static const struct hwmon_ops dimmtemp_ops = {
+	.is_visible = dimmtemp_is_visible,
+	.read_string = dimmtemp_read_string,
+	.read = dimmtemp_read,
+};
+
+static int check_populated_dimms(struct peci_dimmtemp *priv)
+{
+	u32 chan_rank_max = priv->gen_info->chan_rank_max;
+	u32 dimm_idx_max = priv->gen_info->dimm_idx_max;
+	int chan_rank;
+	u8  cfg_data[4];
+
+	for (chan_rank = 0; chan_rank < chan_rank_max; chan_rank++) {
+		int ret, idx;
+
+		ret = read_ddr_dimm_temp_config(priv, chan_rank, cfg_data);
+		if (ret) {
+			if (ret == -EAGAIN)
+				continue;
+
+			priv->dimm_mask = 0;
+			return ret;
+		}
+
+		for (idx = 0; idx < dimm_idx_max; idx++) {
+			if (cfg_data[idx]) {
+				uint chan = chan_rank * dimm_idx_max + idx;
+				priv->dimm_mask |= BIT(chan);
+				priv->temp_max[chan] = DIMM_TEMP_MAX_DEFAULT;
+				priv->temp_crit[chan] = DIMM_TEMP_CRIT_DEFAULT;
+			}
+		}
+	}
+
+	if (!priv->dimm_mask)
+		return -EAGAIN;
+
+	dev_dbg(priv->dev, "Scanned populated DIMMs: 0x%x\n", priv->dimm_mask);
+
+	return 0;
+}
+
+static int create_dimm_temp_label(struct peci_dimmtemp *priv, int chan)
+{
+	int rank, idx;
+
+	priv->dimmtemp_label[chan] = devm_kzalloc(priv->dev,
+						  PECI_HWMON_LABEL_STR_LEN,
+						  GFP_KERNEL);
+	if (!priv->dimmtemp_label[chan])
+		return -ENOMEM;
+
+	rank = chan / priv->gen_info->dimm_idx_max;
+	idx = chan % priv->gen_info->dimm_idx_max;
+
+	snprintf(priv->dimmtemp_label[chan], PECI_HWMON_LABEL_STR_LEN,
+		 "DIMM %c%d", 'A' + rank, idx + 1);
+
+	return 0;
+}
+
+static int create_dimm_temp_info(struct peci_dimmtemp *priv)
+{
+	int ret, i, config_idx, channels;
+	struct device *dev;
+
+	ret = check_populated_dimms(priv);
+	if (ret) {
+		if (ret == -EAGAIN) {
+			if (DIMM_MASK_CHECK_RETRY_MAX == -1 ||
+			    priv->retry_count < DIMM_MASK_CHECK_RETRY_MAX) {
+				queue_delayed_work(priv->work_queue,
+						   &priv->work_handler,
+						 DIMM_MASK_CHECK_DELAY_JIFFIES);
+				priv->retry_count++;
+				dev_dbg(priv->dev,
+					"Deferred DIMM temp info creation\n");
+			} else {
+				dev_err(priv->dev,
+					"Timeout DIMM temp info creation\n");
+				ret = -ETIMEDOUT;
+			}
+		}
+
+		return ret;
+	}
+
+	channels = priv->gen_info->chan_rank_max *
+		   priv->gen_info->dimm_idx_max;
+
+	priv->dimmtemp_label = devm_kzalloc(priv->dev,
+					    channels * sizeof(char *),
+					    GFP_KERNEL);
+	if (!priv->dimmtemp_label)
+		return -ENOMEM;
+
+	for (i = 0, config_idx = 0; i < channels; i++)
+		if (priv->dimm_mask & BIT(i)) {
+			while (i >= config_idx)
+				priv->temp_config[config_idx++] =
+					HWMON_T_LABEL | HWMON_T_INPUT |
+					HWMON_T_MAX | HWMON_T_CRIT;
+
+			ret = create_dimm_temp_label(priv, i);
+			if (ret)
+				return ret;
+		}
+
+	priv->chip.ops = &dimmtemp_ops;
+	priv->chip.info = priv->info;
+
+	priv->info[0] = &priv->temp_info;
+
+	priv->temp_info.type = hwmon_temp;
+	priv->temp_info.config = priv->temp_config;
+
+	dev = devm_hwmon_device_register_with_info(priv->dev,
+						   priv->name,
+						   priv,
+						   &priv->chip,
+						   NULL);
+	if (IS_ERR(dev)) {
+		dev_err(priv->dev, "Failed to register hwmon device\n");
+		return PTR_ERR(dev);
+	}
+
+	dev_dbg(priv->dev, "%s: sensor '%s'\n", dev_name(dev), priv->name);
+
+	return 0;
+}
+
+static void create_dimm_temp_info_delayed(struct work_struct *work)
+{
+	struct delayed_work *dwork = to_delayed_work(work);
+	struct peci_dimmtemp *priv = container_of(dwork, struct peci_dimmtemp,
+						  work_handler);
+	int ret;
+
+	ret = create_dimm_temp_info(priv);
+	if (ret && ret != -EAGAIN)
+		dev_dbg(priv->dev, "Failed to create DIMM temp info\n");
+}
+
+static int peci_dimmtemp_probe(struct platform_device *pdev)
+{
+	struct peci_client_manager *mgr = dev_get_drvdata(pdev->dev.parent);
+	struct device *dev = &pdev->dev;
+	struct peci_dimmtemp *priv;
+	int ret, i;
+
+	if ((mgr->client->adapter->cmd_mask &
+	    (BIT(PECI_CMD_GET_TEMP) | BIT(PECI_CMD_RD_PKG_CFG))) !=
+	    (BIT(PECI_CMD_GET_TEMP) | BIT(PECI_CMD_RD_PKG_CFG)))
+		return -ENODEV;
+
+	for (i = 0; i < ARRAY_SIZE(support_model); i++) {
+		if (mgr->gen_info->model == support_model[i])
+			break;
+	}
+	if (i == ARRAY_SIZE(support_model))
+		return -ENODEV;
+
+	priv = devm_kzalloc(dev, sizeof(*priv), GFP_KERNEL);
+	if (!priv)
+		return -ENOMEM;
+
+	dev_set_drvdata(dev, priv);
+	priv->mgr = mgr;
+	priv->dev = dev;
+	priv->gen_info = mgr->gen_info;
+
+	snprintf(priv->name, PECI_NAME_SIZE, "peci_dimmtemp.cpu%d.%d",
+		 mgr->client->addr - PECI_BASE_ADDR, mgr->client->domain_id);
+
+	priv->work_queue = alloc_ordered_workqueue(priv->name, 0);
+	if (!priv->work_queue)
+		return -ENOMEM;
+
+	INIT_DELAYED_WORK(&priv->work_handler, create_dimm_temp_info_delayed);
+
+	ret = create_dimm_temp_info(priv);
+	if (ret && ret != -EAGAIN) {
+		dev_dbg(dev, "Failed to create DIMM temp info\n");
+		goto err_free_wq;
+	}
+
+	return 0;
+
+err_free_wq:
+	destroy_workqueue(priv->work_queue);
+	return ret;
+}
+
+static int peci_dimmtemp_remove(struct platform_device *pdev)
+{
+	struct peci_dimmtemp *priv = dev_get_drvdata(&pdev->dev);
+
+	cancel_delayed_work_sync(&priv->work_handler);
+	destroy_workqueue(priv->work_queue);
+
+	return 0;
+}
+
+static const struct platform_device_id peci_dimmtemp_ids[] = {
+	{ .name = "peci-dimmtemp", .driver_data = 0 },
+	{ }
+};
+MODULE_DEVICE_TABLE(platform, peci_dimmtemp_ids);
+
+static struct platform_driver peci_dimmtemp_driver = {
+	.probe		= peci_dimmtemp_probe,
+	.remove		= peci_dimmtemp_remove,
+	.id_table	= peci_dimmtemp_ids,
+	.driver		= { .name = KBUILD_MODNAME, },
+};
+module_platform_driver(peci_dimmtemp_driver);
+
+MODULE_AUTHOR("Jae Hyun Yoo <jae.hyun.yoo@linux.intel.com>");
+MODULE_DESCRIPTION("PECI dimmtemp driver");
+MODULE_LICENSE("GPL v2");
diff --git a/drivers/hwmon/peci-hwmon.h b/drivers/hwmon/peci-hwmon.h
new file mode 100644
index 000000000000..c6947346cf77
--- /dev/null
+++ b/drivers/hwmon/peci-hwmon.h
@@ -0,0 +1,659 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/* Copyright (c) 2018-2020 Intel Corporation */
+
+#ifndef __PECI_HWMON_H
+#define __PECI_HWMON_H
+
+#include <linux/peci.h>
+#include <asm/div64.h>
+
+#define TEMP_TYPE_PECI			6 /* Sensor type 6: Intel PECI */
+#define UPDATE_INTERVAL_DEFAULT		HZ
+#define UPDATE_INTERVAL_100MS		(HZ / 10)
+#define UPDATE_INTERVAL_10S		(HZ * 10)
+
+#define PECI_HWMON_LABEL_STR_LEN	10
+
+/**
+ * struct peci_sensor_data - PECI sensor information
+ * @valid: flag to indicate the sensor value is valid
+ * @value: sensor value in milli units
+ * @last_updated: time of the last update in jiffies
+ */
+struct peci_sensor_data {
+	uint valid;
+	union {
+		s32 value;
+		u32 uvalue;
+	};
+	ulong last_updated;
+	struct mutex lock; /* protect sensor access */
+};
+
+/**
+ * peci_sensor_need_update - check whether sensor update is needed or not
+ * @sensor: pointer to sensor data struct
+ *
+ * Return: true if update is needed, false if not.
+ */
+static inline bool peci_sensor_need_update(struct peci_sensor_data *sensor)
+{
+	return !sensor->valid ||
+	       time_after(jiffies,
+			  sensor->last_updated + UPDATE_INTERVAL_DEFAULT);
+}
+
+/**
+ * peci_sensor_need_update_with_time - check whether sensor update is needed
+ * or not
+ * @sensor: pointer to sensor data struct
+ * @update_interval: update interval to check
+ *
+ * Return: true if update is needed, false if not.
+ */
+static inline bool
+peci_sensor_need_update_with_time(struct peci_sensor_data *sensor,
+				  ulong update_interval)
+{
+	return !sensor->valid ||
+	       time_after(jiffies, sensor->last_updated + update_interval);
+}
+
+/**
+ * peci_sensor_mark_updated - mark the sensor is updated
+ * @sensor: pointer to sensor data struct
+ */
+static inline void peci_sensor_mark_updated(struct peci_sensor_data *sensor)
+{
+	sensor->valid = 1;
+	sensor->last_updated = jiffies;
+}
+
+/**
+ * peci_sensor_mark_updated_with_time - mark the sensor is updated
+ * @sensor: pointer to sensor data struct
+ * @jif: jiffies value to update with
+ */
+static inline void
+peci_sensor_mark_updated_with_time(struct peci_sensor_data *sensor, ulong jif)
+{
+	sensor->valid = 1;
+	sensor->last_updated = jif;
+}
+
+/**
+ * struct peci_sensor_conf - PECI sensor information
+ * @attribute: Sensor attribute
+ * @config: Part of channel parameters brought by single sensor
+ * @update_interval: time in jiffies needs to elapse to read sensor again
+ * @read:	Read callback for data attributes. Mandatory if readable
+ *		data attributes are present.
+ *		Parameters are:
+ *		@module_ctx:	Pointer peci module context
+ *		@sensor_conf:	Pointer to sensor configuration object
+ *		@sensor_data:	Pointer to sensor data object
+ *		@val:	Pointer to returned value
+ *		The function returns 0 on success or a negative error number.
+ * @write:	Write callback for data attributes. Mandatory if writeable
+ *		data attributes are present.
+ *		Parameters are:
+ *		@module_ctx:	Pointer peci module context
+ *		@sensor_conf:	Pointer to sensor configuration object
+ *		@sensor_data:	Pointer to sensor data object
+ *		@val:	Value to write
+ *		The function returns 0 on success or a negative error number.
+ */
+struct peci_sensor_conf {
+	const s32 attribute;
+	const u32 config;
+	const ulong update_interval;
+
+	int (*const read)(void *priv, struct peci_sensor_conf *sensor_conf,
+			  struct peci_sensor_data *sensor_data);
+	int (*const write)(void *priv, struct peci_sensor_conf *sensor_conf,
+			   struct peci_sensor_data *sensor_data, s32 val);
+};
+
+/**
+ * peci_sensor_get_config - get peci sensor configuration for provided channel
+ * @sensors: Sensors list
+ * @sensor_count: Sensors count
+ *
+ * Return: sensor configuration
+ */
+static inline u32 peci_sensor_get_config(struct peci_sensor_conf sensors[],
+					 u8 sensor_count)
+{
+	u32 config = 0u;
+	int iter;
+
+	for (iter = 0; iter < sensor_count; ++iter)
+		config |= sensors[iter].config;
+
+	return config;
+}
+
+/**
+ * peci_sensor_get_ctx - get peci sensor context - both configuration and data
+ * @attribute: Sensor attribute
+ * @sensor_conf_list: Sensors configuration object list
+ * @sensor_conf: Sensor configuration object found
+ * @sensor_data_list: Sensors data object list, maybe NULL in case there is no
+ *		need to find sensor data object
+ * @sensor_data: Sensor data object found, maybe NULL in case there is no need
+ *		to find sensor data object
+ * @sensor_count: Sensor count
+ *
+ * Return: 0 on success or -EOPNOTSUPP in case sensor attribute not found
+ */
+static inline int
+peci_sensor_get_ctx(s32 attribute, struct peci_sensor_conf sensor_conf_list[],
+		    struct peci_sensor_conf **sensor_conf,
+		    struct peci_sensor_data sensor_data_list[],
+		    struct peci_sensor_data **sensor_data,
+		    const u8 sensor_count)
+{
+	int iter;
+
+	for (iter = 0; iter < sensor_count; ++iter) {
+		if (attribute == sensor_conf_list[iter].attribute) {
+			*sensor_conf = &sensor_conf_list[iter];
+			if (sensor_data_list && sensor_data)
+				*sensor_data = &sensor_data_list[iter];
+			return 0;
+		}
+	}
+
+	return -EOPNOTSUPP;
+}
+
+/* Value for the most common parameter used for PCS accessing */
+#define PECI_PCS_PARAM_ZERO 0x0000u
+
+#define PECI_PCS_REGISTER_SIZE 4u /* PCS register size in bytes */
+
+/* PPL1 value to PPL2 value conversation macro */
+#define PECI_PCS_PPL1_TO_PPL2(ppl1_value) ((((u32)(ppl1_value)) * 12uL) / 10uL)
+
+#define PECI_PCS_PPL1_TIME_WINDOW 250 /* PPL1 Time Window value in ms */
+
+#define PECI_PCS_PPL2_TIME_WINDOW 10 /* PPL2 Time Window value in ms */
+
+/**
+ * union peci_pkg_power_sku_unit - PECI Package Power Unit PCS
+ * This register coresponds to the MSR@606h - MSR_RAPL_POWER_UNIT
+ * Accessing over PECI: PCS=0x1E, Parameter=0x0000
+ * @value: PCS register value
+ * @bits:	PCS register bits
+ *		@pwr_unit:	Bits [3:0] - Power Unit
+ *		@rsvd0:		Bits [7:4]
+ *		@eng_unit:	Bits [12:8] - Energy Unit
+ *		@rsvd1:		Bits [15:13]
+ *		@tim_unit:	Bits [19:16] - Time Unit
+ *		@rsvd2:		Bits [31:20]
+ */
+union peci_pkg_power_sku_unit {
+	u32 value;
+	struct {
+		u32 pwr_unit	: 4;
+		u32 rsvd0	: 4;
+		u32 eng_unit	: 5;
+		u32 rsvd1	: 3;
+		u32 tim_unit	: 4;
+		u32 rsvd2	: 12;
+	} __attribute__((__packed__)) bits;
+} __attribute__((__packed__));
+
+static_assert(sizeof(union peci_pkg_power_sku_unit) == PECI_PCS_REGISTER_SIZE);
+
+/**
+ * union peci_package_power_info_low - Platform and Package Power SKU (Low) PCS
+ * This PCS coresponds to the MSR@614h - PACKAGE_POWER_SKU, bits [31:0]
+ * Accessing over PECI: PCS=0x1C, parameter=0x00FF
+ * @value: PCS register value
+ * @bits:	PCS register bits
+ *		@pkg_tdp:	Bits [14:0] - TDP Package Power
+ *		@rsvd0:		Bits [15:15]
+ *		@pkg_min_pwr:	Bits [30:16] - Minimal Package Power
+ *		@rsvd1:		Bits [31:31]
+ */
+union peci_package_power_info_low {
+	u32 value;
+	struct {
+		u32 pkg_tdp	: 15;
+		u32 rsvd0	: 1;
+		u32 pkg_min_pwr	: 15;
+		u32 rsvd1	: 1;
+	} __attribute__((__packed__)) bits;
+} __attribute__((__packed__));
+
+static_assert(sizeof(union peci_package_power_info_low) ==
+	      PECI_PCS_REGISTER_SIZE);
+
+/**
+ * union peci_package_power_limit_high - Package Power Limit 2 PCS
+ * This PCS coresponds to the MSR@610h - PACKAGE_RAPL_LIMIT, bits [63:32]
+ * Accessing over PECI: PCS=0x1B, Parameter=0x0000
+ * @value: PCS register value
+ * @bits:	PCS register bits
+ *		@pwr_lim_2:	Bits [14:0] - Power Limit 2
+ *		@pwr_lim_2_en:	Bits [15:15] - Power Limit 2 Enable
+ *		@pwr_clmp_lim_2:Bits [16:16] - Package Clamping Limitation 2
+ *		@pwr_lim_2_time:Bits [23:17] - Power Limit 2 Time Window
+ *		@rsvd0:		Bits [31:24]
+ */
+union peci_package_power_limit_high {
+	u32 value;
+	struct {
+		u32 pwr_lim_2		: 15;
+		u32 pwr_lim_2_en	: 1;
+		u32 pwr_clmp_lim_2	: 1;
+		u32 pwr_lim_2_time	: 7;
+		u32 rsvd0		: 8;
+	} __attribute__((__packed__)) bits;
+} __attribute__((__packed__));
+
+static_assert(sizeof(union peci_package_power_limit_high) ==
+	      PECI_PCS_REGISTER_SIZE);
+
+/**
+ * union peci_package_power_limit_low - Package Power Limit 1 PCS
+ * This PCS coresponds to the MSR@610h - PACKAGE_RAPL_LIMIT, bits [31:0]
+ * Accessing over PECI: PCS=0x1A, Parameter=0x0000
+ * @value: PCS register value
+ * @bits:	PCS register bits
+ *		@pwr_lim_1:	Bits [14:0] - Power Limit 1
+ *		@pwr_lim_1_en:	Bits [15:15] - Power Limit 1 Enable
+ *		@pwr_clmp_lim_1:Bits [16:16] - Package Clamping Limitation 1
+ *		@pwr_lim_1_time:Bits [23:17] - Power Limit 1 Time Window
+ *		@rsvd0:		Bits [31:24]
+ */
+union peci_package_power_limit_low {
+	u32 value;
+	struct {
+		u32 pwr_lim_1		: 15;
+		u32 pwr_lim_1_en	: 1;
+		u32 pwr_clmp_lim_1	: 1;
+		u32 pwr_lim_1_time	: 7;
+		u32 rsvd0		: 8;
+	} __attribute__((__packed__)) bits;
+} __attribute__((__packed__));
+
+static_assert(sizeof(union peci_package_power_limit_low) ==
+	      PECI_PCS_REGISTER_SIZE);
+
+/**
+ * union peci_dram_power_info_low - DRAM Power Info low PCS
+ * This PCS coresponds to the MSR@61Ch - MSR_DRAM_POWER_INFO, bits [31:0]
+ * Accessing over PECI: PCS=0x24, Parameter=0x0000
+ * @value: PCS register value
+ * @bits:	PCS register bits
+ *		@tdp:		Bits [14:0] - Spec DRAM Power
+ *		@rsvd0:		Bits [15:15]
+ *		@min_pwr:	Bits [30:16] - Minimal DRAM Power
+ *		@rsvd1:		Bits [31:31]
+ */
+union peci_dram_power_info_low {
+	u32 value;
+	struct {
+		u32 tdp		: 15;
+		u32 rsvd0	: 1;
+		u32 min_pwr	: 15;
+		u32 rsvd1	: 1;
+	} __attribute__((__packed__)) bits;
+} __attribute__((__packed__));
+
+static_assert(sizeof(union peci_dram_power_info_low) == PECI_PCS_REGISTER_SIZE);
+
+/**
+ * union peci_dram_power_limit - DRAM Power Limit PCS
+ * This PCS coresponds to the MSR@618h - DRAM_PLANE_POWER_LIMIT, bits [31:0]
+ * Accessing over PECI: PCS=0x22, Parameter=0x0000
+ * @value: PCS register value
+ * @bits:	PCS register bits
+ *		@pp_pwr_lim:	Bits [14:0] - Power Limit[0] for DDR domain,
+ *				format: U11.3
+ *		@pwr_lim_ctrl_en:Bits [15:15] - Power Limit[0] enable bit for
+ *				DDR domain
+ *		@rsvd0:		Bits [16:16]
+ *		@ctrl_time_win:	Bits [23:17] - Power Limit[0] time window for
+ *				DDR domain
+ *		@rsvd1:		Bits [31:24]
+ */
+union peci_dram_power_limit {
+	u32 value;
+	struct {
+		u32 pp_pwr_lim		: 15;
+		u32 pwr_lim_ctrl_en	: 1;
+		u32 rsvd0		: 1;
+		u32 ctrl_time_win	: 7;
+		u32 rsvd1		: 8;
+	} __attribute__((__packed__)) bits;
+} __attribute__((__packed__));
+
+static_assert(sizeof(union peci_dram_power_limit) == PECI_PCS_REGISTER_SIZE);
+
+/**
+ * peci_pcs_xn_to_uunits - function converting value in units in x.N format to
+ * micro units (microjoules, microseconds, microdegrees) in regular format
+ * @x_n_value: Value in units in x.n format
+ * @n: n factor for x.n format
+
+ *
+ * Return: value in micro units (microjoules, microseconds, microdegrees)
+ * in regular format
+ */
+static inline u64 peci_pcs_xn_to_uunits(u32 x_n_value, u8 n)
+{
+	u64 mx_n_value = (u64)x_n_value * 1000000uLL;
+
+	return mx_n_value >> n;
+}
+
+/**
+ * peci_pcs_xn_to_munits - function converting value in units in x.N format to
+ * milli units (millijoules, milliseconds, millidegrees) in regular format
+ * @x_n_value: Value in units in x.n format
+ * @n: n factor for x.n format
+
+ *
+ * Return: value in milli units (millijoules, milliseconds, millidegrees)
+ * in regular format
+ */
+static inline u64 peci_pcs_xn_to_munits(u32 x_n_value, u8 n)
+{
+	u64 mx_n_value = (u64)x_n_value * 1000uLL;
+
+	return mx_n_value >> n;
+}
+
+/**
+ * peci_pcs_munits_to_xn - function converting value in milli units
+ * (millijoules,milliseconds, millidegrees) in regular format to value in units
+ * in x.n format
+ * @mu_value: Value in milli units (millijoules, milliseconds, millidegrees)
+ * @n: n factor for x.n format, assumed here maximal value for n is 32
+ *
+ * Return: value in units in x.n format
+ */
+static inline u32 peci_pcs_munits_to_xn(u32 mu_value, u8 n)
+{
+	/* Convert value in milli units (regular format) to the x.n format */
+	u64 mx_n_value = (u64)mu_value << n;
+	/* Convert milli units (x.n format) to units (x.n format) */
+	if (mx_n_value > (u64)U32_MAX) {
+		do_div(mx_n_value, 1000uL);
+		return (u32)mx_n_value;
+	} else {
+		return (u32)mx_n_value / 1000uL;
+	}
+}
+
+/**
+ * peci_pcs_read - read PCS register
+ * @peci_mgr: PECI client manager handle
+ * @index: PCS index
+ * @parameter: PCS parameter
+ * @reg: Pointer to the variable read value is going to be put
+ *
+ * Return: 0 if succeeded,
+ *	-EINVAL if there are null pointers among arguments,
+ *	other values in case other errors.
+ */
+static inline int peci_pcs_read(struct peci_client_manager *peci_mgr, u8 index,
+				u16 parameter, u32 *reg)
+{
+	u32 pcs_reg;
+	int ret;
+
+	if (!reg)
+		return -EINVAL;
+
+	ret = peci_client_read_package_config(peci_mgr, index, parameter,
+					      (u8 *)&pcs_reg);
+	if (!ret)
+		*reg = le32_to_cpup((__le32 *)&pcs_reg);
+
+	return ret;
+}
+
+/**
+ * peci_pcs_write - write PCS register
+ * @peci_mgr: PECI client manager handle
+ * @index: PCS index
+ * @parameter: PCS parameter
+ * @reg: Variable which value is going to be written to the PCS
+ *
+ * Return: 0 if succeeded, other values in case an error.
+ */
+static inline int peci_pcs_write(struct peci_client_manager *peci_mgr, u8 index,
+				 u16 parameter, u32 reg)
+{
+	int ret;
+
+	ret = peci_client_write_package_config(peci_mgr, index, parameter, reg);
+
+	return ret;
+}
+
+/**
+ * peci_pcs_calc_pwr_from_eng - calculate power (in milliwatts) based on
+ * two energy readings
+ * @dev: Device handle
+ * @prev_energy: Previous energy reading context with raw energy counter value
+ * @energy: Current energy reading context with raw energy counter value
+ * @unit: Calculation factor
+ * @power_val_in_mW: Pointer to the variable calculation result is going to
+ * be put
+ *
+ * Return: 0 if succeeded,
+ *	-EINVAL if there are null pointers among arguments,
+ *	-EAGAIN if calculation is skipped.
+ */
+static inline int peci_pcs_calc_pwr_from_eng(struct device *dev,
+					     struct peci_sensor_data *prev_energy,
+					     struct peci_sensor_data *energy,
+					     u32 unit, s32 *power_in_mW)
+{
+	ulong elapsed;
+	int ret;
+
+
+	elapsed = energy->last_updated - prev_energy->last_updated;
+
+	dev_dbg(dev, "raw energy before %u, raw energy now %u, unit %u, jiffies elapsed %lu\n",
+		prev_energy->uvalue, energy->uvalue, unit, elapsed);
+
+	/*
+	 * TODO: Remove checking current energy value against 0.
+	 * During host reset CPU resets its energy counters, hwmon treats such case
+	 * as proper energy read (counter overflow) and calculates invalid
+	 * power consumption. Currently hwmon is unable to determine if CPU was
+	 * reset, stop treating 0 as invalid value when proper mechanism
+	 * is implemented.
+	 *
+	 * Don't calculate average power for first counter read  last counter
+	 * read was more than 60 minutes ago (jiffies did not wrap and power
+	 * calculation does not overflow or underflow) or energy read time
+	 * did not change.
+	 */
+	if (energy->uvalue > 0 && prev_energy->last_updated > 0 &&
+	    elapsed < (HZ * 3600) && elapsed) {
+		u32 energy_consumed;
+		u64 energy_consumed_in_mJ;
+		u64 energy_by_jiffies;
+
+		if (energy->uvalue >= prev_energy->uvalue)
+			energy_consumed = energy->uvalue - prev_energy->uvalue;
+		else
+			energy_consumed = (U32_MAX - prev_energy->uvalue) +
+					energy->uvalue + 1u;
+
+		energy_consumed_in_mJ =
+				peci_pcs_xn_to_munits(energy_consumed, unit);
+		energy_by_jiffies = energy_consumed_in_mJ * HZ;
+
+		if (energy_by_jiffies > (u64)U32_MAX) {
+			do_div(energy_by_jiffies, elapsed);
+			*power_in_mW = (long)energy_by_jiffies;
+		} else {
+			*power_in_mW = (u32)energy_by_jiffies / elapsed;
+		}
+
+		dev_dbg(dev, "raw energy consumed %u, scaled energy consumed %llumJ, scaled power %dmW\n",
+			energy_consumed, energy_consumed_in_mJ, *power_in_mW);
+
+		ret = 0;
+	} else {
+		dev_dbg(dev, "skipping calculate power, try again\n");
+		*power_in_mW = 0;
+		ret = -EAGAIN;
+	}
+
+	prev_energy->uvalue = energy->uvalue;
+	peci_sensor_mark_updated_with_time(prev_energy, energy->last_updated);
+
+	return ret;
+}
+
+/**
+ * peci_pcs_calc_acc_eng - calculate accumulated energy (in microjoules) based
+ * on two energy readings
+ * @dev: Device handle
+ * @prev_energy: Previous energy reading context with raw energy counter value
+ * @energy: Current energy reading context with raw energy counter value
+ * @unit: Calculation factor
+ * @acc_energy_in_uJ: Pointer to the variable with cumulative energy counter
+ *
+ * Return: 0 if succeeded,
+ *	-EINVAL if there are null pointers among arguments,
+ *	-EAGAIN if calculation is skipped.
+ */
+static inline int peci_pcs_calc_acc_eng(struct device *dev,
+					struct peci_sensor_data *prev_energy,
+					struct peci_sensor_data *curr_energy,
+					u32 unit, u32 *acc_energy_in_uJ)
+{
+	ulong elapsed;
+	int ret;
+
+	elapsed = curr_energy->last_updated - prev_energy->last_updated;
+
+	dev_dbg(dev, "raw energy before %u, raw energy now %u, unit %u, jiffies elapsed %lu\n",
+		prev_energy->uvalue, curr_energy->uvalue, unit, elapsed);
+
+	/*
+	 * TODO: Remove checking current energy value against 0.
+	 * During host reset CPU resets its energy counters, hwmon treats such case
+	 * as proper energy read (counter overflow) and calculates invalid
+	 * energy increase. Currently hwmon is unable to determine if CPU was
+	 * reset, stop treating 0 as invalid value when proper mechanism
+	 * is implemented.
+	 *
+	 * Don't calculate cumulative energy for first counter read - last counter
+	 * read was more than 17 minutes ago (jiffies and energy raw counter did not wrap
+	 * and power calculation does not overflow or underflow).
+	 */
+	if (curr_energy->uvalue > 0 && prev_energy->last_updated > 0 &&
+	    elapsed < (HZ * 17 * 60)) {
+		u32 energy_consumed;
+		u64 energy_consumed_in_uJ;
+
+		if (curr_energy->uvalue >= prev_energy->uvalue)
+			energy_consumed = curr_energy->uvalue -
+					prev_energy->uvalue;
+		else
+			energy_consumed = (U32_MAX - prev_energy->uvalue) +
+					curr_energy->uvalue + 1u;
+
+		energy_consumed_in_uJ =
+				peci_pcs_xn_to_uunits(energy_consumed, unit);
+		*acc_energy_in_uJ = S32_MAX &
+				(*acc_energy_in_uJ + (u32)energy_consumed_in_uJ);
+
+		dev_dbg(dev, "raw energy %u, scaled energy %llumJ, cumulative energy %dmJ\n",
+			energy_consumed, energy_consumed_in_uJ,
+			*acc_energy_in_uJ);
+
+		ret = 0;
+	} else {
+		dev_dbg(dev, "skipping calculate cumulative energy, try again\n");
+
+		*acc_energy_in_uJ = 0;
+		ret = -EAGAIN;
+	}
+
+	prev_energy->uvalue = curr_energy->uvalue;
+	peci_sensor_mark_updated_with_time(prev_energy,
+					   curr_energy->last_updated);
+
+	return ret;
+}
+
+/**
+ * peci_pcs_get_units - read units (power, energy, time) from HW or cache
+ * @peci_mgr: PECI client manager handle
+ * @units: Pointer to the variable read value is going to be put in case reading
+ * from HW
+ * @valid: Flag telling cache is valid
+ *
+ * Return: 0 if succeeded
+ *	-EINVAL if there are null pointers among arguments,
+ *	other values in case other errors.
+ */
+static inline int peci_pcs_get_units(struct peci_client_manager *peci_mgr,
+				     union peci_pkg_power_sku_unit *units,
+				     bool *valid)
+{
+	int ret = 0;
+
+	if (!valid)
+		return -EINVAL;
+
+	if (!(*valid)) {
+		ret = peci_pcs_read(peci_mgr, PECI_MBX_INDEX_TDP_UNITS,
+				    PECI_PCS_PARAM_ZERO, &units->value);
+		if (!ret)
+			*valid = true;
+	}
+	return ret;
+}
+
+/**
+ * peci_pcs_calc_plxy_time_window - calculate power limit time window in
+ * PCS format. To figure that value out needs to solve the following equation:
+ * time_window = (1+(x/4)) * (2 ^ y), where time_window is known value and
+ * x and y values are variables to find.
+ * Return value is about X & Y compostion according to the following:
+ * x = ret[6:5], y = ret[4:0].
+ * @pl_tim_wnd_in_xn: PPL time window in X-n format
+ *
+ * Return: Power limit time window value
+ */
+static inline u32 peci_pcs_calc_plxy_time_window(u32 pl_tim_wnd_in_xn)
+{
+	u32 x = 0u;
+	u32 y = 0u;
+
+	/* Calculate y first */
+	while (pl_tim_wnd_in_xn > 7u) {
+		pl_tim_wnd_in_xn >>= 1;
+		y++;
+	}
+
+	/* Correct y value */
+	if (pl_tim_wnd_in_xn >= 4u)
+		y += 2u;
+	else if (pl_tim_wnd_in_xn >= 2u)
+		y += 1u;
+
+	/* Calculate x then */
+	if (pl_tim_wnd_in_xn >= 4u)
+		x = pl_tim_wnd_in_xn % 4;
+	else
+		x = 0u;
+
+	return ((x & 0x3) << 5) | (y & 0x1F);
+}
+
+#endif /* __PECI_HWMON_H */
diff --git a/drivers/mfd/Kconfig b/drivers/mfd/Kconfig
index d2f345245538..ac76f5cf7ceb 100644
--- a/drivers/mfd/Kconfig
+++ b/drivers/mfd/Kconfig
@@ -676,6 +676,23 @@ config MFD_INTEL_LPSS_PCI
 	  I2C, SPI and HS-UART starting from Intel Sunrisepoint (Intel Skylake
 	  PCH) in PCI mode.
 
+config MFD_INTEL_PECI_CLIENT
+	tristate "Intel PECI client"
+	depends on (PECI || COMPILE_TEST)
+	select MFD_CORE
+	help
+	  If you say yes to this option, support will be included for the
+	  Intel PECI (Platform Environment Control Interface) client. PECI is a
+	  one-wire bus interface that provides a communication channel from PECI
+	  clients in Intel processors and chipset components to external
+	  monitoring or control devices.
+
+	  Additional drivers must be enabled in order to use the functionality
+	  of the device.
+
+	  This driver can also be built as a module. If so, the module
+	  will be called intel-peci-client.
+
 config MFD_INTEL_PMC_BXT
 	tristate "Intel PMC Driver for Broxton"
 	depends on X86
diff --git a/drivers/mfd/Makefile b/drivers/mfd/Makefile
index 2ba6646e874c..b940be7d8aea 100644
--- a/drivers/mfd/Makefile
+++ b/drivers/mfd/Makefile
@@ -211,6 +211,7 @@ obj-$(CONFIG_MFD_ATMEL_SMC)	+= atmel-smc.o
 obj-$(CONFIG_MFD_INTEL_LPSS)	+= intel-lpss.o
 obj-$(CONFIG_MFD_INTEL_LPSS_PCI)	+= intel-lpss-pci.o
 obj-$(CONFIG_MFD_INTEL_LPSS_ACPI)	+= intel-lpss-acpi.o
+obj-$(CONFIG_MFD_INTEL_PECI_CLIENT)	+= intel-peci-client.o
 obj-$(CONFIG_MFD_INTEL_PMC_BXT)	+= intel_pmc_bxt.o
 obj-$(CONFIG_MFD_INTEL_PMT)	+= intel_pmt.o
 obj-$(CONFIG_MFD_PALMAS)	+= palmas.o
diff --git a/drivers/mfd/intel-peci-client.c b/drivers/mfd/intel-peci-client.c
new file mode 100644
index 000000000000..69834a230998
--- /dev/null
+++ b/drivers/mfd/intel-peci-client.c
@@ -0,0 +1,166 @@
+// SPDX-License-Identifier: GPL-2.0
+// Copyright (c) 2018-2019 Intel Corporation
+
+#include <linux/bitfield.h>
+#include <linux/mfd/core.h>
+#include <linux/mfd/intel-peci-client.h>
+#include <linux/module.h>
+#include <linux/of_device.h>
+#include <linux/peci.h>
+
+#define CPU_ID_MODEL_MASK	GENMASK(7, 4)
+#define CPU_ID_FAMILY_MASK	GENMASK(11, 8)
+#define CPU_ID_EXT_MODEL_MASK	GENMASK(19, 16)
+#define CPU_ID_EXT_FAMILY_MASK	GENMASK(27, 20)
+
+#define LOWER_NIBBLE_MASK	GENMASK(3, 0)
+#define UPPER_NIBBLE_MASK	GENMASK(7, 4)
+#define LOWER_BYTE_MASK		GENMASK(7, 0)
+#define UPPER_BYTE_MASK		GENMASK(16, 8)
+
+static struct mfd_cell peci_functions[] = {
+	{ .name = "peci-cputemp", },
+	{ .name = "peci-dimmtemp", },
+	{ .name = "peci-cpupower", },
+	{ .name = "peci-dimmpower", },
+};
+
+static const struct cpu_gen_info cpu_gen_info_table[] = {
+	{ /* Haswell Xeon */
+		.family         = INTEL_FAM6,
+		.model          = INTEL_FAM6_HASWELL_X,
+		.core_mask_bits = CORE_MASK_BITS_ON_HSX,
+		.chan_rank_max  = CHAN_RANK_MAX_ON_HSX,
+		.dimm_idx_max   = DIMM_IDX_MAX_ON_HSX },
+	{ /* Broadwell Xeon */
+		.family         = INTEL_FAM6,
+		.model          = INTEL_FAM6_BROADWELL_X,
+		.core_mask_bits = CORE_MASK_BITS_ON_BDX,
+		.chan_rank_max  = CHAN_RANK_MAX_ON_BDX,
+		.dimm_idx_max   = DIMM_IDX_MAX_ON_BDX },
+	{ /* Skylake Xeon */
+		.family         = INTEL_FAM6,
+		.model          = INTEL_FAM6_SKYLAKE_X,
+		.core_mask_bits = CORE_MASK_BITS_ON_SKX,
+		.chan_rank_max  = CHAN_RANK_MAX_ON_SKX,
+		.dimm_idx_max   = DIMM_IDX_MAX_ON_SKX },
+	{ /* Skylake Xeon D */
+		.family         = INTEL_FAM6,
+		.model          = INTEL_FAM6_SKYLAKE_XD,
+		.core_mask_bits = CORE_MASK_BITS_ON_SKXD,
+		.chan_rank_max  = CHAN_RANK_MAX_ON_SKXD,
+		.dimm_idx_max   = DIMM_IDX_MAX_ON_SKXD },
+	{ /* Icelake Xeon */
+		.family         = INTEL_FAM6,
+		.model          = INTEL_FAM6_ICELAKE_X,
+		.core_mask_bits = CORE_MASK_BITS_ON_ICX,
+		.chan_rank_max  = CHAN_RANK_MAX_ON_ICX,
+		.dimm_idx_max   = DIMM_IDX_MAX_ON_ICX },
+	{ /* Icelake Xeon D */
+		.family         = INTEL_FAM6,
+		.model          = INTEL_FAM6_ICELAKE_XD,
+		.core_mask_bits = CORE_MASK_BITS_ON_ICXD,
+		.chan_rank_max  = CHAN_RANK_MAX_ON_ICXD,
+		.dimm_idx_max   = DIMM_IDX_MAX_ON_ICXD },
+};
+
+static int peci_client_get_cpu_gen_info(struct peci_client_manager *priv)
+{
+	struct device *dev = &priv->client->dev;
+	u32 cpu_id;
+	u16 family;
+	u8 model;
+	int ret;
+	int i;
+
+	ret = peci_get_cpu_id(priv->client->adapter, priv->client->addr,
+			      priv->client->domain_id, &cpu_id);
+	if (ret)
+		return ret;
+
+	family = FIELD_PREP(LOWER_BYTE_MASK,
+			    FIELD_GET(CPU_ID_FAMILY_MASK, cpu_id)) |
+		 FIELD_PREP(UPPER_BYTE_MASK,
+			    FIELD_GET(CPU_ID_EXT_FAMILY_MASK, cpu_id));
+	model = FIELD_PREP(LOWER_NIBBLE_MASK,
+			   FIELD_GET(CPU_ID_MODEL_MASK, cpu_id)) |
+		FIELD_PREP(UPPER_NIBBLE_MASK,
+			   FIELD_GET(CPU_ID_EXT_MODEL_MASK, cpu_id));
+
+	for (i = 0; i < ARRAY_SIZE(cpu_gen_info_table); i++) {
+		const struct cpu_gen_info *cpu_info = &cpu_gen_info_table[i];
+
+		if (family == cpu_info->family && model == cpu_info->model) {
+			priv->gen_info = cpu_info;
+			break;
+		}
+	}
+
+	if (!priv->gen_info) {
+		dev_err(dev, "Can't support this CPU: 0x%x\n", cpu_id);
+		ret = -ENODEV;
+	}
+
+	return ret;
+}
+
+static int peci_client_probe(struct peci_client *client)
+{
+	struct device *dev = &client->dev;
+	u8 cpu_id = client->addr - PECI_BASE_ADDR;
+	u8 domain_id = client->domain_id;
+	u8 adapter_nr = client->adapter->nr;
+	struct peci_client_manager *priv;
+	int device_id;
+	int ret;
+
+	priv = devm_kzalloc(dev, sizeof(*priv), GFP_KERNEL);
+	if (!priv)
+		return -ENOMEM;
+
+	dev_set_drvdata(dev, priv);
+	priv->client = client;
+
+	ret = peci_client_get_cpu_gen_info(priv);
+	if (ret)
+		return ret;
+
+	device_id = (adapter_nr << 8) | (cpu_id << 4) | domain_id;
+
+	ret = devm_mfd_add_devices(dev, device_id, peci_functions,
+				   ARRAY_SIZE(peci_functions), NULL, 0, NULL);
+	if (ret < 0) {
+		dev_err(dev, "Failed to register child devices: %d\n", ret);
+		return ret;
+	}
+
+	return 0;
+}
+
+#ifdef CONFIG_OF
+static const struct of_device_id peci_client_of_table[] = {
+	{ .compatible = "intel,peci-client" },
+	{ }
+};
+MODULE_DEVICE_TABLE(of, peci_client_of_table);
+#endif
+
+static const struct peci_device_id peci_client_ids[] = {
+	{ .name = "peci-client" },
+	{ }
+};
+MODULE_DEVICE_TABLE(peci, peci_client_ids);
+
+static struct peci_driver peci_client_driver = {
+	.probe		= peci_client_probe,
+	.id_table	= peci_client_ids,
+	.driver		= {
+		.name		= KBUILD_MODNAME,
+		.of_match_table	= of_match_ptr(peci_client_of_table),
+	},
+};
+module_peci_driver(peci_client_driver);
+
+MODULE_AUTHOR("Jae Hyun Yoo <jae.hyun.yoo@linux.intel.com>");
+MODULE_DESCRIPTION("PECI client driver");
+MODULE_LICENSE("GPL v2");
diff --git a/drivers/peci/Kconfig b/drivers/peci/Kconfig
new file mode 100644
index 000000000000..a64fed7bb367
--- /dev/null
+++ b/drivers/peci/Kconfig
@@ -0,0 +1,37 @@
+#
+# Platform Environment Control Interface (PECI) subsystem configuration
+#
+
+menu "PECI support"
+
+config PECI
+	tristate "PECI support"
+	select CRC8
+	help
+	  The Platform Environment Control Interface (PECI) is a one-wire bus
+	  interface that provides a communication channel from Intel processors
+	  and chipset components to external monitoring or control devices.
+
+	  If you want PECI support, you should say Y here and also to the
+	  specific driver for your bus adapter(s) below.
+
+	  This support is also available as a module. If so, the module
+	  will be called peci-core.
+
+if PECI
+
+config PECI_CHARDEV
+	tristate "PECI device interface"
+	help
+	  Say Y here to use peci-* device files, usually found in the /dev
+	  directory on your system. They make it possible to have user-space
+	  programs use the PECI bus.
+
+	  This support is also available as a module. If so, the module
+	  will be called peci-dev.
+
+source "drivers/peci/busses/Kconfig"
+
+endif # PECI
+
+endmenu
diff --git a/drivers/peci/Makefile b/drivers/peci/Makefile
new file mode 100644
index 000000000000..da8b0a33fa42
--- /dev/null
+++ b/drivers/peci/Makefile
@@ -0,0 +1,11 @@
+# SPDX-License-Identifier: GPL-2.0
+#
+# Makefile for the PECI core drivers.
+#
+
+# Core functionality
+obj-$(CONFIG_PECI)		+= peci-core.o
+obj-$(CONFIG_PECI_CHARDEV)	+= peci-dev.o
+
+# Hardware specific bus drivers
+obj-y				+= busses/
diff --git a/drivers/peci/busses/Kconfig b/drivers/peci/busses/Kconfig
new file mode 100644
index 000000000000..8e6a602c879d
--- /dev/null
+++ b/drivers/peci/busses/Kconfig
@@ -0,0 +1,60 @@
+#
+# PECI hardware bus configuration
+#
+
+menu "PECI Hardware Bus support"
+
+config PECI_ASPEED
+	tristate "ASPEED PECI support"
+	depends on ARCH_ASPEED || COMPILE_TEST
+	depends on OF
+	depends on HAS_IOMEM
+	depends on PECI
+	help
+	  Say Y here if you want support for the Platform Environment Control
+	  Interface (PECI) bus adapter driver on the ASPEED SoCs.
+
+	  This support is also available as a module. If so, the module
+	  will be called peci-aspeed.
+
+config PECI_NPCM
+	tristate "Nuvoton NPCM PECI support"
+	select REGMAP_MMIO
+	depends on OF
+	depends on HAS_IOMEM
+	depends on ARCH_NPCM || COMPILE_TEST
+	depends on PECI
+	help
+	  Say Y here if you want support for the Platform Environment Control
+	  Interface (PECI) bus adapter driver on the Nuvoton NPCM SoCs.
+
+	  This support is also available as a module. If so, the module
+	  will be called peci-npcm.
+
+config PECI_MCTP
+	tristate "PECI over MCTP support"
+	depends on ARCH_ASPEED || COMPILE_TEST
+	depends on PECI
+	depends on ASPEED_MCTP
+
+	help
+	  Say Y here if you want support for the Platform Environment Control
+	  Interface (PECI) over MCTP bus adapter driver.
+
+	  This support is also available as a module. If so, the module
+	  will be called peci-mctp.
+
+config PECI_I3C
+	tristate "PECI over MCTP over I3C support"
+	depends on I3C
+	depends on PECI
+	depends on I3C_MCTP
+
+	help
+	Say Y here if you want support for the Platform Environment Control
+	  Interface (PECI) over MCTP over I3C bus adapter driver.
+
+	  This support is also available as a module. If so, the module
+	  will be called peci-i3c
+
+endmenu
diff --git a/drivers/peci/busses/Makefile b/drivers/peci/busses/Makefile
new file mode 100644
index 000000000000..948578ff6bd1
--- /dev/null
+++ b/drivers/peci/busses/Makefile
@@ -0,0 +1,9 @@
+# SPDX-License-Identifier: GPL-2.0
+#
+# Makefile for the PECI hardware bus drivers.
+#
+
+obj-$(CONFIG_PECI_ASPEED)	+= peci-aspeed.o
+obj-$(CONFIG_PECI_NPCM)		+= peci-npcm.o
+obj-$(CONFIG_PECI_MCTP)		+= peci-mctp.o
+obj-$(CONFIG_PECI_I3C)		+= peci-i3c.o
diff --git a/drivers/peci/busses/peci-aspeed.c b/drivers/peci/busses/peci-aspeed.c
new file mode 100644
index 000000000000..224a3ae8492c
--- /dev/null
+++ b/drivers/peci/busses/peci-aspeed.c
@@ -0,0 +1,522 @@
+// SPDX-License-Identifier: GPL-2.0
+// Copyright (C) 2012-2017 ASPEED Technology Inc.
+// Copyright (c) 2018-2019 Intel Corporation
+
+#include <linux/bitfield.h>
+#include <linux/clk.h>
+#include <linux/delay.h>
+#include <linux/interrupt.h>
+#include <linux/io.h>
+#include <linux/iopoll.h>
+#include <linux/jiffies.h>
+#include <linux/module.h>
+#include <linux/of.h>
+#include <linux/peci.h>
+#include <linux/platform_device.h>
+#include <linux/reset.h>
+
+/* ASPEED PECI Registers */
+/* Control Register */
+#define ASPEED_PECI_CTRL			0x00
+#define   ASPEED_PECI_CTRL_SAMPLING_MASK	GENMASK(19, 16)
+#define   ASPEED_PECI_CTRL_READ_MODE_MASK	GENMASK(13, 12)
+#define   ASPEED_PECI_CTRL_READ_MODE_COUNT	BIT(12)
+#define   ASPEED_PECI_CTRL_READ_MODE_DBG	BIT(13)
+#define   ASPEED_PECI_CTRL_CLK_SOURCE_MASK	BIT(11)
+#define   ASPEED_PECI_CTRL_CLK_DIV_MASK		GENMASK(10, 8)
+#define   ASPEED_PECI_CTRL_INVERT_OUT		BIT(7)
+#define   ASPEED_PECI_CTRL_INVERT_IN		BIT(6)
+#define   ASPEED_PECI_CTRL_BUS_CONTENT_EN	BIT(5)
+#define   ASPEED_PECI_CTRL_PECI_EN		BIT(4)
+#define   ASPEED_PECI_CTRL_PECI_CLK_EN		BIT(0)
+
+/* Timing Negotiation Register */
+#define ASPEED_PECI_TIMING_NEGOTIATION		0x04
+#define   ASPEED_PECI_TIMING_MESSAGE_MASK	GENMASK(15, 8)
+#define   ASPEED_PECI_TIMING_ADDRESS_MASK	GENMASK(7, 0)
+
+/* Command Register */
+#define ASPEED_PECI_CMD				0x08
+#define   ASPEED_PECI_CMD_PIN_MON		BIT(31)
+#define   ASPEED_PECI_CMD_STS_MASK		GENMASK(27, 24)
+#define     ASPEED_PECI_CMD_STS_ADDR_T_NEGO	0x3
+#define   ASPEED_PECI_CMD_IDLE_MASK		\
+	  (ASPEED_PECI_CMD_STS_MASK | ASPEED_PECI_CMD_PIN_MON)
+#define   ASPEED_PECI_CMD_FIRE			BIT(0)
+
+/* Read/Write Length Register */
+#define ASPEED_PECI_RW_LENGTH			0x0c
+#define   ASPEED_PECI_AW_FCS_EN			BIT(31)
+#define   ASPEED_PECI_READ_LEN_MASK		GENMASK(23, 16)
+#define   ASPEED_PECI_WRITE_LEN_MASK		GENMASK(15, 8)
+#define   ASPEED_PECI_TAGET_ADDR_MASK		GENMASK(7, 0)
+
+/* Expected FCS Data Register */
+#define ASPEED_PECI_EXP_FCS			0x10
+#define   ASPEED_PECI_EXP_READ_FCS_MASK		GENMASK(23, 16)
+#define   ASPEED_PECI_EXP_AW_FCS_AUTO_MASK	GENMASK(15, 8)
+#define   ASPEED_PECI_EXP_WRITE_FCS_MASK	GENMASK(7, 0)
+
+/* Captured FCS Data Register */
+#define ASPEED_PECI_CAP_FCS			0x14
+#define   ASPEED_PECI_CAP_READ_FCS_MASK		GENMASK(23, 16)
+#define   ASPEED_PECI_CAP_WRITE_FCS_MASK	GENMASK(7, 0)
+
+/* Interrupt Register */
+#define ASPEED_PECI_INT_CTRL			0x18
+#define   ASPEED_PECI_TIMING_NEGO_SEL_MASK	GENMASK(31, 30)
+#define     ASPEED_PECI_1ST_BIT_OF_ADDR_NEGO	0
+#define     ASPEED_PECI_2ND_BIT_OF_ADDR_NEGO	1
+#define     ASPEED_PECI_MESSAGE_NEGO		2
+#define   ASPEED_PECI_INT_MASK			GENMASK(4, 0)
+#define   ASPEED_PECI_INT_BUS_TIMEOUT		BIT(4)
+#define   ASPEED_PECI_INT_BUS_CONNECT		BIT(3)
+#define   ASPEED_PECI_INT_W_FCS_BAD		BIT(2)
+#define   ASPEED_PECI_INT_W_FCS_ABORT		BIT(1)
+#define   ASPEED_PECI_INT_CMD_DONE		BIT(0)
+
+/* Interrupt Status Register */
+#define ASPEED_PECI_INT_STS			0x1c
+#define   ASPEED_PECI_INT_TIMING_RESULT_MASK	GENMASK(29, 16)
+	  /* bits[4..0]: Same bit fields in the 'Interrupt Register' */
+
+/* Rx/Tx Data Buffer Registers */
+#define ASPEED_PECI_W_DATA0			0x20
+#define ASPEED_PECI_W_DATA1			0x24
+#define ASPEED_PECI_W_DATA2			0x28
+#define ASPEED_PECI_W_DATA3			0x2c
+#define ASPEED_PECI_R_DATA0			0x30
+#define ASPEED_PECI_R_DATA1			0x34
+#define ASPEED_PECI_R_DATA2			0x38
+#define ASPEED_PECI_R_DATA3			0x3c
+#define ASPEED_PECI_W_DATA4			0x40
+#define ASPEED_PECI_W_DATA5			0x44
+#define ASPEED_PECI_W_DATA6			0x48
+#define ASPEED_PECI_W_DATA7			0x4c
+#define ASPEED_PECI_R_DATA4			0x50
+#define ASPEED_PECI_R_DATA5			0x54
+#define ASPEED_PECI_R_DATA6			0x58
+#define ASPEED_PECI_R_DATA7			0x5c
+#define   ASPEED_PECI_DATA_BUF_SIZE_MAX		32
+
+/* Timing Negotiation */
+#define ASPEED_PECI_RD_SAMPLING_POINT_DEFAULT	8
+#define ASPEED_PECI_RD_SAMPLING_POINT_MAX	15
+#define ASPEED_PECI_CLK_DIV_DEFAULT		0
+#define ASPEED_PECI_CLK_DIV_MAX			7
+#define ASPEED_PECI_MSG_TIMING_DEFAULT		1
+#define ASPEED_PECI_MSG_TIMING_MAX		255
+#define ASPEED_PECI_ADDR_TIMING_DEFAULT		1
+#define ASPEED_PECI_ADDR_TIMING_MAX		255
+
+/* Timeout */
+#define ASPEED_PECI_IDLE_CHECK_TIMEOUT_USEC	50000
+#define ASPEED_PECI_IDLE_CHECK_INTERVAL_USEC	10000
+#define ASPEED_PECI_CMD_TIMEOUT_MS_DEFAULT	1000
+#define ASPEED_PECI_CMD_TIMEOUT_MS_MAX		60000
+
+struct aspeed_peci {
+	struct peci_adapter	*adapter;
+	struct device		*dev;
+	void __iomem		*base;
+	struct clk		*clk;
+	struct reset_control	*rst;
+	int			irq;
+	spinlock_t		lock; /* to sync completion status handling */
+	struct completion	xfer_complete;
+	u32			status;
+	u32			cmd_timeout_ms;
+	u32			msg_timing;
+	u32			addr_timing;
+	u32			rd_sampling_point;
+	u32			clk_div_val;
+};
+
+static void aspeed_peci_init_regs(struct aspeed_peci *priv)
+{
+	writel(FIELD_PREP(ASPEED_PECI_CTRL_CLK_DIV_MASK,
+			  ASPEED_PECI_CLK_DIV_DEFAULT) |
+	       ASPEED_PECI_CTRL_PECI_CLK_EN, priv->base + ASPEED_PECI_CTRL);
+
+	/*
+	 * Timing negotiation period setting.
+	 * The unit of the programmed value is 4 times of PECI clock period.
+	 */
+	writel(FIELD_PREP(ASPEED_PECI_TIMING_MESSAGE_MASK, priv->msg_timing) |
+	       FIELD_PREP(ASPEED_PECI_TIMING_ADDRESS_MASK, priv->addr_timing),
+	       priv->base + ASPEED_PECI_TIMING_NEGOTIATION);
+
+	/* Clear interrupts */
+	writel(readl(priv->base + ASPEED_PECI_INT_STS) | ASPEED_PECI_INT_MASK,
+	       priv->base + ASPEED_PECI_INT_STS);
+
+	/* Set timing negotiation mode and enable interrupts */
+	writel(FIELD_PREP(ASPEED_PECI_TIMING_NEGO_SEL_MASK,
+			  ASPEED_PECI_1ST_BIT_OF_ADDR_NEGO) |
+	       ASPEED_PECI_INT_MASK, priv->base + ASPEED_PECI_INT_CTRL);
+
+	/* Read sampling point and clock speed setting */
+	writel(FIELD_PREP(ASPEED_PECI_CTRL_SAMPLING_MASK, priv->rd_sampling_point) |
+	       FIELD_PREP(ASPEED_PECI_CTRL_CLK_DIV_MASK, priv->clk_div_val) |
+	       ASPEED_PECI_CTRL_PECI_EN | ASPEED_PECI_CTRL_PECI_CLK_EN,
+	       priv->base + ASPEED_PECI_CTRL);
+}
+
+static inline int aspeed_peci_check_idle(struct aspeed_peci *priv)
+{
+	u32 cmd_sts = readl(priv->base + ASPEED_PECI_CMD);
+	int ret;
+
+	/*
+	 * Under normal circumstances, we expect to be idle here.
+	 * In case there were any errors/timeouts that led to the situation
+	 * where the hardware is not in idle state - we need to reset and
+	 * reinitialize it to avoid potential controller hang.
+	 */
+	if (FIELD_GET(ASPEED_PECI_CMD_STS_MASK, cmd_sts)) {
+		ret = reset_control_assert(priv->rst);
+		if (ret) {
+			dev_err(priv->dev, "cannot assert reset control\n");
+			return ret;
+		}
+
+		ret = reset_control_deassert(priv->rst);
+		if (ret) {
+			dev_err(priv->dev, "cannot deassert reset control\n");
+			return ret;
+		}
+
+		aspeed_peci_init_regs(priv);
+	}
+
+	return readl_poll_timeout(priv->base + ASPEED_PECI_CMD,
+				  cmd_sts,
+				  !(cmd_sts & ASPEED_PECI_CMD_IDLE_MASK),
+				  ASPEED_PECI_IDLE_CHECK_INTERVAL_USEC,
+				  ASPEED_PECI_IDLE_CHECK_TIMEOUT_USEC);
+}
+
+static int aspeed_peci_xfer(struct peci_adapter *adapter,
+			    struct peci_xfer_msg *msg)
+{
+	struct aspeed_peci *priv = peci_get_adapdata(adapter);
+	long err, timeout = msecs_to_jiffies(priv->cmd_timeout_ms);
+	u32 peci_head, peci_state, rx_data = 0;
+	ulong flags;
+	int i, ret;
+	uint reg;
+
+	if (msg->tx_len > ASPEED_PECI_DATA_BUF_SIZE_MAX ||
+	    msg->rx_len > ASPEED_PECI_DATA_BUF_SIZE_MAX)
+		return -EINVAL;
+
+	/* Check command sts and bus idle state */
+	ret = aspeed_peci_check_idle(priv);
+	if (ret)
+		return ret; /* -ETIMEDOUT */
+
+	spin_lock_irqsave(&priv->lock, flags);
+	reinit_completion(&priv->xfer_complete);
+
+	peci_head = FIELD_PREP(ASPEED_PECI_TAGET_ADDR_MASK, msg->addr) |
+		    FIELD_PREP(ASPEED_PECI_WRITE_LEN_MASK, msg->tx_len) |
+		    FIELD_PREP(ASPEED_PECI_READ_LEN_MASK, msg->rx_len);
+
+	writel(peci_head, priv->base + ASPEED_PECI_RW_LENGTH);
+
+	for (i = 0; i < msg->tx_len; i += 4) {
+		reg = i < 16 ? ASPEED_PECI_W_DATA0 + i % 16 :
+			       ASPEED_PECI_W_DATA4 + i % 16;
+		writel(le32_to_cpup((__le32 *)&msg->tx_buf[i]),
+		       priv->base + reg);
+	}
+
+	dev_dbg(priv->dev, "HEAD : 0x%08x\n", peci_head);
+	print_hex_dump_debug("TX : ", DUMP_PREFIX_NONE, 16, 1,
+			     msg->tx_buf, msg->tx_len, true);
+
+	priv->status = 0;
+	writel(ASPEED_PECI_CMD_FIRE, priv->base + ASPEED_PECI_CMD);
+	spin_unlock_irqrestore(&priv->lock, flags);
+
+	err = wait_for_completion_interruptible_timeout(&priv->xfer_complete,
+							timeout);
+
+	spin_lock_irqsave(&priv->lock, flags);
+	dev_dbg(priv->dev, "INT_STS : 0x%08x\n", priv->status);
+	peci_state = readl(priv->base + ASPEED_PECI_CMD);
+	dev_dbg(priv->dev, "PECI_STATE : 0x%lx\n",
+		FIELD_GET(ASPEED_PECI_CMD_STS_MASK, peci_state));
+
+	writel(0, priv->base + ASPEED_PECI_CMD);
+
+	if (err <= 0 || priv->status != ASPEED_PECI_INT_CMD_DONE) {
+		if (err < 0) { /* -ERESTARTSYS */
+			ret = (int)err;
+			goto err_irqrestore;
+		} else if (err == 0) {
+			dev_dbg(priv->dev, "Timeout waiting for a response!\n");
+			ret = -ETIMEDOUT;
+			goto err_irqrestore;
+		}
+
+		dev_dbg(priv->dev, "No valid response!\n");
+		ret = -EIO;
+		goto err_irqrestore;
+	}
+
+	/*
+	 * Note that rx_len and rx_buf size can be an odd number.
+	 * Byte handling is more efficient.
+	 */
+	for (i = 0; i < msg->rx_len; i++) {
+		u8 byte_offset = i % 4;
+
+		if (byte_offset == 0) {
+			reg = i < 16 ? ASPEED_PECI_R_DATA0 + i % 16 :
+				       ASPEED_PECI_R_DATA4 + i % 16;
+			rx_data = readl(priv->base + reg);
+		}
+
+		msg->rx_buf[i] = (u8)(rx_data >> (byte_offset << 3));
+	}
+
+	print_hex_dump_debug("RX : ", DUMP_PREFIX_NONE, 16, 1,
+			     msg->rx_buf, msg->rx_len, true);
+
+	peci_state = readl(priv->base + ASPEED_PECI_CMD);
+	dev_dbg(priv->dev, "PECI_STATE : 0x%lx\n",
+		FIELD_GET(ASPEED_PECI_CMD_STS_MASK, peci_state));
+	dev_dbg(priv->dev, "------------------------\n");
+
+err_irqrestore:
+	spin_unlock_irqrestore(&priv->lock, flags);
+
+	return ret;
+}
+
+static irqreturn_t aspeed_peci_irq_handler(int irq, void *arg)
+{
+	struct aspeed_peci *priv = arg;
+	u32 status;
+
+	spin_lock(&priv->lock);
+	status = readl(priv->base + ASPEED_PECI_INT_STS);
+	writel(status, priv->base + ASPEED_PECI_INT_STS);
+	priv->status |= (status & ASPEED_PECI_INT_MASK);
+
+	/*
+	 * In most cases, interrupt bits will be set one by one but also note
+	 * that multiple interrupt bits could be set at the same time.
+	 */
+	if (status & ASPEED_PECI_INT_BUS_TIMEOUT)
+		dev_dbg(priv->dev, "ASPEED_PECI_INT_BUS_TIMEOUT\n");
+
+	if (status & ASPEED_PECI_INT_BUS_CONNECT)
+		dev_dbg(priv->dev, "ASPEED_PECI_INT_BUS_CONNECT\n");
+
+	if (status & ASPEED_PECI_INT_W_FCS_BAD)
+		dev_dbg(priv->dev, "ASPEED_PECI_INT_W_FCS_BAD\n");
+
+	if (status & ASPEED_PECI_INT_W_FCS_ABORT)
+		dev_dbg(priv->dev, "ASPEED_PECI_INT_W_FCS_ABORT\n");
+
+	/*
+	 * All commands should be ended up with a ASPEED_PECI_INT_CMD_DONE bit
+	 * set even in an error case.
+	 */
+	if (status & ASPEED_PECI_INT_CMD_DONE) {
+		dev_dbg(priv->dev, "ASPEED_PECI_INT_CMD_DONE\n");
+		complete(&priv->xfer_complete);
+	}
+
+	spin_unlock(&priv->lock);
+
+	return IRQ_HANDLED;
+}
+
+static int aspeed_peci_init_ctrl(struct aspeed_peci *priv)
+{
+	u32 msg_timing, addr_timing, rd_sampling_point;
+	u32 clk_freq, clk_divisor, clk_div_val = 0;
+	int ret;
+
+	priv->clk = devm_clk_get(priv->dev, NULL);
+	if (IS_ERR(priv->clk)) {
+		dev_err(priv->dev, "Failed to get clk source.\n");
+		return PTR_ERR(priv->clk);
+	}
+
+	ret = clk_prepare_enable(priv->clk);
+	if (ret) {
+		dev_err(priv->dev, "Failed to enable clock.\n");
+		return ret;
+	}
+
+	ret = device_property_read_u32(priv->dev, "clock-frequency", &clk_freq);
+	if (ret) {
+		dev_err(priv->dev,
+			"Could not read clock-frequency property.\n");
+		clk_disable_unprepare(priv->clk);
+		return ret;
+	}
+
+	clk_divisor = clk_get_rate(priv->clk) / clk_freq;
+
+	while ((clk_divisor >>= 1) && (clk_div_val < ASPEED_PECI_CLK_DIV_MAX))
+		clk_div_val++;
+	priv->clk_div_val = clk_div_val;
+
+	ret = device_property_read_u32(priv->dev, "msg-timing", &msg_timing);
+	if (ret || msg_timing > ASPEED_PECI_MSG_TIMING_MAX) {
+		if (!ret)
+			dev_warn(priv->dev,
+				 "Invalid msg-timing : %u, Use default : %u\n",
+				 msg_timing, ASPEED_PECI_MSG_TIMING_DEFAULT);
+		msg_timing = ASPEED_PECI_MSG_TIMING_DEFAULT;
+	}
+	priv->msg_timing = msg_timing;
+
+	ret = device_property_read_u32(priv->dev, "addr-timing", &addr_timing);
+	if (ret || addr_timing > ASPEED_PECI_ADDR_TIMING_MAX) {
+		if (!ret)
+			dev_warn(priv->dev,
+				 "Invalid addr-timing : %u, Use default : %u\n",
+				 addr_timing, ASPEED_PECI_ADDR_TIMING_DEFAULT);
+		addr_timing = ASPEED_PECI_ADDR_TIMING_DEFAULT;
+	}
+	priv->addr_timing = addr_timing;
+
+	ret = device_property_read_u32(priv->dev, "rd-sampling-point",
+				       &rd_sampling_point);
+	if (ret || rd_sampling_point > ASPEED_PECI_RD_SAMPLING_POINT_MAX) {
+		if (!ret)
+			dev_warn(priv->dev,
+				 "Invalid rd-sampling-point : %u. Use default : %u\n",
+				 rd_sampling_point,
+				 ASPEED_PECI_RD_SAMPLING_POINT_DEFAULT);
+		rd_sampling_point = ASPEED_PECI_RD_SAMPLING_POINT_DEFAULT;
+	}
+	priv->rd_sampling_point = rd_sampling_point;
+
+	ret = device_property_read_u32(priv->dev, "cmd-timeout-ms",
+				       &priv->cmd_timeout_ms);
+	if (ret || priv->cmd_timeout_ms > ASPEED_PECI_CMD_TIMEOUT_MS_MAX ||
+	    priv->cmd_timeout_ms == 0) {
+		if (!ret)
+			dev_warn(priv->dev,
+				 "Invalid cmd-timeout-ms : %u. Use default : %u\n",
+				 priv->cmd_timeout_ms,
+				 ASPEED_PECI_CMD_TIMEOUT_MS_DEFAULT);
+		priv->cmd_timeout_ms = ASPEED_PECI_CMD_TIMEOUT_MS_DEFAULT;
+	}
+
+	aspeed_peci_init_regs(priv);
+
+	return 0;
+}
+
+static int aspeed_peci_probe(struct platform_device *pdev)
+{
+	struct peci_adapter *adapter;
+	struct aspeed_peci *priv;
+	int ret;
+
+	adapter = peci_alloc_adapter(&pdev->dev, sizeof(*priv));
+	if (!adapter)
+		return -ENOMEM;
+
+	priv = peci_get_adapdata(adapter);
+	priv->adapter = adapter;
+	priv->dev = &pdev->dev;
+	dev_set_drvdata(&pdev->dev, priv);
+
+	priv->base = devm_platform_ioremap_resource(pdev, 0);
+	if (IS_ERR(priv->base)) {
+		ret = PTR_ERR(priv->base);
+		goto err_put_adapter_dev;
+	}
+
+	priv->irq = platform_get_irq(pdev, 0);
+	if (!priv->irq) {
+		ret = -ENODEV;
+		goto err_put_adapter_dev;
+	}
+
+	ret = devm_request_irq(&pdev->dev, priv->irq, aspeed_peci_irq_handler,
+			       0, "peci-aspeed-irq", priv);
+	if (ret)
+		goto err_put_adapter_dev;
+
+	init_completion(&priv->xfer_complete);
+	spin_lock_init(&priv->lock);
+
+	priv->adapter->owner = THIS_MODULE;
+	priv->adapter->dev.of_node = of_node_get(dev_of_node(priv->dev));
+	strlcpy(priv->adapter->name, pdev->name, sizeof(priv->adapter->name));
+	priv->adapter->xfer = aspeed_peci_xfer;
+	priv->adapter->use_dma = false;
+
+	priv->rst = devm_reset_control_get(&pdev->dev, NULL);
+	if (IS_ERR(priv->rst)) {
+		dev_err(&pdev->dev,
+			"missing or invalid reset controller entry\n");
+		ret = PTR_ERR(priv->rst);
+		goto err_put_adapter_dev;
+	}
+	reset_control_deassert(priv->rst);
+
+	ret = aspeed_peci_init_ctrl(priv);
+	if (ret)
+		goto err_put_adapter_dev;
+
+	ret = peci_add_adapter(priv->adapter);
+	if (ret)
+		goto err_put_adapter_dev;
+
+	dev_info(&pdev->dev, "peci bus %d registered, irq %d\n",
+		 priv->adapter->nr, priv->irq);
+
+	return 0;
+
+err_put_adapter_dev:
+	put_device(&adapter->dev);
+
+	return ret;
+}
+
+static int aspeed_peci_remove(struct platform_device *pdev)
+{
+	struct aspeed_peci *priv = dev_get_drvdata(&pdev->dev);
+
+	peci_del_adapter(priv->adapter);
+	complete(&priv->xfer_complete);
+	clk_disable_unprepare(priv->clk);
+	reset_control_assert(priv->rst);
+	of_node_put(priv->adapter->dev.of_node);
+
+	return 0;
+}
+
+static const struct of_device_id aspeed_peci_of_table[] = {
+	{ .compatible = "aspeed,ast2400-peci", },
+	{ .compatible = "aspeed,ast2500-peci", },
+	{ .compatible = "aspeed,ast2600-peci", },
+	{ }
+};
+MODULE_DEVICE_TABLE(of, aspeed_peci_of_table);
+
+static struct platform_driver aspeed_peci_driver = {
+	.probe  = aspeed_peci_probe,
+	.remove = aspeed_peci_remove,
+	.driver = {
+		.name           = KBUILD_MODNAME,
+		.of_match_table = of_match_ptr(aspeed_peci_of_table),
+	},
+};
+module_platform_driver(aspeed_peci_driver);
+
+MODULE_AUTHOR("Ryan Chen <ryan_chen@aspeedtech.com>");
+MODULE_AUTHOR("Jae Hyun Yoo <jae.hyun.yoo@linux.intel.com>");
+MODULE_DESCRIPTION("ASPEED PECI driver");
+MODULE_LICENSE("GPL v2");
diff --git a/drivers/peci/busses/peci-mctp.c b/drivers/peci/busses/peci-mctp.c
new file mode 100644
index 000000000000..79833ad8a12a
--- /dev/null
+++ b/drivers/peci/busses/peci-mctp.c
@@ -0,0 +1,450 @@
+// SPDX-License-Identifier: GPL-2.0
+// Copyright (c) 2020 Intel Corporation
+
+#include <linux/aspeed-mctp.h>
+#include <linux/jiffies.h>
+#include <linux/module.h>
+#include <linux/peci.h>
+#include <linux/platform_device.h>
+
+#define PCIE_SET_DATA_LEN(x, val)	((x)->len_lo |= (val))
+#define PCIE_GET_DATA_LEN(x)		((x)->len_lo)
+#define PCIE_GET_PAD_LEN(x)		(((x)->tag >> 4) & 0x3)
+#define PCIE_SET_TARGET_ID(x, val)	((x)->target |= (swab16(val)))
+#define PCIE_PKT_ALIGN(x)		ALIGN(x, sizeof(u32))
+#define PCIE_GET_REQUESTER_ID(x)	(swab16((x)->requester))
+
+/*
+ * PCIe header template in "network format" - Big Endian
+ */
+#define MSG_4DW_HDR_ROUTE_BY_ID	0x72
+#define MSG_CODE_VDM_TYPE_1	0x7f
+#define VENDOR_ID_DMTF_VDM	0xb41a
+static const struct pcie_transport_hdr pcie_hdr_template_be = {
+	.fmt_type = MSG_4DW_HDR_ROUTE_BY_ID,
+	.code = MSG_CODE_VDM_TYPE_1,
+	.vendor = VENDOR_ID_DMTF_VDM
+};
+
+#define MSG_TAG_MASK			GENMASK(2, 0)
+#define MCTP_SET_MSG_TAG(x, val)	((x)->flags_seq_tag |= ((val) & MSG_TAG_MASK))
+#define MCTP_GET_MSG_TAG(x)		((x)->flags_seq_tag & MSG_TAG_MASK)
+#define MCTP_HDR_VERSION		1
+#define REQUEST_FLAGS			0xc8
+#define RESPONSE_FLAGS			0xc0
+static const struct mctp_protocol_hdr mctp_hdr_template_be = {
+	.ver = MCTP_HDR_VERSION,
+	.flags_seq_tag = REQUEST_FLAGS
+};
+
+struct mctp_peci_vdm_hdr {
+	u8 type;
+	u16 vendor_id;
+	u8 instance_req_d;
+	u8 vendor_code;
+} __packed;
+
+#define PCIE_VDM_TYPE	0x7e
+#define INTEL_VENDOR_ID	0x8680
+#define PECI_REQUEST	0x80
+#define PECI_RESPONSE	0
+#define PECI_MSG_OPCODE	0x02
+static const struct mctp_peci_vdm_hdr peci_hdr_template = {
+	.type = PCIE_VDM_TYPE,
+	.vendor_id = INTEL_VENDOR_ID,
+	.instance_req_d = PECI_REQUEST,
+	.vendor_code = PECI_MSG_OPCODE
+};
+
+#define PECI_VDM_TYPE	0x0200
+#define PECI_VDM_MASK	0xff00
+
+#define CPUNODEID_CFG_LCLNODEID_MASK	GENMASK(2, 0)
+#define CPUNODEID_CFG_OFFSET	0xc0
+#define CPUNODEID_CFG_BUS	0x1e
+#define CPUNODEID_CFG_DEV	0
+#define CPUNODEID_CFG_FUNC	0
+
+struct node_cfg {
+	u8 eid;
+	u16 bdf;
+	u8 domain_id;
+};
+
+struct mctp_peci {
+	struct peci_adapter *adapter;
+	struct device *dev;
+	struct mctp_client *peci_client;
+	struct node_cfg cpus[PECI_OFFSET_MAX][DOMAIN_OFFSET_MAX];
+	bool is_discovery_done;
+	u8 tag;
+};
+
+static void
+prepare_tx_packet(struct mctp_pcie_packet *tx_packet, struct node_cfg *cpu,
+		  u8 tx_len, u8 rx_len, u8 *tx_buf, u8 tag)
+{
+	struct pcie_transport_hdr *pcie_hdr;
+	struct mctp_protocol_hdr *mctp_hdr;
+	struct mctp_peci_vdm_hdr *peci_hdr;
+	u8 *peci_payload;
+	u32 payload_len, payload_len_dw;
+
+	BUILD_BUG_ON((sizeof(struct pcie_transport_hdr) +
+		     sizeof(struct mctp_protocol_hdr)) != PCIE_VDM_HDR_SIZE);
+
+	pcie_hdr = (struct pcie_transport_hdr *)tx_packet;
+	*pcie_hdr = pcie_hdr_template_be;
+
+	mctp_hdr = (struct mctp_protocol_hdr *)&tx_packet->data.hdr[3];
+	*mctp_hdr = mctp_hdr_template_be;
+
+	peci_hdr = (struct mctp_peci_vdm_hdr *)tx_packet->data.payload;
+	*peci_hdr = peci_hdr_template;
+
+	peci_payload = (u8 *)(tx_packet->data.payload) + sizeof(struct mctp_peci_vdm_hdr);
+	peci_payload[0] = tx_len;
+	peci_payload[1] = rx_len;
+	memcpy(&peci_payload[2], tx_buf, tx_len);
+
+	/*
+	 * MCTP packet payload consists of PECI VDM header, WL, RL and actual
+	 * PECI payload
+	 */
+	payload_len = sizeof(struct mctp_peci_vdm_hdr) + 2 + tx_len;
+	payload_len_dw = PCIE_PKT_ALIGN(payload_len) / sizeof(u32);
+
+	PCIE_SET_DATA_LEN(pcie_hdr, payload_len_dw);
+
+	tx_packet->size = PCIE_PKT_ALIGN(payload_len) + PCIE_VDM_HDR_SIZE;
+
+	mctp_hdr->dest = cpu->eid;
+	PCIE_SET_TARGET_ID(pcie_hdr, cpu->bdf);
+	MCTP_SET_MSG_TAG(mctp_hdr, tag);
+}
+
+static int
+verify_rx_packet(struct peci_adapter *adapter, struct mctp_pcie_packet *rx_packet,
+		 struct node_cfg *cpu, u8 tag)
+{
+	struct mctp_peci *priv = peci_get_adapdata(adapter);
+	bool invalid_packet = false;
+	struct pcie_transport_hdr *pcie_hdr;
+	struct mctp_protocol_hdr *mctp_hdr;
+	struct mctp_peci_vdm_hdr *peci_hdr;
+	u8 expected_flags;
+	u16 requester_id;
+
+	expected_flags = (RESPONSE_FLAGS | (tag & MSG_TAG_MASK));
+
+	pcie_hdr = (struct pcie_transport_hdr *)rx_packet;
+	mctp_hdr = (struct mctp_protocol_hdr *)&rx_packet->data.hdr[3];
+	peci_hdr = (struct mctp_peci_vdm_hdr *)rx_packet->data.payload;
+
+	requester_id = PCIE_GET_REQUESTER_ID(pcie_hdr);
+
+	if (requester_id != cpu->bdf) {
+		dev_dbg(priv->dev,
+			"mismatch in src bdf: expected: 0x%.4x, got: 0x%.4x",
+			cpu->bdf, requester_id);
+		invalid_packet = true;
+	}
+	if (mctp_hdr->src != cpu->eid) {
+		dev_dbg(priv->dev,
+			"mismatch in src eid: expected: 0x%.2x, got: 0x%.2x",
+			cpu->eid, mctp_hdr->src);
+		invalid_packet = true;
+	}
+	if (mctp_hdr->flags_seq_tag != expected_flags) {
+		dev_dbg(priv->dev,
+			"mismatch in mctp flags: expected: 0x%.2x, got: 0x%.2x",
+			expected_flags, mctp_hdr->flags_seq_tag);
+		invalid_packet = true;
+	}
+	if (peci_hdr->instance_req_d != PECI_RESPONSE) {
+		dev_dbg(priv->dev,
+			"packet doesn't match a response: expected: 0x%.2x, got: 0x%.2x",
+			PECI_RESPONSE, peci_hdr->instance_req_d);
+		invalid_packet = true;
+	}
+
+	if (invalid_packet) {
+		dev_warn_ratelimited(priv->dev, "unexpected peci response found\n");
+		return -EIO;
+	}
+
+	return 0;
+}
+
+static struct mctp_pcie_packet *
+mctp_peci_send_receive(struct peci_adapter *adapter, struct node_cfg *cpu,
+		       u8 tx_len, u8 rx_len, u8 *tx_buf)
+{
+	struct mctp_peci *priv = peci_get_adapdata(adapter);
+	/* XXX: Sporadically it can take up to 1100 ms for response to arrive */
+	unsigned long timeout = msecs_to_jiffies(1100);
+	u8 tag = priv->tag;
+	struct mctp_pcie_packet *tx_packet, *rx_packet;
+	unsigned long current_time, end_time;
+	struct pcie_transport_hdr *pcie_hdr;
+	u32 payload_len, rx_packet_size;
+	int ret;
+
+	tx_packet = aspeed_mctp_packet_alloc(GFP_KERNEL);
+	if (!tx_packet)
+		return ERR_PTR(-ENOMEM);
+
+	prepare_tx_packet(tx_packet, cpu, tx_len, rx_len, tx_buf, tag);
+
+	aspeed_mctp_flush_rx_queue(priv->peci_client);
+
+	print_hex_dump_bytes("TX : ", DUMP_PREFIX_NONE, &tx_packet->data, tx_packet->size);
+
+	ret = aspeed_mctp_send_packet(priv->peci_client, tx_packet);
+	if (ret) {
+		dev_dbg_ratelimited(priv->dev, "failed to send mctp packet: %d\n", ret);
+		aspeed_mctp_packet_free(tx_packet);
+		return ERR_PTR(ret);
+	}
+	priv->tag++;
+
+	end_time = jiffies + timeout;
+retry:
+	rx_packet = aspeed_mctp_receive_packet(priv->peci_client, timeout);
+	if (IS_ERR(rx_packet)) {
+		if (PTR_ERR(rx_packet) != -ERESTARTSYS)
+			dev_err_ratelimited(priv->dev, "failed to receive mctp packet: %ld\n",
+					    PTR_ERR(rx_packet));
+
+		return rx_packet;
+	}
+	BUG_ON(!rx_packet);
+
+	ret = verify_rx_packet(adapter, rx_packet, cpu, tag);
+	current_time = jiffies;
+	if (ret && time_before(current_time, end_time)) {
+		aspeed_mctp_packet_free(rx_packet);
+		timeout = ((long)end_time - (long)current_time);
+		goto retry;
+	}
+
+	pcie_hdr = (struct pcie_transport_hdr *)rx_packet;
+	payload_len = PCIE_GET_DATA_LEN(pcie_hdr) * sizeof(u32) - PCIE_GET_PAD_LEN(pcie_hdr);
+	rx_packet_size = payload_len + PCIE_VDM_HDR_SIZE;
+	print_hex_dump_bytes("RX : ", DUMP_PREFIX_NONE, &rx_packet->data, rx_packet_size);
+
+	return rx_packet;
+}
+
+static void mctp_peci_cpu_discovery(struct peci_adapter *adapter)
+{
+	const u8 eids[] = { 0x1d, 0x3d, 0x5d, 0x7d, 0x9d, 0xbd, 0xdd, 0xfd };
+	struct mctp_peci *priv = peci_get_adapdata(adapter);
+	u8 tx_buf[PECI_RDENDPTCFG_PCI_WRITE_LEN];
+	struct mctp_pcie_packet *rx_packet;
+	struct node_cfg cpu;
+	int i, domain_id, node_id, ret;
+	bool is_discovery_done = false;
+	u8 *rx_buf;
+	u32 addr;
+
+	addr = CPUNODEID_CFG_OFFSET;     /* [11:0] offset */
+	addr |= CPUNODEID_CFG_FUNC << 12;/* [14:12] function */
+	addr |= CPUNODEID_CFG_DEV << 15; /* [19:15] device */
+	addr |= CPUNODEID_CFG_BUS << 20; /* [27:20] bus, [31:28] reserved */
+
+	tx_buf[0] = PECI_RDENDPTCFG_CMD;
+	tx_buf[1] = 0;
+	tx_buf[2] = PECI_ENDPTCFG_TYPE_LOCAL_PCI;
+	tx_buf[3] = 0; /* Endpoint ID */
+	tx_buf[4] = 0; /* Reserved */
+	tx_buf[5] = 0; /* Reserved */
+	tx_buf[6] = PECI_ENDPTCFG_ADDR_TYPE_PCI;
+	tx_buf[7] = 0; /* PCI Segment */
+	tx_buf[8] = (u8)addr;
+	tx_buf[9] = (u8)(addr >> 8);
+	tx_buf[10] = (u8)(addr >> 16);
+	tx_buf[11] = (u8)(addr >> 24);
+
+	for (i = 0; i < PECI_OFFSET_MAX; i++) {
+		memset(&cpu, 0, sizeof(cpu));
+		cpu.eid = eids[i];
+		ret = aspeed_mctp_get_eid_bdf(priv->peci_client, cpu.eid, &cpu.bdf);
+		if (ret)
+			continue;
+
+		for (domain_id = 0; domain_id < DOMAIN_OFFSET_MAX; domain_id++) {
+			ret = aspeed_mctp_get_eid(priv->peci_client,
+						  cpu.bdf, domain_id,
+						  &cpu.eid);
+
+			/* No entries for specific BDF/domain_Id. */
+			if (ret)
+				continue;
+
+			rx_packet = mctp_peci_send_receive(adapter, &cpu,
+							   PECI_RDENDPTCFG_PCI_WRITE_LEN,
+							   PECI_RDENDPTCFG_READ_LEN_BASE + 4,
+							   tx_buf);
+
+			if (IS_ERR(rx_packet)) {
+				dev_warn(priv->dev, "Device EID=%d DomainId=%d not discovered\n",
+					 cpu.eid, cpu.domain_id);
+				continue;
+			}
+
+			rx_buf = (u8 *)(rx_packet->data.payload) + sizeof(struct mctp_peci_vdm_hdr);
+			node_id = rx_buf[1] & CPUNODEID_CFG_LCLNODEID_MASK;
+			if (node_id < PECI_OFFSET_MAX) {
+				is_discovery_done = true;
+				priv->cpus[node_id][domain_id] = cpu;
+			} else {
+				dev_warn(priv->dev, "Incorrect node_id=%d (EID=%d DomainId=%d)\n",
+					 node_id, cpu.eid, cpu.domain_id);
+			}
+			aspeed_mctp_packet_free(rx_packet);
+		}
+	}
+	priv->is_discovery_done = is_discovery_done;
+}
+
+static int
+mctp_peci_get_address(struct peci_adapter *adapter, u8 peci_addr, u8 domain_id,
+		      struct node_cfg *cpu)
+{
+	struct mctp_peci *priv = peci_get_adapdata(adapter);
+	int node_id = peci_addr - 0x30;
+
+	/*
+	 * XXX: Is it possible we're able to communicate with CPU 0 before other
+	 * CPUs are up? Make sure we're always discovering all CPUs.
+	 */
+	if (!priv->is_discovery_done)
+		mctp_peci_cpu_discovery(adapter);
+
+	if (node_id < PECI_OFFSET_MAX && domain_id < DOMAIN_OFFSET_MAX &&
+	    priv->is_discovery_done && priv->cpus[node_id][domain_id].eid) {
+		*cpu = priv->cpus[node_id][domain_id];
+		return 0;
+	}
+
+	return -EINVAL;
+}
+
+static int
+mctp_peci_xfer(struct peci_adapter *adapter, struct peci_xfer_msg *msg)
+{
+	u32 max_len = sizeof(struct mctp_pcie_packet_data) -
+		PCIE_VDM_HDR_SIZE - sizeof(struct mctp_peci_vdm_hdr);
+	struct mctp_pcie_packet *rx_packet;
+	struct node_cfg cpu;
+	u8 domain_id = 0;
+	int ret;
+
+	if (msg->tx_len > max_len || msg->rx_len > max_len)
+		return -EINVAL;
+
+	if (msg->tx_len > 2)
+		domain_id = (msg->tx_buf[1]  >> 1);
+
+	ret = mctp_peci_get_address(adapter, msg->addr, domain_id, &cpu);
+	if (ret)
+		return ret;
+
+	rx_packet = mctp_peci_send_receive(adapter, &cpu, msg->tx_len, msg->rx_len, msg->tx_buf);
+	if (IS_ERR(rx_packet))
+		return PTR_ERR(rx_packet);
+
+	memcpy(msg->rx_buf,
+	       (u8 *)(rx_packet->data.payload) + sizeof(struct mctp_peci_vdm_hdr),
+	       msg->rx_len);
+
+	aspeed_mctp_packet_free(rx_packet);
+
+	return 0;
+}
+
+static int mctp_peci_init_peci_client(struct mctp_peci *priv)
+{
+	struct device *parent = priv->dev->parent;
+	int ret;
+
+	priv->peci_client = aspeed_mctp_create_client(dev_get_drvdata(parent));
+	if (IS_ERR(priv->peci_client))
+		return -ENOMEM;
+
+	ret = aspeed_mctp_add_type_handler(priv->peci_client, PCIE_VDM_TYPE,
+					   INTEL_VENDOR_ID, PECI_VDM_TYPE,
+					   PECI_VDM_MASK);
+	if (ret)
+		aspeed_mctp_delete_client(priv->peci_client);
+
+	return ret;
+}
+
+static int mctp_peci_probe(struct platform_device *pdev)
+{
+	struct peci_adapter *adapter;
+	struct mctp_peci *priv;
+	int ret;
+
+	adapter = peci_alloc_adapter(&pdev->dev, sizeof(*priv));
+	if (!adapter)
+		return -ENOMEM;
+
+	priv = peci_get_adapdata(adapter);
+	priv->dev = &pdev->dev;
+	dev_set_drvdata(&pdev->dev, priv);
+
+	adapter->owner = THIS_MODULE;
+	strlcpy(adapter->name, pdev->name, sizeof(adapter->name));
+
+	adapter->xfer = mctp_peci_xfer;
+	adapter->peci_revision = 0x41;
+
+	priv->adapter = adapter;
+
+	ret = mctp_peci_init_peci_client(priv);
+	if (ret)
+		goto out_put_device;
+
+	ret = peci_add_adapter(adapter);
+	if (ret)
+		goto out_del_client;
+
+	return 0;
+
+out_del_client:
+	aspeed_mctp_delete_client(priv->peci_client);
+out_put_device:
+	put_device(&adapter->dev);
+	return ret;
+}
+
+static int mctp_peci_remove(struct platform_device *pdev)
+{
+	struct mctp_peci *priv = dev_get_drvdata(&pdev->dev);
+
+	if (!priv)
+		goto out;
+
+	aspeed_mctp_delete_client(priv->peci_client);
+
+	peci_del_adapter(priv->adapter);
+out:
+	return 0;
+}
+
+static struct platform_driver mctp_peci_driver = {
+	.probe  = mctp_peci_probe,
+	.remove = mctp_peci_remove,
+	.driver = {
+		.name = "peci-mctp",
+	},
+};
+module_platform_driver(mctp_peci_driver);
+
+MODULE_ALIAS("platform:peci-mctp");
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR("Iwona Winiarska <iwona.winiarska@intel.com>");
+MODULE_DESCRIPTION("PECI MCTP driver");
diff --git a/drivers/peci/busses/peci-npcm.c b/drivers/peci/busses/peci-npcm.c
new file mode 100644
index 000000000000..bdebbf1ec7f1
--- /dev/null
+++ b/drivers/peci/busses/peci-npcm.c
@@ -0,0 +1,406 @@
+// SPDX-License-Identifier: GPL-2.0
+// Copyright (c) 2019 Nuvoton Technology corporation.
+
+#include <linux/bitfield.h>
+#include <linux/clk.h>
+#include <linux/interrupt.h>
+#include <linux/jiffies.h>
+#include <linux/module.h>
+#include <linux/of.h>
+#include <linux/peci.h>
+#include <linux/platform_device.h>
+#include <linux/regmap.h>
+#include <linux/mfd/syscon.h>
+#include <linux/reset.h>
+
+/* NPCM7xx GCR module */
+#define NPCM7XX_INTCR3_OFFSET			0x9C
+#define NPCM7XX_INTCR3_PECIVSEL			BIT(19)
+
+/* NPCM PECI Registers */
+#define NPCM_PECI_CTL_STS			0x00
+#define NPCM_PECI_RD_LENGTH			0x04
+#define NPCM_PECI_ADDR				0x08
+#define NPCM_PECI_CMD				0x0C
+#define NPCM_PECI_CTL2				0x10
+#define NPCM_PECI_WR_LENGTH			0x1C
+#define NPCM_PECI_PDDR				0x2C
+#define NPCM_PECI_DAT_INOUT(n)			(0x100 + ((n) * 4))
+
+#define NPCM_PECI_MAX_REG			0x200
+
+/* NPCM_PECI_CTL_STS - 0x00 : Control Register */
+#define NPCM_PECI_CTRL_DONE_INT_EN		BIT(6)
+#define NPCM_PECI_CTRL_ABRT_ERR			BIT(4)
+#define NPCM_PECI_CTRL_CRC_ERR			BIT(3)
+#define NPCM_PECI_CTRL_DONE			BIT(1)
+#define NPCM_PECI_CTRL_START_BUSY		BIT(0)
+
+/* NPCM_PECI_RD_LENGTH - 0x04 : Command Register */
+#define NPCM_PECI_RD_LEN_MASK			GENMASK(6, 0)
+
+/* NPCM_PECI_CMD - 0x10 : Command Register */
+#define NPCM_PECI_CTL2_MASK			GENMASK(7, 6)
+
+/* NPCM_PECI_WR_LENGTH - 0x1C : Command Register */
+#define NPCM_PECI_WR_LEN_MASK			GENMASK(6, 0)
+
+/* NPCM_PECI_PDDR - 0x2C : Command Register */
+#define NPCM_PECI_PDDR_MASK			GENMASK(4, 0)
+
+#define NPCM_PECI_INT_MASK			\
+	(NPCM_PECI_CTRL_ABRT_ERR | NPCM_PECI_CTRL_CRC_ERR | NPCM_PECI_CTRL_DONE)
+
+#define NPCM_PECI_IDLE_CHECK_TIMEOUT_USEC	50000
+#define NPCM_PECI_IDLE_CHECK_INTERVAL_USEC	10000
+#define NPCM_PECI_CMD_TIMEOUT_MS_DEFAULT	1000
+#define NPCM_PECI_CMD_TIMEOUT_MS_MAX		60000
+#define NPCM_PECI_HOST_NEG_BIT_RATE_MAX		31
+#define NPCM_PECI_HOST_NEG_BIT_RATE_MIN		7
+#define NPCM_PECI_HOST_NEG_BIT_RATE_DEFAULT	15
+#define NPCM_PECI_PULL_DOWN_DEFAULT		0
+#define NPCM_PECI_PULL_DOWN_MAX			2
+
+struct npcm_peci {
+	u32			cmd_timeout_ms;
+	u32			host_bit_rate;
+	struct completion	xfer_complete;
+	struct regmap		*gcr_regmap;
+	struct peci_adapter	*adapter;
+	struct regmap		*regmap;
+	u32			status;
+	spinlock_t		lock; /* to sync completion status handling */
+	struct device		*dev;
+	struct clk		*clk;
+	int			irq;
+};
+
+static int npcm_peci_xfer_native(struct npcm_peci *priv,
+				 struct peci_xfer_msg *msg)
+{
+	long err, timeout = msecs_to_jiffies(priv->cmd_timeout_ms);
+	unsigned long flags;
+	unsigned int msg_rd;
+	u32 cmd_sts;
+	int i, rc;
+
+	/* Check command sts and bus idle state */
+	rc = regmap_read_poll_timeout(priv->regmap, NPCM_PECI_CTL_STS, cmd_sts,
+				      !(cmd_sts & NPCM_PECI_CTRL_START_BUSY),
+				      NPCM_PECI_IDLE_CHECK_INTERVAL_USEC,
+				      NPCM_PECI_IDLE_CHECK_TIMEOUT_USEC);
+	if (rc)
+		return rc; /* -ETIMEDOUT */
+
+	spin_lock_irqsave(&priv->lock, flags);
+	reinit_completion(&priv->xfer_complete);
+
+	regmap_write(priv->regmap, NPCM_PECI_ADDR, msg->addr);
+	regmap_write(priv->regmap, NPCM_PECI_RD_LENGTH,
+		     NPCM_PECI_WR_LEN_MASK & msg->rx_len);
+	regmap_write(priv->regmap, NPCM_PECI_WR_LENGTH,
+		     NPCM_PECI_WR_LEN_MASK & msg->tx_len);
+
+	if (msg->tx_len) {
+		regmap_write(priv->regmap, NPCM_PECI_CMD, msg->tx_buf[0]);
+
+		for (i = 0; i < (msg->tx_len - 1); i++)
+			regmap_write(priv->regmap, NPCM_PECI_DAT_INOUT(i),
+				     msg->tx_buf[i + 1]);
+	}
+
+	priv->status = 0;
+	regmap_update_bits(priv->regmap, NPCM_PECI_CTL_STS,
+			   NPCM_PECI_CTRL_START_BUSY,
+			   NPCM_PECI_CTRL_START_BUSY);
+
+	spin_unlock_irqrestore(&priv->lock, flags);
+
+	err = wait_for_completion_interruptible_timeout(&priv->xfer_complete,
+							timeout);
+
+	spin_lock_irqsave(&priv->lock, flags);
+
+	regmap_write(priv->regmap, NPCM_PECI_CMD, 0);
+
+	if (err <= 0 || priv->status != NPCM_PECI_CTRL_DONE) {
+		if (err < 0) { /* -ERESTARTSYS */
+			rc = (int)err;
+			goto err_irqrestore;
+		} else if (err == 0) {
+			dev_dbg(priv->dev, "Timeout waiting for a response!\n");
+			rc = -ETIMEDOUT;
+			goto err_irqrestore;
+		}
+
+		dev_dbg(priv->dev, "No valid response!\n");
+		rc = -EIO;
+		goto err_irqrestore;
+	}
+
+	for (i = 0; i < msg->rx_len; i++) {
+		regmap_read(priv->regmap, NPCM_PECI_DAT_INOUT(i), &msg_rd);
+		msg->rx_buf[i] = (u8)msg_rd;
+	}
+
+err_irqrestore:
+	spin_unlock_irqrestore(&priv->lock, flags);
+	return rc;
+}
+
+static irqreturn_t npcm_peci_irq_handler(int irq, void *arg)
+{
+	struct npcm_peci *priv = arg;
+	u32 status_ack = 0;
+	u32 status;
+
+	spin_lock(&priv->lock);
+	regmap_read(priv->regmap, NPCM_PECI_CTL_STS, &status);
+	priv->status |= (status & NPCM_PECI_INT_MASK);
+
+	if (status & NPCM_PECI_CTRL_CRC_ERR) {
+		dev_dbg(priv->dev, "PECI_INT_W_FCS_BAD\n");
+		status_ack |= NPCM_PECI_CTRL_CRC_ERR;
+	}
+
+	if (status & NPCM_PECI_CTRL_ABRT_ERR) {
+		dev_dbg(priv->dev, "NPCM_PECI_CTRL_ABRT_ERR\n");
+		status_ack |= NPCM_PECI_CTRL_ABRT_ERR;
+	}
+
+	/*
+	 * All commands should be ended up with a NPCM_PECI_CTRL_DONE
+	 * bit set even in an error case.
+	 */
+	if (status & NPCM_PECI_CTRL_DONE) {
+		dev_dbg(priv->dev, "NPCM_PECI_CTRL_DONE\n");
+		status_ack |= NPCM_PECI_CTRL_DONE;
+		complete(&priv->xfer_complete);
+	}
+
+	regmap_write_bits(priv->regmap, NPCM_PECI_CTL_STS,
+			  NPCM_PECI_INT_MASK, status_ack);
+
+	spin_unlock(&priv->lock);
+	return IRQ_HANDLED;
+}
+
+static int npcm_peci_init_ctrl(struct npcm_peci *priv)
+{
+	u32 cmd_sts, host_neg_bit_rate = 0, pull_down = 0;
+	int ret;
+
+	priv->clk = devm_clk_get(priv->dev, NULL);
+	if (IS_ERR(priv->clk)) {
+		dev_err(priv->dev, "Failed to get clk source.\n");
+		return PTR_ERR(priv->clk);
+	}
+
+	ret = clk_prepare_enable(priv->clk);
+	if (ret) {
+		dev_err(priv->dev, "Failed to enable clock.\n");
+		return ret;
+	}
+
+	ret = of_property_read_u32(priv->dev->of_node, "cmd-timeout-ms",
+				   &priv->cmd_timeout_ms);
+	if (ret || priv->cmd_timeout_ms > NPCM_PECI_CMD_TIMEOUT_MS_MAX ||
+	    priv->cmd_timeout_ms == 0) {
+		if (ret)
+			dev_warn(priv->dev,
+				 "cmd-timeout-ms not found, use default : %u\n",
+				 NPCM_PECI_CMD_TIMEOUT_MS_DEFAULT);
+		else
+			dev_warn(priv->dev,
+				 "Invalid cmd-timeout-ms : %u. Use default : %u\n",
+				 priv->cmd_timeout_ms,
+				 NPCM_PECI_CMD_TIMEOUT_MS_DEFAULT);
+
+		priv->cmd_timeout_ms = NPCM_PECI_CMD_TIMEOUT_MS_DEFAULT;
+	}
+
+	if (of_device_is_compatible(priv->dev->of_node,
+				    "nuvoton,npcm750-peci")) {
+		priv->gcr_regmap = syscon_regmap_lookup_by_compatible
+			("nuvoton,npcm750-gcr");
+		if (!IS_ERR(priv->gcr_regmap)) {
+			bool volt = of_property_read_bool(priv->dev->of_node,
+							  "high-volt-range");
+			if (volt)
+				regmap_update_bits(priv->gcr_regmap,
+						   NPCM7XX_INTCR3_OFFSET,
+						   NPCM7XX_INTCR3_PECIVSEL,
+						   NPCM7XX_INTCR3_PECIVSEL);
+			else
+				regmap_update_bits(priv->gcr_regmap,
+						   NPCM7XX_INTCR3_OFFSET,
+						   NPCM7XX_INTCR3_PECIVSEL, 0);
+		}
+	}
+
+	ret = of_property_read_u32(priv->dev->of_node, "pull-down",
+				   &pull_down);
+	if (ret || pull_down > NPCM_PECI_PULL_DOWN_MAX) {
+		if (ret)
+			dev_warn(priv->dev,
+				 "pull-down not found, use default : %u\n",
+				 NPCM_PECI_PULL_DOWN_DEFAULT);
+		else
+			dev_warn(priv->dev,
+				 "Invalid pull-down : %u. Use default : %u\n",
+				 pull_down,
+				 NPCM_PECI_PULL_DOWN_DEFAULT);
+		pull_down = NPCM_PECI_PULL_DOWN_DEFAULT;
+	}
+
+	regmap_update_bits(priv->regmap, NPCM_PECI_CTL2, NPCM_PECI_CTL2_MASK,
+			   pull_down << 6);
+
+	ret = of_property_read_u32(priv->dev->of_node, "host-neg-bit-rate",
+				   &host_neg_bit_rate);
+	if (ret || host_neg_bit_rate > NPCM_PECI_HOST_NEG_BIT_RATE_MAX ||
+	    host_neg_bit_rate < NPCM_PECI_HOST_NEG_BIT_RATE_MIN) {
+		if (ret)
+			dev_warn(priv->dev,
+				 "host-neg-bit-rate not found, use default : %u\n",
+				 NPCM_PECI_HOST_NEG_BIT_RATE_DEFAULT);
+		else
+			dev_warn(priv->dev,
+				 "Invalid host-neg-bit-rate : %u. Use default : %u\n",
+				 host_neg_bit_rate,
+				 NPCM_PECI_HOST_NEG_BIT_RATE_DEFAULT);
+		host_neg_bit_rate = NPCM_PECI_HOST_NEG_BIT_RATE_DEFAULT;
+	}
+
+	regmap_update_bits(priv->regmap, NPCM_PECI_PDDR, NPCM_PECI_PDDR_MASK,
+			   host_neg_bit_rate);
+
+	priv->host_bit_rate = clk_get_rate(priv->clk) /
+		(4 * (host_neg_bit_rate + 1));
+
+	ret = regmap_read_poll_timeout(priv->regmap, NPCM_PECI_CTL_STS, cmd_sts,
+				       !(cmd_sts & NPCM_PECI_CTRL_START_BUSY),
+				       NPCM_PECI_IDLE_CHECK_INTERVAL_USEC,
+				       NPCM_PECI_IDLE_CHECK_TIMEOUT_USEC);
+	if (ret)
+		return ret; /* -ETIMEDOUT */
+
+	/* PECI interrupt enable */
+	regmap_update_bits(priv->regmap, NPCM_PECI_CTL_STS,
+			   NPCM_PECI_CTRL_DONE_INT_EN,
+			   NPCM_PECI_CTRL_DONE_INT_EN);
+
+	return 0;
+}
+
+static const struct regmap_config npcm_peci_regmap_config = {
+	.reg_bits = 8,
+	.val_bits = 8,
+	.max_register = NPCM_PECI_MAX_REG,
+	.fast_io = true,
+};
+
+static int npcm_peci_xfer(struct peci_adapter *adapter,
+			  struct peci_xfer_msg *msg)
+{
+	struct npcm_peci *priv = peci_get_adapdata(adapter);
+
+	return npcm_peci_xfer_native(priv, msg);
+}
+
+static int npcm_peci_probe(struct platform_device *pdev)
+{
+	struct peci_adapter *adapter;
+	struct npcm_peci *priv;
+	void __iomem *base;
+	int ret;
+
+	adapter = peci_alloc_adapter(&pdev->dev, sizeof(*priv));
+	if (!adapter)
+		return -ENOMEM;
+
+	priv = peci_get_adapdata(adapter);
+	priv->adapter = adapter;
+	priv->dev = &pdev->dev;
+	dev_set_drvdata(&pdev->dev, priv);
+
+	base = devm_platform_ioremap_resource(pdev, 0);
+	if (IS_ERR(base)) {
+		ret = PTR_ERR(base);
+		goto err_put_adapter_dev;
+	}
+
+	priv->regmap = devm_regmap_init_mmio(&pdev->dev, base,
+					     &npcm_peci_regmap_config);
+	if (IS_ERR(priv->regmap)) {
+		ret = PTR_ERR(priv->regmap);
+		goto err_put_adapter_dev;
+	}
+
+	priv->irq = platform_get_irq(pdev, 0);
+	if (!priv->irq) {
+		ret = -ENODEV;
+		goto err_put_adapter_dev;
+	}
+
+	ret = devm_request_irq(&pdev->dev, priv->irq, npcm_peci_irq_handler,
+			       0, "peci-npcm-irq", priv);
+	if (ret)
+		goto err_put_adapter_dev;
+
+	init_completion(&priv->xfer_complete);
+	spin_lock_init(&priv->lock);
+
+	priv->adapter->owner = THIS_MODULE;
+	priv->adapter->dev.of_node = of_node_get(dev_of_node(priv->dev));
+	strlcpy(priv->adapter->name, pdev->name, sizeof(priv->adapter->name));
+	priv->adapter->xfer = npcm_peci_xfer;
+
+	ret = npcm_peci_init_ctrl(priv);
+	if (ret)
+		goto err_put_adapter_dev;
+
+	ret = peci_add_adapter(priv->adapter);
+	if (ret)
+		goto err_put_adapter_dev;
+
+	dev_info(&pdev->dev, "peci bus %d registered, host negotiation bit rate %dHz",
+		 priv->adapter->nr, priv->host_bit_rate);
+
+	return 0;
+
+err_put_adapter_dev:
+	put_device(&adapter->dev);
+	return ret;
+}
+
+static int npcm_peci_remove(struct platform_device *pdev)
+{
+	struct npcm_peci *priv = dev_get_drvdata(&pdev->dev);
+
+	clk_disable_unprepare(priv->clk);
+	peci_del_adapter(priv->adapter);
+	of_node_put(priv->adapter->dev.of_node);
+
+	return 0;
+}
+
+static const struct of_device_id npcm_peci_of_table[] = {
+	{ .compatible = "nuvoton,npcm750-peci", },
+	{ }
+};
+MODULE_DEVICE_TABLE(of, npcm_peci_of_table);
+
+static struct platform_driver npcm_peci_driver = {
+	.probe  = npcm_peci_probe,
+	.remove = npcm_peci_remove,
+	.driver = {
+		.name           = KBUILD_MODNAME,
+		.of_match_table = of_match_ptr(npcm_peci_of_table),
+	},
+};
+module_platform_driver(npcm_peci_driver);
+
+MODULE_AUTHOR("Tomer Maimon <tomer.maimon@nuvoton.com>");
+MODULE_DESCRIPTION("NPCM Platform Environment Control Interface (PECI) driver");
+MODULE_LICENSE("GPL v2");
diff --git a/drivers/peci/peci-core.c b/drivers/peci/peci-core.c
new file mode 100644
index 000000000000..b3328d6d1c6f
--- /dev/null
+++ b/drivers/peci/peci-core.c
@@ -0,0 +1,2194 @@
+// SPDX-License-Identifier: GPL-2.0
+// Copyright (c) 2018-2019 Intel Corporation
+
+#include <linux/bitfield.h>
+#include <linux/crc8.h>
+#include <linux/delay.h>
+#include <linux/mm.h>
+#include <linux/module.h>
+#include <linux/of_device.h>
+#include <linux/peci.h>
+#include <linux/pm_domain.h>
+#include <linux/pm_runtime.h>
+#include <linux/sched/task_stack.h>
+#include <linux/slab.h>
+
+/* Mask for getting minor revision number from DIB */
+#define REVISION_NUM_MASK	GENMASK(15, 8)
+
+/* CRC8 table for Assured Write Frame Check */
+#define PECI_CRC8_POLYNOMIAL	0x07
+DECLARE_CRC8_TABLE(peci_crc8_table);
+
+static bool is_registered;
+
+static DEFINE_MUTEX(core_lock);
+static DEFINE_IDR(peci_adapter_idr);
+
+struct peci_adapter *peci_get_adapter(int nr)
+{
+	struct peci_adapter *adapter;
+
+	mutex_lock(&core_lock);
+	adapter = idr_find(&peci_adapter_idr, nr);
+	if (!adapter)
+		goto out_unlock;
+
+	if (try_module_get(adapter->owner))
+		get_device(&adapter->dev);
+	else
+		adapter = NULL;
+
+out_unlock:
+	mutex_unlock(&core_lock);
+
+	return adapter;
+}
+EXPORT_SYMBOL_GPL(peci_get_adapter);
+
+void peci_put_adapter(struct peci_adapter *adapter)
+{
+	if (!adapter)
+		return;
+
+	put_device(&adapter->dev);
+	module_put(adapter->owner);
+}
+EXPORT_SYMBOL_GPL(peci_put_adapter);
+
+static ssize_t name_show(struct device *dev,
+			 struct device_attribute *attr,
+			 char *buf)
+{
+	return sprintf(buf, "%s\n", dev->type == &peci_client_type ?
+		       to_peci_client(dev)->name : to_peci_adapter(dev)->name);
+}
+static DEVICE_ATTR_RO(name);
+
+static void peci_client_dev_release(struct device *dev)
+{
+	struct peci_client *client = to_peci_client(dev);
+
+	dev_dbg(dev, "%s: %s\n", __func__, client->name);
+	peci_put_adapter(client->adapter);
+	kfree(client);
+}
+
+static struct attribute *peci_device_attrs[] = {
+	&dev_attr_name.attr,
+	NULL
+};
+ATTRIBUTE_GROUPS(peci_device);
+
+struct device_type peci_client_type = {
+	.groups		= peci_device_groups,
+	.release	= peci_client_dev_release,
+};
+EXPORT_SYMBOL_GPL(peci_client_type);
+
+/**
+ * peci_verify_client - return parameter as peci_client, or NULL
+ * @dev: device, probably from some driver model iterator
+ *
+ * Return: pointer to peci_client on success, else NULL.
+ */
+struct peci_client *peci_verify_client(struct device *dev)
+{
+	return (dev->type == &peci_client_type)
+			? to_peci_client(dev)
+			: NULL;
+}
+EXPORT_SYMBOL_GPL(peci_verify_client);
+
+/**
+ * peci_get_xfer_msg() - get a DMA safe peci_xfer_msg for the given tx and rx
+ *			 length
+ * @tx_len: the length of tx_buf. May be 0 if tx_buf isn't needed.
+ * @rx_len: the length of rx_buf. May be 0 if rx_buf isn't needed.
+ *
+ * Return: NULL if a DMA safe buffer was not obtained.
+ *	   Or a valid pointer to be used with DMA. After use, release it by
+ *	   calling peci_put_xfer_msg().
+ *
+ * This function must only be called from process context!
+ */
+struct peci_xfer_msg *peci_get_xfer_msg(u8 tx_len, u8 rx_len)
+{
+	struct peci_xfer_msg *msg;
+	u8 *tx_buf, *rx_buf;
+
+	if (tx_len) {
+		tx_buf = kzalloc(tx_len, GFP_KERNEL);
+		if (!tx_buf)
+			return NULL;
+	} else {
+		tx_buf = NULL;
+	}
+
+	if (rx_len) {
+		rx_buf = kzalloc(rx_len, GFP_KERNEL);
+		if (!rx_buf)
+			goto err_free_tx_buf;
+	} else {
+		rx_buf = NULL;
+	}
+
+	msg = kzalloc(sizeof(*msg), GFP_KERNEL);
+	if (!msg)
+		goto err_free_tx_rx_buf;
+
+	msg->tx_len = tx_len;
+	msg->tx_buf = tx_buf;
+	msg->rx_len = rx_len;
+	msg->rx_buf = rx_buf;
+
+	return msg;
+
+err_free_tx_rx_buf:
+	kfree(rx_buf);
+err_free_tx_buf:
+	kfree(tx_buf);
+
+	return NULL;
+}
+EXPORT_SYMBOL_GPL(peci_get_xfer_msg);
+
+/**
+ * peci_put_xfer_msg - release a DMA safe peci_xfer_msg
+ * @msg: the message obtained from peci_get_xfer_msg(). May be NULL.
+ */
+void peci_put_xfer_msg(struct peci_xfer_msg *msg)
+{
+	if (!msg)
+		return;
+
+	kfree(msg->rx_buf);
+	kfree(msg->tx_buf);
+	kfree(msg);
+}
+EXPORT_SYMBOL_GPL(peci_put_xfer_msg);
+
+/* Calculate an Assured Write Frame Check Sequence byte */
+static int peci_aw_fcs(struct peci_xfer_msg *msg, int len, u8 *aw_fcs)
+{
+	u8 *tmp_buf;
+
+	/* Allocate a temporary buffer to use a contiguous byte array */
+	tmp_buf = kmalloc(len, GFP_KERNEL);
+	if (!tmp_buf)
+		return -ENOMEM;
+
+	tmp_buf[0] = msg->addr;
+	tmp_buf[1] = msg->tx_len;
+	tmp_buf[2] = msg->rx_len;
+	memcpy(&tmp_buf[3], msg->tx_buf, len - 3);
+
+	*aw_fcs = crc8(peci_crc8_table, tmp_buf, (size_t)len, 0);
+
+	kfree(tmp_buf);
+
+	return 0;
+}
+
+static int __peci_xfer(struct peci_adapter *adapter, struct peci_xfer_msg *msg,
+		       bool do_retry, bool has_aw_fcs)
+{
+	uint interval_us = PECI_DEV_RETRY_INTERVAL_MIN_USEC;
+	char task_name[TASK_COMM_LEN];
+	ulong timeout = jiffies;
+	u8 aw_fcs;
+	int ret;
+
+	/*
+	 * In case if adapter uses DMA, check at here whether tx and rx buffers
+	 * are DMA capable or not.
+	 */
+	if (IS_ENABLED(CONFIG_HAS_DMA) && adapter->use_dma) {
+		if (is_vmalloc_addr(msg->tx_buf) ||
+		    is_vmalloc_addr(msg->rx_buf)) {
+			WARN_ONCE(1, "xfer msg is not dma capable\n");
+			return -EAGAIN;
+		} else if (object_is_on_stack(msg->tx_buf) ||
+			   object_is_on_stack(msg->rx_buf)) {
+			WARN_ONCE(1, "xfer msg is on stack\n");
+			return -EAGAIN;
+		}
+	}
+
+	get_task_comm(task_name, current);
+	dev_dbg(&adapter->dev, "%s is called by %s(%d) through %s\n",
+		__func__, task_name, current->pid, adapter->name);
+
+	/*
+	 * For some commands, the PECI originator may need to retry a command if
+	 * the processor PECI client responds with a 0x8x completion code. In
+	 * each instance, the processor PECI client may have started the
+	 * operation but not completed it yet. When the 'retry' bit is set, the
+	 * PECI client will ignore a new request if it exactly matches a
+	 * previous valid request. For better performance and for reducing
+	 * retry traffic, the interval time will be increased exponentially.
+	 */
+
+	if (do_retry)
+		timeout += PECI_DEV_RETRY_TIMEOUT;
+
+	for (;;) {
+		ret = adapter->xfer(adapter, msg);
+
+		if (!do_retry || ret || !msg->rx_buf)
+			break;
+
+		/* Retry is needed when completion code is 0x8x */
+		if ((msg->rx_buf[0] & PECI_DEV_CC_RETRY_CHECK_MASK) !=
+		    PECI_DEV_CC_NEED_RETRY)
+			break;
+
+		/* Set the retry bit to indicate a retry attempt */
+		msg->tx_buf[1] |= PECI_DEV_RETRY_BIT;
+
+		/* Recalculate the AW FCS if it has one */
+		if (has_aw_fcs) {
+			ret = peci_aw_fcs(msg, 2 + msg->tx_len, &aw_fcs);
+			if (ret)
+				break;
+
+			msg->tx_buf[msg->tx_len - 1] = 0x80 ^ aw_fcs;
+		}
+
+		/* Retry it for 'timeout' before returning an error. */
+		if (time_after(jiffies, timeout)) {
+			dev_dbg(&adapter->dev, "Timeout retrying xfer!\n");
+			ret = -ETIMEDOUT;
+			break;
+		}
+
+		usleep_range(interval_us, interval_us * 2);
+
+		interval_us *= 2;
+		if (interval_us > PECI_DEV_RETRY_INTERVAL_MAX_USEC)
+			interval_us = PECI_DEV_RETRY_INTERVAL_MAX_USEC;
+	}
+
+	if (ret)
+		dev_dbg(&adapter->dev, "xfer error: %d\n", ret);
+
+	return ret;
+}
+
+static int peci_xfer(struct peci_adapter *adapter, struct peci_xfer_msg *msg)
+{
+	return __peci_xfer(adapter, msg, false, false);
+}
+
+static int peci_xfer_with_retries(struct peci_adapter *adapter,
+				  struct peci_xfer_msg *msg,
+				  bool has_aw_fcs)
+{
+	return __peci_xfer(adapter, msg, true, has_aw_fcs);
+}
+
+static int peci_scan_cmd_mask(struct peci_adapter *adapter)
+{
+	struct peci_xfer_msg *msg;
+	u8 revision;
+	int ret;
+	u64 dib;
+
+	/* Update command mask just once */
+	if (adapter->cmd_mask & BIT(PECI_CMD_XFER))
+		return 0;
+
+	msg = peci_get_xfer_msg(PECI_GET_DIB_WR_LEN, PECI_GET_DIB_RD_LEN);
+	if (!msg)
+		return -ENOMEM;
+
+	msg->addr      = PECI_BASE_ADDR;
+	msg->tx_buf[0] = PECI_GET_DIB_CMD;
+
+	ret = peci_xfer(adapter, msg);
+	if (ret) {
+		ret = -EAGAIN;
+		goto out;
+	}
+	if (msg->rx_buf[0] == PECI_DEV_CC_INVALID_REQ) {
+		/*
+		 * if GetDIB() is not supported, use a revision property of
+		 * hardware adapter
+		 */
+		revision = adapter->peci_revision;
+	} else {
+		dib = le64_to_cpup((__le64 *)msg->rx_buf);
+
+		/* Check special case for Get DIB command */
+		if (dib == 0) {
+			dev_dbg(&adapter->dev, "DIB read as 0\n");
+			ret = -EIO;
+			goto out;
+		}
+
+		/*
+		 * Setting up the supporting commands based on revision number.
+		 * See PECI Spec Table 3-1.
+		 */
+		revision = FIELD_GET(REVISION_NUM_MASK, dib);
+	}
+
+	if (revision >= 0x40) { /* Rev. 4.0 */
+		adapter->cmd_mask |= BIT(PECI_CMD_RD_IA_MSREX);
+		adapter->cmd_mask |= BIT(PECI_CMD_RD_END_PT_CFG);
+		adapter->cmd_mask |= BIT(PECI_CMD_WR_END_PT_CFG);
+		adapter->cmd_mask |= BIT(PECI_CMD_CRASHDUMP_DISC);
+		adapter->cmd_mask |= BIT(PECI_CMD_CRASHDUMP_GET_FRAME);
+	}
+	if (revision >= 0x36) /* Rev. 3.6 */
+		adapter->cmd_mask |= BIT(PECI_CMD_WR_IA_MSR);
+	if (revision >= 0x35) /* Rev. 3.5 */
+		adapter->cmd_mask |= BIT(PECI_CMD_WR_PCI_CFG);
+	if (revision >= 0x34) /* Rev. 3.4 */
+		adapter->cmd_mask |= BIT(PECI_CMD_RD_PCI_CFG);
+	if (revision >= 0x33) { /* Rev. 3.3 */
+		adapter->cmd_mask |= BIT(PECI_CMD_RD_PCI_CFG_LOCAL);
+		adapter->cmd_mask |= BIT(PECI_CMD_WR_PCI_CFG_LOCAL);
+	}
+	if (revision >= 0x32) /* Rev. 3.2 */
+		adapter->cmd_mask |= BIT(PECI_CMD_RD_IA_MSR);
+	if (revision >= 0x31) { /* Rev. 3.1 */
+		adapter->cmd_mask |= BIT(PECI_CMD_RD_PKG_CFG);
+		adapter->cmd_mask |= BIT(PECI_CMD_WR_PKG_CFG);
+	}
+
+	adapter->cmd_mask |= BIT(PECI_CMD_XFER);
+	adapter->cmd_mask |= BIT(PECI_CMD_GET_TEMP);
+	adapter->cmd_mask |= BIT(PECI_CMD_GET_DIB);
+	adapter->cmd_mask |= BIT(PECI_CMD_PING);
+
+out:
+	peci_put_xfer_msg(msg);
+
+	return ret;
+}
+
+static int peci_check_cmd_support(struct peci_adapter *adapter,
+				  enum peci_cmd cmd)
+{
+	if (!(adapter->cmd_mask & BIT(PECI_CMD_PING)) &&
+	    peci_scan_cmd_mask(adapter) < 0) {
+		dev_dbg(&adapter->dev, "Failed to scan command mask\n");
+		return -EIO;
+	}
+
+	if (!(adapter->cmd_mask & BIT(cmd))) {
+		dev_dbg(&adapter->dev, "Command %d is not supported\n", cmd);
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+static int peci_cmd_xfer(struct peci_adapter *adapter, uint msg_len, void *vmsg)
+{
+	struct peci_xfer_msg *msg = vmsg;
+	u8 aw_fcs;
+	int ret;
+
+	if (!msg->tx_len) {
+		ret = peci_xfer(adapter, msg);
+	} else {
+		switch (msg->tx_buf[0]) {
+		case PECI_GET_DIB_CMD:
+		case PECI_GET_TEMP_CMD:
+			ret = peci_xfer(adapter, msg);
+			break;
+		case PECI_WRPKGCFG_CMD:
+		case PECI_WRIAMSR_CMD:
+		case PECI_WRPCICFG_CMD:
+		case PECI_WRPCICFGLOCAL_CMD:
+		case PECI_WRENDPTCFG_CMD:
+			/*
+			 * The sender may not have supplied the AW FCS byte.
+			 * Unconditionally add an Assured Write Frame Check
+			 * Sequence byte
+			 */
+			ret = peci_aw_fcs(msg, 2 + msg->tx_len, &aw_fcs);
+			if (ret)
+				break;
+
+			msg->tx_buf[msg->tx_len - 1] = 0x80 ^ aw_fcs;
+
+			ret = peci_xfer_with_retries(adapter, msg, true);
+			break;
+		default:
+			ret = peci_xfer_with_retries(adapter, msg, false);
+			break;
+		}
+	}
+
+	return ret;
+}
+
+static int peci_cmd_ping(struct peci_adapter *adapter, uint msg_len, void *vmsg)
+{
+	struct peci_ping_msg *umsg = vmsg;
+	struct peci_xfer_msg *msg;
+	int ret;
+
+	msg = peci_get_xfer_msg(0, 0);
+	if (!msg)
+		return -ENOMEM;
+
+	msg->addr   = umsg->addr;
+
+	ret = peci_xfer(adapter, msg);
+
+	peci_put_xfer_msg(msg);
+
+	return ret;
+}
+
+static int peci_cmd_get_dib(struct peci_adapter *adapter, uint msg_len, void *vmsg)
+{
+	struct peci_get_dib_msg *umsg = vmsg;
+	struct peci_xfer_msg *msg;
+	int ret;
+
+	msg = peci_get_xfer_msg(PECI_GET_DIB_WR_LEN, PECI_GET_DIB_RD_LEN);
+	if (!msg)
+		return -ENOMEM;
+
+	msg->addr      = umsg->addr;
+	msg->tx_buf[0] = PECI_GET_DIB_CMD;
+
+	ret = peci_xfer(adapter, msg);
+	if (ret)
+		goto out;
+
+	umsg->dib = le64_to_cpup((__le64 *)msg->rx_buf);
+
+out:
+	peci_put_xfer_msg(msg);
+
+	return ret;
+}
+
+static int peci_cmd_get_temp(struct peci_adapter *adapter, uint msg_len, void *vmsg)
+{
+	struct peci_get_temp_msg *umsg = vmsg;
+	struct peci_xfer_msg *msg;
+	int ret;
+
+	msg = peci_get_xfer_msg(PECI_GET_TEMP_WR_LEN, PECI_GET_TEMP_RD_LEN);
+	if (!msg)
+		return -ENOMEM;
+
+	msg->addr      = umsg->addr;
+	msg->tx_buf[0] = PECI_GET_TEMP_CMD;
+
+	ret = peci_xfer(adapter, msg);
+	if (ret)
+		goto out;
+
+	umsg->temp_raw = le16_to_cpup((__le16 *)msg->rx_buf);
+
+out:
+	peci_put_xfer_msg(msg);
+
+	return ret;
+}
+
+static int peci_cmd_rd_pkg_cfg(struct peci_adapter *adapter, uint msg_len, void *vmsg)
+{
+	struct peci_rd_pkg_cfg_msg *umsg = vmsg;
+	struct peci_xfer_msg *msg;
+	u8 domain_id;
+	int ret;
+
+	/*
+	 * vmsg may not have a domain ID defined, so we need to check the msg_len.
+	 * If the msg_len is the same size as the struct, then domain ID is provided.
+	 * Otherwise the domain ID is 0.
+	 */
+	domain_id = (msg_len == sizeof(*umsg)) ? umsg->domain_id : 0;
+
+	/* Per the PECI spec, the read length must be a byte, word, or dword */
+	if (umsg->rx_len != 1 && umsg->rx_len != 2 && umsg->rx_len != 4) {
+		dev_dbg(&adapter->dev, "Invalid read length, rx_len: %d\n",
+			umsg->rx_len);
+		return -EINVAL;
+	}
+
+	msg = peci_get_xfer_msg(PECI_RDPKGCFG_WRITE_LEN,
+				PECI_RDPKGCFG_READ_LEN_BASE + umsg->rx_len);
+	if (!msg)
+		return -ENOMEM;
+
+	msg->addr = umsg->addr;
+	msg->tx_buf[0] = PECI_RDPKGCFG_CMD;
+	msg->tx_buf[1] = domain_id << 1;         /* Domain ID [7:1] | Retry bit [0] */
+	msg->tx_buf[2] = umsg->index;            /* RdPkgConfig index */
+	msg->tx_buf[3] = (u8)umsg->param;        /* LSB - Config parameter */
+	msg->tx_buf[4] = (u8)(umsg->param >> 8); /* MSB - Config parameter */
+
+	ret = peci_xfer_with_retries(adapter, msg, false);
+	if (!ret)
+		memcpy(umsg->pkg_config, &msg->rx_buf[1], umsg->rx_len);
+
+	umsg->cc = msg->rx_buf[0];
+	peci_put_xfer_msg(msg);
+
+	return ret;
+}
+
+static int peci_cmd_wr_pkg_cfg(struct peci_adapter *adapter, uint msg_len, void *vmsg)
+{
+	struct peci_wr_pkg_cfg_msg *umsg = vmsg;
+	struct peci_xfer_msg *msg;
+	u8 aw_fcs, domain_id;
+	int ret, i;
+
+	/*
+	 * vmsg may not have a domain ID defined, so we need to check the msg_len.
+	 * If the msg_len is the same size as the struct, then domain ID is provided.
+	 * Otherwise the domain ID is 0.
+	 */
+	domain_id = (msg_len == sizeof(*umsg)) ? umsg->domain_id : 0;
+
+	/* Per the PECI spec, the write length must be a dword */
+	if (umsg->tx_len != 4) {
+		dev_dbg(&adapter->dev, "Invalid write length, tx_len: %d\n",
+			umsg->tx_len);
+		return -EINVAL;
+	}
+
+	msg = peci_get_xfer_msg(PECI_WRPKGCFG_WRITE_LEN_BASE + umsg->tx_len,
+				PECI_WRPKGCFG_READ_LEN);
+	if (!msg)
+		return -ENOMEM;
+
+	msg->addr = umsg->addr;
+	msg->tx_buf[0] = PECI_WRPKGCFG_CMD;
+	msg->tx_buf[1] = domain_id << 1;         /* Domain ID [7:1] | Retry bit [0] */
+	msg->tx_buf[2] = umsg->index;            /* RdPkgConfig index */
+	msg->tx_buf[3] = (u8)umsg->param;        /* LSB - Config parameter */
+	msg->tx_buf[4] = (u8)(umsg->param >> 8); /* MSB - Config parameter */
+	for (i = 0; i < umsg->tx_len; i++)
+		msg->tx_buf[5 + i] = (u8)(umsg->value >> (i << 3));
+
+	/* Add an Assured Write Frame Check Sequence byte */
+	ret = peci_aw_fcs(msg, 8 + umsg->tx_len, &aw_fcs);
+	if (ret)
+		goto out;
+
+	msg->tx_buf[5 + i] = 0x80 ^ aw_fcs;
+
+	ret = peci_xfer_with_retries(adapter, msg, true);
+
+out:
+	umsg->cc = msg->rx_buf[0];
+	peci_put_xfer_msg(msg);
+
+	return ret;
+}
+
+static int peci_cmd_rd_ia_msr(struct peci_adapter *adapter, uint msg_len, void *vmsg)
+{
+	struct peci_rd_ia_msr_msg *umsg = vmsg;
+	struct peci_xfer_msg *msg;
+	u8 domain_id;
+	int ret;
+
+	/*
+	 * vmsg may not have a domain ID defined, so we need to check the msg_len.
+	 * If the msg_len is the same size as the struct, then domain ID is provided.
+	 * Otherwise the domain ID is 0.
+	 */
+	domain_id = (msg_len == sizeof(*umsg)) ? umsg->domain_id : 0;
+
+	msg = peci_get_xfer_msg(PECI_RDIAMSR_WRITE_LEN, PECI_RDIAMSR_READ_LEN);
+	if (!msg)
+		return -ENOMEM;
+
+	msg->addr = umsg->addr;
+	msg->tx_buf[0] = PECI_RDIAMSR_CMD;
+	msg->tx_buf[1] = domain_id << 1; /* Domain ID [7:1] | Retry bit [0] */
+	msg->tx_buf[2] = umsg->thread_id;
+	msg->tx_buf[3] = (u8)umsg->address;
+	msg->tx_buf[4] = (u8)(umsg->address >> 8);
+
+	ret = peci_xfer_with_retries(adapter, msg, false);
+	if (!ret)
+		memcpy(&umsg->value, &msg->rx_buf[1], sizeof(uint64_t));
+
+	umsg->cc = msg->rx_buf[0];
+	peci_put_xfer_msg(msg);
+
+	return ret;
+}
+
+static int peci_cmd_rd_ia_msrex(struct peci_adapter *adapter, uint msg_len, void *vmsg)
+{
+	struct peci_rd_ia_msrex_msg *umsg = vmsg;
+	struct peci_xfer_msg *msg;
+	u8 domain_id;
+	int ret;
+
+	/*
+	 * vmsg may not have a domain ID defined, so we need to check the msg_len.
+	 * If the msg_len is the same size as the struct, then domain ID is provided.
+	 * Otherwise the domain ID is 0.
+	 */
+	domain_id = (msg_len == sizeof(*umsg)) ? umsg->domain_id : 0;
+
+	msg = peci_get_xfer_msg(PECI_RDIAMSREX_WRITE_LEN,
+				PECI_RDIAMSREX_READ_LEN);
+	if (!msg)
+		return -ENOMEM;
+
+	msg->addr = umsg->addr;
+	msg->tx_buf[0] = PECI_RDIAMSREX_CMD;
+	msg->tx_buf[1] = domain_id << 1; /* Domain ID [7:1] | Retry bit [0] */
+	msg->tx_buf[2] = (u8)umsg->thread_id;
+	msg->tx_buf[3] = (u8)(umsg->thread_id >> 8);
+	msg->tx_buf[4] = (u8)umsg->address;
+	msg->tx_buf[5] = (u8)(umsg->address >> 8);
+
+	ret = peci_xfer_with_retries(adapter, msg, false);
+	if (!ret)
+		memcpy(&umsg->value, &msg->rx_buf[1], sizeof(uint64_t));
+
+	umsg->cc = msg->rx_buf[0];
+	peci_put_xfer_msg(msg);
+
+	return ret;
+}
+
+static int peci_cmd_wr_ia_msr(struct peci_adapter *adapter, uint msg_len, void *vmsg)
+{
+	return -ENOSYS; /* Not implemented yet */
+}
+
+static int peci_cmd_rd_pci_cfg(struct peci_adapter *adapter, uint msg_len, void *vmsg)
+{
+	struct peci_rd_pci_cfg_msg *umsg = vmsg;
+	struct peci_xfer_msg *msg;
+	u8 domain_id;
+	u32 address;
+	int ret;
+
+	/*
+	 * vmsg may not have a domain ID defined, so we need to check the msg_len.
+	 * If the msg_len is the same size as the struct, then domain ID is provided.
+	 * Otherwise the domain ID is 0.
+	 */
+	domain_id = (msg_len == sizeof(*umsg)) ? umsg->domain_id : 0;
+
+	msg = peci_get_xfer_msg(PECI_RDPCICFG_WRITE_LEN,
+				PECI_RDPCICFG_READ_LEN);
+	if (!msg)
+		return -ENOMEM;
+
+	address = umsg->reg;                  /* [11:0]  - Register */
+	address |= (u32)umsg->function << 12; /* [14:12] - Function */
+	address |= (u32)umsg->device << 15;   /* [19:15] - Device   */
+	address |= (u32)umsg->bus << 20;      /* [27:20] - Bus      */
+					      /* [31:28] - Reserved */
+	msg->addr = umsg->addr;
+	msg->tx_buf[0] = PECI_RDPCICFG_CMD;
+	msg->tx_buf[1] = domain_id << 1;      /* Domain ID [7:1] | Retry bit [0] */
+	msg->tx_buf[2] = (u8)address;         /* LSB - PCI Config Address */
+	msg->tx_buf[3] = (u8)(address >> 8);  /* PCI Config Address */
+	msg->tx_buf[4] = (u8)(address >> 16); /* PCI Config Address */
+	msg->tx_buf[5] = (u8)(address >> 24); /* MSB - PCI Config Address */
+
+	ret = peci_xfer_with_retries(adapter, msg, false);
+	if (!ret)
+		memcpy(umsg->pci_config, &msg->rx_buf[1], 4);
+
+	umsg->cc = msg->rx_buf[0];
+	peci_put_xfer_msg(msg);
+
+	return ret;
+}
+
+static int peci_cmd_wr_pci_cfg(struct peci_adapter *adapter, uint msg_len, void *vmsg)
+{
+	return -ENOSYS; /* Not implemented yet */
+}
+
+static int peci_cmd_rd_pci_cfg_local(struct peci_adapter *adapter, uint msg_len, void *vmsg)
+{
+	struct peci_rd_pci_cfg_local_msg *umsg = vmsg;
+	struct peci_xfer_msg *msg;
+	u8 domain_id;
+	u32 address;
+	int ret;
+
+	/*
+	 * vmsg may not have a domain ID defined, so we need to check the msg_len.
+	 * If the msg_len is the same size as the struct, then domain ID is provided.
+	 * Otherwise the domain ID is 0.
+	 */
+	domain_id = (msg_len == sizeof(*umsg)) ? umsg->domain_id : 0;
+
+	/* Per the PECI spec, the read length must be a byte, word, or dword */
+	if (umsg->rx_len != 1 && umsg->rx_len != 2 && umsg->rx_len != 4) {
+		dev_dbg(&adapter->dev, "Invalid read length, rx_len: %d\n",
+			umsg->rx_len);
+		return -EINVAL;
+	}
+
+	msg = peci_get_xfer_msg(PECI_RDPCICFGLOCAL_WRITE_LEN,
+				PECI_RDPCICFGLOCAL_READ_LEN_BASE +
+				umsg->rx_len);
+	if (!msg)
+		return -ENOMEM;
+
+	address = umsg->reg;                  /* [11:0]  - Register */
+	address |= (u32)umsg->function << 12; /* [14:12] - Function */
+	address |= (u32)umsg->device << 15;   /* [19:15] - Device   */
+	address |= (u32)umsg->bus << 20;      /* [23:20] - Bus      */
+
+	msg->addr = umsg->addr;
+	msg->tx_buf[0] = PECI_RDPCICFGLOCAL_CMD;
+	msg->tx_buf[1] = domain_id << 1;   /* Domain ID [7:1] | Retry bit [0] */
+	msg->tx_buf[2] = (u8)address;      /* LSB - PCI Configuration Address */
+	msg->tx_buf[3] = (u8)(address >> 8);  /* PCI Configuration Address */
+	msg->tx_buf[4] = (u8)(address >> 16); /* PCI Configuration Address */
+
+	ret = peci_xfer_with_retries(adapter, msg, false);
+	if (!ret)
+		memcpy(umsg->pci_config, &msg->rx_buf[1], umsg->rx_len);
+
+	umsg->cc = msg->rx_buf[0];
+	peci_put_xfer_msg(msg);
+
+	return ret;
+}
+
+static int peci_cmd_wr_pci_cfg_local(struct peci_adapter *adapter, uint msg_len, void *vmsg)
+{
+	struct peci_wr_pci_cfg_local_msg *umsg = vmsg;
+	struct peci_xfer_msg *msg;
+	u8 aw_fcs, domain_id;
+	u32 address;
+	int ret, i;
+
+	/*
+	 * vmsg may not have a domain ID defined, so we need to check the msg_len.
+	 * If the msg_len is the same size as the struct, then domain ID is provided.
+	 * Otherwise the domain ID is 0.
+	 */
+	domain_id = (msg_len == sizeof(*umsg)) ? umsg->domain_id : 0;
+
+	/* Per the PECI spec, the write length must be a byte, word, or dword */
+	if (umsg->tx_len != 1 && umsg->tx_len != 2 && umsg->tx_len != 4) {
+		dev_dbg(&adapter->dev, "Invalid write length, tx_len: %d\n",
+			umsg->tx_len);
+		return -EINVAL;
+	}
+
+	msg = peci_get_xfer_msg(PECI_WRPCICFGLOCAL_WRITE_LEN_BASE +
+				umsg->tx_len, PECI_WRPCICFGLOCAL_READ_LEN);
+	if (!msg)
+		return -ENOMEM;
+
+	address = umsg->reg;                  /* [11:0]  - Register */
+	address |= (u32)umsg->function << 12; /* [14:12] - Function */
+	address |= (u32)umsg->device << 15;   /* [19:15] - Device   */
+	address |= (u32)umsg->bus << 20;      /* [23:20] - Bus      */
+
+	msg->addr = umsg->addr;
+	msg->tx_buf[0] = PECI_WRPCICFGLOCAL_CMD;
+	msg->tx_buf[1] = domain_id << 1;   /* Domain ID [7:1] | Retry bit [0] */
+	msg->tx_buf[2] = (u8)address;      /* LSB - PCI Configuration Address */
+	msg->tx_buf[3] = (u8)(address >> 8);  /* PCI Configuration Address */
+	msg->tx_buf[4] = (u8)(address >> 16); /* PCI Configuration Address */
+	for (i = 0; i < umsg->tx_len; i++)
+		msg->tx_buf[5 + i] = (u8)(umsg->value >> (i << 3));
+
+	/* Add an Assured Write Frame Check Sequence byte */
+	ret = peci_aw_fcs(msg, 8 + umsg->tx_len, &aw_fcs);
+	if (ret)
+		goto out;
+
+	msg->tx_buf[5 + i] = 0x80 ^ aw_fcs;
+
+	ret = peci_xfer_with_retries(adapter, msg, true);
+
+out:
+	umsg->cc = msg->rx_buf[0];
+	peci_put_xfer_msg(msg);
+
+	return ret;
+}
+
+static int peci_cmd_rd_end_pt_cfg(struct peci_adapter *adapter, uint msg_len, void *vmsg)
+{
+	struct peci_rd_end_pt_cfg_msg *umsg = vmsg;
+	struct peci_xfer_msg *msg = NULL;
+	u8 tx_size, domain_id;
+	u32 address;
+	int ret;
+
+	/*
+	 * vmsg may not have a domain ID defined, so we need to check the msg_len.
+	 * If the msg_len is the same size as the struct, then domain ID is provided.
+	 * Otherwise the domain ID is 0.
+	 */
+	domain_id = (msg_len == sizeof(*umsg)) ? umsg->domain_id : 0;
+
+	switch (umsg->msg_type) {
+	case PECI_ENDPTCFG_TYPE_LOCAL_PCI:
+	case PECI_ENDPTCFG_TYPE_PCI:
+		/*
+		 * Per the PECI spec, the read length must be a byte, word,
+		 * or dword
+		 */
+		if (umsg->rx_len != 1 && umsg->rx_len != 2 &&
+		    umsg->rx_len != 4) {
+			dev_dbg(&adapter->dev,
+				"Invalid read length, rx_len: %d\n",
+				umsg->rx_len);
+			return -EINVAL;
+		}
+
+		msg = peci_get_xfer_msg(PECI_RDENDPTCFG_PCI_WRITE_LEN,
+					PECI_RDENDPTCFG_READ_LEN_BASE +
+					umsg->rx_len);
+		if (!msg)
+			return -ENOMEM;
+
+		address = umsg->params.pci_cfg.reg; /* [11:0] - Register */
+		address |= (u32)umsg->params.pci_cfg.function
+			   << 12; /* [14:12] - Function */
+		address |= (u32)umsg->params.pci_cfg.device
+			   << 15; /* [19:15] - Device   */
+		address |= (u32)umsg->params.pci_cfg.bus
+			   << 20; /* [27:20] - Bus      */
+				  /* [31:28] - Reserved */
+		msg->addr = umsg->addr;
+		msg->tx_buf[0] = PECI_RDENDPTCFG_CMD;
+		msg->tx_buf[1] = domain_id << 1;	   /* Domain ID [7:1] | Retry bit [0] */
+		msg->tx_buf[2] = umsg->msg_type;	   /* Message Type */
+		msg->tx_buf[3] = 0x00;			   /* Endpoint ID */
+		msg->tx_buf[4] = 0x00;			   /* Reserved */
+		msg->tx_buf[5] = 0x00;			   /* Reserved */
+		msg->tx_buf[6] = PECI_ENDPTCFG_ADDR_TYPE_PCI; /* Addr Type */
+		msg->tx_buf[7] = umsg->params.pci_cfg.seg; /* PCI Segment */
+		msg->tx_buf[8] = (u8)address; /* LSB - PCI Config Address */
+		msg->tx_buf[9] = (u8)(address >> 8);   /* PCI Config Address */
+		msg->tx_buf[10] = (u8)(address >> 16); /* PCI Config Address */
+		msg->tx_buf[11] =
+			(u8)(address >> 24); /* MSB - PCI Config Address */
+		break;
+
+	case PECI_ENDPTCFG_TYPE_MMIO:
+		/*
+		 * Per the PECI spec, the read length must be a byte, word,
+		 * dword, or qword
+		 */
+		if (umsg->rx_len != 1 && umsg->rx_len != 2 &&
+		    umsg->rx_len != 4 && umsg->rx_len != 8) {
+			dev_dbg(&adapter->dev,
+				"Invalid read length, rx_len: %d\n",
+				umsg->rx_len);
+			return -EINVAL;
+		}
+		/*
+		 * Per the PECI spec, the address type must specify either DWORD
+		 * or QWORD
+		 */
+		if (umsg->params.mmio.addr_type !=
+		    PECI_ENDPTCFG_ADDR_TYPE_MMIO_D &&
+		    umsg->params.mmio.addr_type !=
+		    PECI_ENDPTCFG_ADDR_TYPE_MMIO_Q) {
+			dev_dbg(&adapter->dev,
+				"Invalid address type, addr_type: %d\n",
+				umsg->params.mmio.addr_type);
+			return -EINVAL;
+		}
+
+		if (umsg->params.mmio.addr_type ==
+			PECI_ENDPTCFG_ADDR_TYPE_MMIO_D)
+			tx_size = PECI_RDENDPTCFG_MMIO_D_WRITE_LEN;
+		else
+			tx_size = PECI_RDENDPTCFG_MMIO_Q_WRITE_LEN;
+		msg = peci_get_xfer_msg(tx_size,
+					PECI_RDENDPTCFG_READ_LEN_BASE +
+					umsg->rx_len);
+		if (!msg)
+			return -ENOMEM;
+
+		address = umsg->params.mmio.function; /* [2:0] - Function */
+		address |= (u32)umsg->params.mmio.device
+			   << 3; /* [7:3] - Device */
+
+		msg->addr = umsg->addr;
+		msg->tx_buf[0] = PECI_RDENDPTCFG_CMD;
+		msg->tx_buf[1] = domain_id << 1;	      /* Domain ID [7:1] | Retry bit [0] */
+		msg->tx_buf[2] = umsg->msg_type;	      /* Message Type */
+		msg->tx_buf[3] = 0x00;			      /* Endpoint ID */
+		msg->tx_buf[4] = 0x00;			      /* Reserved */
+		msg->tx_buf[5] = umsg->params.mmio.bar;       /* BAR # */
+		msg->tx_buf[6] = umsg->params.mmio.addr_type; /* Address Type */
+		msg->tx_buf[7] = umsg->params.mmio.seg;       /* PCI Segment */
+		msg->tx_buf[8] = (u8)address;	   /* Function/Device */
+		msg->tx_buf[9] = umsg->params.mmio.bus; /* PCI Bus */
+		msg->tx_buf[10] = (u8)umsg->params.mmio
+					 .offset; /* LSB - Register Offset */
+		msg->tx_buf[11] = (u8)(umsg->params.mmio.offset
+				       >> 8); /* Register Offset */
+		msg->tx_buf[12] = (u8)(umsg->params.mmio.offset
+				       >> 16); /* Register Offset */
+		msg->tx_buf[13] = (u8)(umsg->params.mmio.offset
+				       >> 24); /* MSB - DWORD Register Offset */
+		if (umsg->params.mmio.addr_type ==
+		    PECI_ENDPTCFG_ADDR_TYPE_MMIO_Q) {
+			msg->tx_buf[14] = (u8)(umsg->params.mmio.offset
+					       >> 32); /* Register Offset */
+			msg->tx_buf[15] = (u8)(umsg->params.mmio.offset
+					       >> 40); /* Register Offset */
+			msg->tx_buf[16] = (u8)(umsg->params.mmio.offset
+					       >> 48); /* Register Offset */
+			msg->tx_buf[17] =
+				(u8)(umsg->params.mmio.offset
+				     >> 56); /* MSB - QWORD Register Offset */
+		}
+		break;
+
+	default:
+		return -EINVAL;
+	}
+
+	ret = peci_xfer_with_retries(adapter, msg, false);
+	if (!ret)
+		memcpy(umsg->data, &msg->rx_buf[1], umsg->rx_len);
+
+	umsg->cc = msg->rx_buf[0];
+	peci_put_xfer_msg(msg);
+
+	return ret;
+}
+
+static int peci_cmd_wr_end_pt_cfg(struct peci_adapter *adapter, uint msg_len, void *vmsg)
+{
+	struct peci_wr_end_pt_cfg_msg *umsg = vmsg;
+	struct peci_xfer_msg *msg = NULL;
+	u8 tx_size, aw_fcs, domain_id;
+	int ret, i, idx;
+	u32 address;
+
+	/*
+	 * vmsg may not have a domain ID defined, so we need to check the msg_len.
+	 * If the msg_len is the same size as the struct, then domain ID is provided.
+	 * Otherwise the domain ID is 0.
+	 */
+	domain_id = (msg_len == sizeof(*umsg)) ? umsg->domain_id : 0;
+
+	switch (umsg->msg_type) {
+	case PECI_ENDPTCFG_TYPE_LOCAL_PCI:
+	case PECI_ENDPTCFG_TYPE_PCI:
+		/*
+		 * Per the PECI spec, the write length must be a byte, word,
+		 * or dword
+		 */
+		if (umsg->tx_len != 1 && umsg->tx_len != 2 &&
+		    umsg->tx_len != 4) {
+			dev_dbg(&adapter->dev,
+				"Invalid write length, tx_len: %d\n",
+				umsg->tx_len);
+			return -EINVAL;
+		}
+
+		msg = peci_get_xfer_msg(PECI_WRENDPTCFG_PCI_WRITE_LEN_BASE +
+					umsg->tx_len, PECI_WRENDPTCFG_READ_LEN);
+		if (!msg)
+			return -ENOMEM;
+
+		address = umsg->params.pci_cfg.reg; /* [11:0] - Register */
+		address |= (u32)umsg->params.pci_cfg.function
+			   << 12; /* [14:12] - Function */
+		address |= (u32)umsg->params.pci_cfg.device
+			   << 15; /* [19:15] - Device   */
+		address |= (u32)umsg->params.pci_cfg.bus
+			   << 20; /* [27:20] - Bus      */
+				  /* [31:28] - Reserved */
+		msg->addr = umsg->addr;
+		msg->tx_buf[0] = PECI_WRENDPTCFG_CMD;
+		msg->tx_buf[1] = domain_id << 1;	   /* Domain ID [7:1] | Retry bit [0] */
+		msg->tx_buf[2] = umsg->msg_type;	   /* Message Type */
+		msg->tx_buf[3] = 0x00;			   /* Endpoint ID */
+		msg->tx_buf[4] = 0x00;			   /* Reserved */
+		msg->tx_buf[5] = 0x00;			   /* Reserved */
+		msg->tx_buf[6] = PECI_ENDPTCFG_ADDR_TYPE_PCI; /* Addr Type */
+		msg->tx_buf[7] = umsg->params.pci_cfg.seg; /* PCI Segment */
+		msg->tx_buf[8] = (u8)address; /* LSB - PCI Config Address */
+		msg->tx_buf[9] = (u8)(address >> 8);   /* PCI Config Address */
+		msg->tx_buf[10] = (u8)(address >> 16); /* PCI Config Address */
+		msg->tx_buf[11] =
+			(u8)(address >> 24); /* MSB - PCI Config Address */
+		for (i = 0; i < umsg->tx_len; i++)
+			msg->tx_buf[12 + i] = (u8)(umsg->value >> (i << 3));
+
+		/* Add an Assured Write Frame Check Sequence byte */
+		ret = peci_aw_fcs(msg, 15 + umsg->tx_len, &aw_fcs);
+		if (ret)
+			goto out;
+
+		msg->tx_buf[12 + i] = 0x80 ^ aw_fcs;
+		break;
+
+	case PECI_ENDPTCFG_TYPE_MMIO:
+		/*
+		 * Per the PECI spec, the write length must be a byte, word,
+		 * dword, or qword
+		 */
+		if (umsg->tx_len != 1 && umsg->tx_len != 2 &&
+		    umsg->tx_len != 4 && umsg->tx_len != 8) {
+			dev_dbg(&adapter->dev,
+				"Invalid write length, tx_len: %d\n",
+				umsg->tx_len);
+			return -EINVAL;
+		}
+		/*
+		 * Per the PECI spec, the address type must specify either DWORD
+		 * or QWORD
+		 */
+		if (umsg->params.mmio.addr_type !=
+		    PECI_ENDPTCFG_ADDR_TYPE_MMIO_D &&
+		    umsg->params.mmio.addr_type !=
+		    PECI_ENDPTCFG_ADDR_TYPE_MMIO_Q) {
+			dev_dbg(&adapter->dev,
+				"Invalid address type, addr_type: %d\n",
+				umsg->params.mmio.addr_type);
+			return -EINVAL;
+		}
+
+		if (umsg->params.mmio.addr_type ==
+			PECI_ENDPTCFG_ADDR_TYPE_MMIO_D)
+			tx_size = PECI_WRENDPTCFG_MMIO_D_WRITE_LEN_BASE +
+				  umsg->tx_len;
+		else
+			tx_size = PECI_WRENDPTCFG_MMIO_Q_WRITE_LEN_BASE +
+				  umsg->tx_len;
+		msg = peci_get_xfer_msg(tx_size, PECI_WRENDPTCFG_READ_LEN);
+		if (!msg)
+			return -ENOMEM;
+
+		address = umsg->params.mmio.function; /* [2:0] - Function */
+		address |= (u32)umsg->params.mmio.device
+			   << 3; /* [7:3] - Device */
+
+		msg->addr = umsg->addr;
+		msg->tx_buf[0] = PECI_WRENDPTCFG_CMD;
+		msg->tx_buf[1] = domain_id << 1;	      /* Domain ID [7:1] | Retry bit [0] */
+		msg->tx_buf[2] = umsg->msg_type;	      /* Message Type */
+		msg->tx_buf[3] = 0x00;			      /* Endpoint ID */
+		msg->tx_buf[4] = 0x00;			      /* Reserved */
+		msg->tx_buf[5] = umsg->params.mmio.bar;       /* BAR # */
+		msg->tx_buf[6] = umsg->params.mmio.addr_type; /* Address Type */
+		msg->tx_buf[7] = umsg->params.mmio.seg;       /* PCI Segment */
+		msg->tx_buf[8] = (u8)address;	   /* Function/Device */
+		msg->tx_buf[9] = umsg->params.mmio.bus; /* PCI Bus */
+		msg->tx_buf[10] = (u8)umsg->params.mmio
+					 .offset; /* LSB - Register Offset */
+		msg->tx_buf[11] = (u8)(umsg->params.mmio.offset
+				       >> 8); /* Register Offset */
+		msg->tx_buf[12] = (u8)(umsg->params.mmio.offset
+				       >> 16); /* Register Offset */
+		msg->tx_buf[13] = (u8)(umsg->params.mmio.offset
+				       >> 24); /* MSB - DWORD Register Offset */
+		if (umsg->params.mmio.addr_type ==
+		    PECI_ENDPTCFG_ADDR_TYPE_MMIO_Q) {
+			msg->tx_buf[14] = (u8)(umsg->params.mmio.offset
+					       >> 32); /* Register Offset */
+			msg->tx_buf[15] = (u8)(umsg->params.mmio.offset
+					       >> 40); /* Register Offset */
+			msg->tx_buf[16] = (u8)(umsg->params.mmio.offset
+					       >> 48); /* Register Offset */
+			msg->tx_buf[17] =
+				(u8)(umsg->params.mmio.offset
+				     >> 56); /* MSB - QWORD Register Offset */
+			idx = 18;
+		} else {
+			idx = 14;
+		}
+		for (i = 0; i < umsg->tx_len; i++)
+			msg->tx_buf[idx + i] = (u8)(umsg->value >> (i << 3));
+
+		/* Add an Assured Write Frame Check Sequence byte */
+		ret = peci_aw_fcs(msg, idx + 3 + umsg->tx_len, &aw_fcs);
+		if (ret)
+			goto out;
+
+		msg->tx_buf[idx + i] = 0x80 ^ aw_fcs;
+		break;
+
+	default:
+		return -EINVAL;
+	}
+
+	ret = peci_xfer_with_retries(adapter, msg, true);
+
+out:
+	umsg->cc = msg->rx_buf[0];
+	peci_put_xfer_msg(msg);
+
+	return ret;
+}
+
+static int peci_cmd_crashdump_disc(struct peci_adapter *adapter, uint msg_len, void *vmsg)
+{
+	struct peci_crashdump_disc_msg *umsg = vmsg;
+	struct peci_xfer_msg *msg;
+	u8 domain_id;
+	int ret;
+
+	/*
+	 * vmsg may not have a domain ID defined, so we need to check the msg_len.
+	 * If the msg_len is the same size as the struct, then domain ID is provided.
+	 * Otherwise the domain ID is 0.
+	 */
+	domain_id = (msg_len == sizeof(*umsg)) ? umsg->domain_id : 0;
+
+	/* Per the EDS, the read length must be a byte, word, or qword */
+	if (umsg->rx_len != 1 && umsg->rx_len != 2 && umsg->rx_len != 8) {
+		dev_dbg(&adapter->dev, "Invalid read length, rx_len: %d\n",
+			umsg->rx_len);
+		return -EINVAL;
+	}
+
+	msg = peci_get_xfer_msg(PECI_CRASHDUMP_DISC_WRITE_LEN,
+				PECI_CRASHDUMP_DISC_READ_LEN_BASE +
+				umsg->rx_len);
+	if (!msg)
+		return -ENOMEM;
+
+	msg->addr = umsg->addr;
+	msg->tx_buf[0] = PECI_CRASHDUMP_CMD;
+	msg->tx_buf[1] = domain_id << 1; /* Domain ID [7:1] | Retry bit [0] */
+	msg->tx_buf[2] = PECI_CRASHDUMP_DISC_VERSION;
+	msg->tx_buf[3] = PECI_CRASHDUMP_DISC_OPCODE;
+	msg->tx_buf[4] = umsg->subopcode;
+	msg->tx_buf[5] = umsg->param0;
+	msg->tx_buf[6] = (u8)umsg->param1;
+	msg->tx_buf[7] = (u8)(umsg->param1 >> 8);
+	msg->tx_buf[8] = umsg->param2;
+
+	ret = peci_xfer_with_retries(adapter, msg, false);
+	if (!ret)
+		memcpy(umsg->data, &msg->rx_buf[1], umsg->rx_len);
+
+	umsg->cc = msg->rx_buf[0];
+	peci_put_xfer_msg(msg);
+
+	return ret;
+}
+
+static int peci_cmd_crashdump_get_frame(struct peci_adapter *adapter, uint msg_len,
+					void *vmsg)
+{
+	struct peci_crashdump_get_frame_msg *umsg = vmsg;
+	struct peci_xfer_msg *msg;
+	u8 domain_id;
+	int ret;
+
+	/*
+	 * vmsg may not have a domain ID defined, so we need to check the msg_len.
+	 * If the msg_len is the same size as the struct, then domain ID is provided.
+	 * Otherwise the domain ID is 0.
+	 */
+	domain_id = (msg_len == sizeof(*umsg)) ? umsg->domain_id : 0;
+
+	/* Per the EDS, the read length must be a qword or dqword */
+	if (umsg->rx_len != 8 && umsg->rx_len != 16) {
+		dev_dbg(&adapter->dev, "Invalid read length, rx_len: %d\n",
+			umsg->rx_len);
+		return -EINVAL;
+	}
+
+	msg = peci_get_xfer_msg(PECI_CRASHDUMP_GET_FRAME_WRITE_LEN,
+				PECI_CRASHDUMP_GET_FRAME_READ_LEN_BASE +
+				umsg->rx_len);
+	if (!msg)
+		return -ENOMEM;
+
+	msg->addr = umsg->addr;
+	msg->tx_buf[0] = PECI_CRASHDUMP_CMD;
+	msg->tx_buf[1] = domain_id << 1; /* Domain ID [7:1] | Retry bit [0] */
+	msg->tx_buf[2] = PECI_CRASHDUMP_GET_FRAME_VERSION;
+	msg->tx_buf[3] = PECI_CRASHDUMP_GET_FRAME_OPCODE;
+	msg->tx_buf[4] = (u8)umsg->param0;
+	msg->tx_buf[5] = (u8)(umsg->param0 >> 8);
+	msg->tx_buf[6] = (u8)umsg->param1;
+	msg->tx_buf[7] = (u8)(umsg->param1 >> 8);
+	msg->tx_buf[8] = (u8)umsg->param2;
+	msg->tx_buf[9] = (u8)(umsg->param2 >> 8);
+
+	ret = peci_xfer_with_retries(adapter, msg, false);
+	if (!ret)
+		memcpy(umsg->data, &msg->rx_buf[1], umsg->rx_len);
+
+	umsg->cc = msg->rx_buf[0];
+	peci_put_xfer_msg(msg);
+
+	return ret;
+}
+
+typedef int (*peci_cmd_fn_type)(struct peci_adapter *, uint, void *);
+
+static const peci_cmd_fn_type peci_cmd_fn[PECI_CMD_MAX] = {
+	peci_cmd_xfer,
+	peci_cmd_ping,
+	peci_cmd_get_dib,
+	peci_cmd_get_temp,
+	peci_cmd_rd_pkg_cfg,
+	peci_cmd_wr_pkg_cfg,
+	peci_cmd_rd_ia_msr,
+	peci_cmd_wr_ia_msr,
+	peci_cmd_rd_ia_msrex,
+	peci_cmd_rd_pci_cfg,
+	peci_cmd_wr_pci_cfg,
+	peci_cmd_rd_pci_cfg_local,
+	peci_cmd_wr_pci_cfg_local,
+	peci_cmd_rd_end_pt_cfg,
+	peci_cmd_wr_end_pt_cfg,
+	peci_cmd_crashdump_disc,
+	peci_cmd_crashdump_get_frame,
+};
+
+/**
+ * peci_command - transfer function of a PECI command
+ * @adapter: pointer to peci_adapter
+ * @vmsg: pointer to PECI messages
+ * Context: can sleep
+ *
+ * This performs a transfer of a PECI command using PECI messages parameter
+ * which has various formats on each command.
+ *
+ * Return: zero on success, else a negative error code.
+ */
+int peci_command(struct peci_adapter *adapter, enum peci_cmd cmd, uint msg_len, void *vmsg)
+{
+	int ret;
+
+	if (cmd >= PECI_CMD_MAX || cmd < PECI_CMD_XFER)
+		return -ENOTTY;
+
+	dev_dbg(&adapter->dev, "%s, cmd=0x%02x\n", __func__, cmd);
+
+	if (!peci_cmd_fn[cmd])
+		return -EINVAL;
+
+	mutex_lock(&adapter->bus_lock);
+
+	ret = peci_check_cmd_support(adapter, cmd);
+	if (!ret)
+		ret = peci_cmd_fn[cmd](adapter, msg_len, vmsg);
+
+	mutex_unlock(&adapter->bus_lock);
+
+	return ret;
+}
+EXPORT_SYMBOL_GPL(peci_command);
+
+static int peci_detect(struct peci_adapter *adapter, u8 addr)
+{
+	struct peci_ping_msg msg;
+
+	msg.addr = addr;
+
+	return peci_command(adapter, PECI_CMD_PING, sizeof(msg), &msg);
+}
+
+static const struct of_device_id *
+peci_of_match_device(const struct of_device_id *matches,
+		     struct peci_client *client)
+{
+#if IS_ENABLED(CONFIG_OF)
+	if (!(client && matches))
+		return NULL;
+
+	return of_match_device(matches, &client->dev);
+#else /* CONFIG_OF */
+	return NULL;
+#endif /* CONFIG_OF */
+}
+
+static const struct peci_device_id *
+peci_match_id(const struct peci_device_id *id, struct peci_client *client)
+{
+	if (!(id && client))
+		return NULL;
+
+	while (id->name[0]) {
+		if (!strncmp(client->name, id->name, PECI_NAME_SIZE))
+			return id;
+		id++;
+	}
+
+	return NULL;
+}
+
+static int peci_device_match(struct device *dev, struct device_driver *drv)
+{
+	struct peci_client *client = peci_verify_client(dev);
+	struct peci_driver *driver;
+
+	/* Attempt an OF style match */
+	if (peci_of_match_device(drv->of_match_table, client))
+		return 1;
+
+	driver = to_peci_driver(drv);
+
+	/* Finally an ID match */
+	if (peci_match_id(driver->id_table, client))
+		return 1;
+
+	return 0;
+}
+
+static int peci_device_probe(struct device *dev)
+{
+	struct peci_client *client = peci_verify_client(dev);
+	struct peci_driver *driver;
+	int status = -EINVAL;
+
+	if (!client)
+		return 0;
+
+	driver = to_peci_driver(dev->driver);
+
+	if (!driver->id_table &&
+	    !peci_of_match_device(dev->driver->of_match_table, client))
+		return -ENODEV;
+
+	dev_dbg(dev, "%s: name:%s\n", __func__, client->name);
+
+	status = dev_pm_domain_attach(&client->dev, true);
+	if (status == -EPROBE_DEFER)
+		return status;
+
+	if (driver->probe)
+		status = driver->probe(client);
+	else
+		status = -EINVAL;
+
+	if (status)
+		goto err_detach_pm_domain;
+
+	return 0;
+
+err_detach_pm_domain:
+	dev_pm_domain_detach(&client->dev, true);
+
+	return status;
+}
+
+static void peci_device_remove(struct device *dev)
+{
+	struct peci_client *client = peci_verify_client(dev);
+	struct peci_driver *driver;
+
+	if (!client || !dev->driver)
+		return;
+
+	driver = to_peci_driver(dev->driver);
+	if (driver->remove) {
+		dev_dbg(dev, "%s: name:%s\n", __func__, client->name);
+		driver->remove(client);
+	}
+
+	dev_pm_domain_detach(&client->dev, true);
+}
+
+static void peci_device_shutdown(struct device *dev)
+{
+	struct peci_client *client = peci_verify_client(dev);
+	struct peci_driver *driver;
+
+	if (!client || !dev->driver)
+		return;
+
+	dev_dbg(dev, "%s: name:%s\n", __func__, client->name);
+
+	driver = to_peci_driver(dev->driver);
+	if (driver->shutdown)
+		driver->shutdown(client);
+}
+
+struct bus_type peci_bus_type = {
+	.name		= "peci",
+	.match		= peci_device_match,
+	.probe		= peci_device_probe,
+	.remove		= peci_device_remove,
+	.shutdown	= peci_device_shutdown,
+};
+EXPORT_SYMBOL_GPL(peci_bus_type);
+
+static int peci_check_domain_validity(u8 domain_id)
+{
+	if (domain_id >= DOMAIN_OFFSET_MAX)
+		return -EINVAL;
+	return 0;
+}
+
+static int peci_check_addr_validity(u8 addr)
+{
+	if (addr < PECI_BASE_ADDR && addr > PECI_BASE_ADDR + PECI_OFFSET_MAX)
+		return -EINVAL;
+
+	return 0;
+}
+
+static int peci_check_client_busy(struct device *dev, void *client_new_p)
+{
+	struct peci_client *client = peci_verify_client(dev);
+	struct peci_client *client_new = client_new_p;
+
+	if (client && client->addr == client_new->addr &&
+	    client->domain_id == client_new->domain_id)
+		return -EBUSY;
+
+	return 0;
+}
+
+/**
+ * peci_get_cpu_id - read CPU ID from the Package Configuration Space of CPU
+ * @adapter: pointer to peci_adapter
+ * @addr: address of the PECI client CPU
+ * @cpu_id: where the CPU ID will be stored
+ * Context: can sleep
+ *
+ * Return: zero on success, else a negative error code.
+ */
+int peci_get_cpu_id(struct peci_adapter *adapter, u8 addr, u8 domain_id, u32 *cpu_id)
+{
+	struct peci_rd_pkg_cfg_msg msg;
+	int ret;
+
+	msg.addr = addr;
+	msg.domain_id = domain_id;
+	msg.index = PECI_MBX_INDEX_CPU_ID;
+	msg.param = PECI_PKG_ID_CPU_ID;
+	msg.rx_len = 4;
+
+	ret = peci_command(adapter, PECI_CMD_RD_PKG_CFG, sizeof(msg), &msg);
+	if (msg.cc != PECI_DEV_CC_SUCCESS)
+		ret = -EAGAIN;
+	if (ret)
+		return ret;
+
+	*cpu_id = le32_to_cpup((__le32 *)msg.pkg_config);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(peci_get_cpu_id);
+
+static struct peci_client *peci_new_device(struct peci_adapter *adapter,
+					   struct peci_board_info const *info)
+{
+	struct peci_client *client;
+	char name[16];
+	int ret;
+
+	/* Increase reference count for the adapter assigned */
+	if (!peci_get_adapter(adapter->nr))
+		return NULL;
+
+	client = kzalloc(sizeof(*client), GFP_KERNEL);
+	if (!client)
+		goto err_put_adapter;
+
+	client->adapter = adapter;
+	client->addr = info->addr;
+	client->domain_id = info->domain_id;
+	strlcpy(client->name, info->type, sizeof(client->name));
+
+	/* Check online status of client */
+	ret = peci_detect(adapter, client->addr);
+	if (ret)
+		goto err_free_client;
+
+	ret = device_for_each_child(&adapter->dev, client,
+				    peci_check_client_busy);
+	if (ret)
+		goto err_free_client;
+
+	if (client->domain_id)
+		snprintf(name, 16, "%d-%02x-%02x", adapter->nr, client->addr, client->domain_id);
+	else
+		snprintf(name, 16, "%d-%02x", adapter->nr, client->addr);
+
+	client->dev.parent = &client->adapter->dev;
+	client->dev.bus = &peci_bus_type;
+	client->dev.type = &peci_client_type;
+	client->dev.of_node = of_node_get(info->of_node);
+	dev_set_name(&client->dev, name);
+
+	ret = device_register(&client->dev);
+	if (ret)
+		goto err_put_of_node;
+
+	dev_dbg(&adapter->dev, "client [%s] registered with bus id %s\n",
+		client->name, dev_name(&client->dev));
+
+	return client;
+
+err_put_of_node:
+	of_node_put(info->of_node);
+err_free_client:
+	dev_err(&adapter->dev,
+		"Failed to register peci client %s, addr: %#02x, domain id: %#02x, ret: %d\n",
+		client->name, client->addr, client->domain_id, ret);
+	kfree(client);
+err_put_adapter:
+	peci_put_adapter(adapter);
+
+	return NULL;
+}
+
+static void peci_unregister_device(struct peci_client *client)
+{
+	if (!client)
+		return;
+
+	if (client->dev.of_node) {
+		of_node_clear_flag(client->dev.of_node, OF_POPULATED);
+		of_node_put(client->dev.of_node);
+	}
+
+	device_unregister(&client->dev);
+}
+
+static int peci_unregister_client(struct device *dev, void *dummy)
+{
+	struct peci_client *client = peci_verify_client(dev);
+
+	peci_unregister_device(client);
+
+	return 0;
+}
+
+static void peci_adapter_dev_release(struct device *dev)
+{
+	struct peci_adapter *adapter = to_peci_adapter(dev);
+
+	dev_dbg(dev, "%s: %s\n", __func__, adapter->name);
+	mutex_destroy(&adapter->userspace_clients_lock);
+	mutex_destroy(&adapter->bus_lock);
+	kfree(adapter);
+}
+
+static ssize_t peci_sysfs_new_device(struct device *dev,
+				     struct device_attribute *attr,
+				     const char *buf, size_t count)
+{
+	struct peci_adapter *adapter = to_peci_adapter(dev);
+	struct peci_board_info info = {};
+	struct peci_client *client;
+	u8 addr, domain_id;
+	char *blank, end;
+	int ret;
+
+	/* Parse device type */
+	blank = strchr(buf, ' ');
+	if (!blank) {
+		dev_err(dev, "%s: Missing parameters\n", "new_device");
+		return -EINVAL;
+	}
+	if (blank - buf > PECI_NAME_SIZE - 1) {
+		dev_err(dev, "%s: Invalid device type\n", "new_device");
+		return -EINVAL;
+	}
+	memcpy(info.type, buf, blank - buf);
+
+	/* Parse remaining parameters, reject extra parameters */
+	ret = sscanf(++blank, "%hhi %hhi%c", &addr, &domain_id, &end);
+	if (ret < 1) {
+		dev_err(dev, "%s: Can't parse parameters\n", "new_device");
+		return -EINVAL;
+	}
+	if (ret > 1 && end != '\n') {
+		dev_err(dev, "%s: Extra parameters\n", "new_device");
+		return -EINVAL;
+	}
+
+	ret = peci_check_addr_validity(addr);
+	if (ret)
+		return ret;
+
+	ret = peci_check_domain_validity(domain_id);
+	if (ret)
+		domain_id = 0;
+
+	info.addr = addr;
+	info.domain_id = domain_id;
+	client = peci_new_device(adapter, &info);
+	if (!client)
+		return -EINVAL;
+
+	/* Keep track of the added device */
+	mutex_lock(&adapter->userspace_clients_lock);
+	list_add_tail(&client->detected, &adapter->userspace_clients);
+	mutex_unlock(&adapter->userspace_clients_lock);
+	dev_dbg(dev, "%s: Instantiated device %s at 0x%02hx\n", "new_device",
+		info.type, info.addr);
+
+	return count;
+}
+static DEVICE_ATTR(new_device, 0200, NULL, peci_sysfs_new_device);
+
+static ssize_t peci_sysfs_delete_device(struct device *dev,
+					struct device_attribute *attr,
+					const char *buf, size_t count)
+{
+	struct peci_adapter *adapter = to_peci_adapter(dev);
+	struct peci_client *client, *next;
+	struct peci_board_info info = {};
+	u8 addr, domain_id;
+	char *blank, end;
+	int ret;
+
+	/* Parse device type */
+	blank = strchr(buf, ' ');
+	if (!blank) {
+		dev_err(dev, "%s: Missing parameters\n", "delete_device");
+		return -EINVAL;
+	}
+	if (blank - buf > PECI_NAME_SIZE - 1) {
+		dev_err(dev, "%s: Invalid device type\n", "delete_device");
+		return -EINVAL;
+	}
+	memcpy(info.type, buf, blank - buf);
+
+	/* Parse remaining parameters, reject extra parameters */
+	ret = sscanf(++blank, "%hhi %hhi%c", &addr, &domain_id, &end);
+	if (ret < 1) {
+		dev_err(dev, "%s: Can't parse parameters\n", "delete_device");
+		return -EINVAL;
+	}
+	if (ret > 1 && end != '\n') {
+		dev_err(dev, "%s: Extra parameters\n", "delete_device");
+		return -EINVAL;
+	}
+
+	ret = peci_check_addr_validity(addr);
+	if (ret)
+		return ret;
+
+	ret = peci_check_domain_validity(domain_id);
+	if (ret)
+		domain_id = 0;
+
+	info.addr = addr;
+	info.domain_id = domain_id;
+
+	/* Make sure the device was added through sysfs */
+	ret = -ENOENT;
+	mutex_lock(&adapter->userspace_clients_lock);
+	list_for_each_entry_safe(client, next, &adapter->userspace_clients,
+				 detected) {
+		if (client->addr == info.addr && client->domain_id == info.domain_id &&
+		    !strncmp(client->name, info.type, PECI_NAME_SIZE)) {
+			dev_dbg(dev, "%s: Deleting device %s at 0x%02hx\n",
+				"delete_device", client->name, client->addr);
+			list_del(&client->detected);
+			peci_unregister_device(client);
+			ret = count;
+			break;
+		}
+	}
+	mutex_unlock(&adapter->userspace_clients_lock);
+
+	if (ret < 0)
+		dev_dbg(dev, "%s: Can't find device in list\n",
+			"delete_device");
+
+	return ret;
+}
+static DEVICE_ATTR_IGNORE_LOCKDEP(delete_device, 0200, NULL,
+				  peci_sysfs_delete_device);
+
+static struct attribute *peci_adapter_attrs[] = {
+	&dev_attr_name.attr,
+	&dev_attr_new_device.attr,
+	&dev_attr_delete_device.attr,
+	NULL
+};
+ATTRIBUTE_GROUPS(peci_adapter);
+
+struct device_type peci_adapter_type = {
+	.groups		= peci_adapter_groups,
+	.release	= peci_adapter_dev_release,
+};
+EXPORT_SYMBOL_GPL(peci_adapter_type);
+
+/**
+ * peci_verify_adapter - return parameter as peci_adapter, or NULL
+ * @dev: device, probably from some driver model iterator
+ *
+ * Return: pointer to peci_adapter on success, else NULL.
+ */
+struct peci_adapter *peci_verify_adapter(struct device *dev)
+{
+	return (dev->type == &peci_adapter_type)
+			? to_peci_adapter(dev)
+			: NULL;
+}
+EXPORT_SYMBOL_GPL(peci_verify_adapter);
+
+#if IS_ENABLED(CONFIG_OF)
+static struct peci_client *peci_of_register_device(struct peci_adapter *adapter,
+						   struct device_node *node)
+{
+	struct peci_board_info info = {};
+	struct peci_client *client;
+	u32 addr, domain_id;
+	int ret;
+
+	dev_dbg(&adapter->dev, "register %pOF\n", node);
+
+	ret = of_property_read_u32(node, "reg", &addr);
+	if (ret) {
+		dev_err(&adapter->dev, "invalid reg on %pOF\n", node);
+		return ERR_PTR(ret);
+	}
+
+	ret = peci_check_addr_validity(addr);
+	if (ret)
+		return ERR_PTR(ret);
+
+	ret = of_property_read_u32(node, "domain", &domain_id);
+	if (ret || peci_check_domain_validity(domain_id)) {
+		dev_dbg(&adapter->dev, "invalid domain on %pOF, fallback to domain 0\n", node);
+		domain_id = 0;
+	}
+
+	info.addr = addr;
+	info.of_node = node;
+	info.domain_id = domain_id;
+
+	client = peci_new_device(adapter, &info);
+	if (!client)
+		client = ERR_PTR(-EINVAL);
+
+	return client;
+}
+
+static void peci_of_register_devices(struct peci_adapter *adapter)
+{
+	struct device_node *bus, *node;
+	struct peci_client *client;
+
+	/* Only register child devices if the adapter has a node pointer set */
+	if (!adapter->dev.of_node)
+		return;
+
+	bus = of_get_child_by_name(adapter->dev.of_node, "peci-bus");
+	if (!bus)
+		bus = of_node_get(adapter->dev.of_node);
+
+	for_each_available_child_of_node(bus, node) {
+		if (of_node_test_and_set_flag(node, OF_POPULATED))
+			continue;
+
+		client = peci_of_register_device(adapter, node);
+		if (IS_ERR(client)) {
+			dev_warn(&adapter->dev,
+				 "Failed to create PECI device for %pOF\n",
+				 node);
+			of_node_clear_flag(node, OF_POPULATED);
+		}
+	}
+
+	of_node_put(bus);
+}
+#else /* CONFIG_OF */
+static void peci_of_register_devices(struct peci_adapter *adapter) { }
+#endif /* CONFIG_OF */
+
+#if IS_ENABLED(CONFIG_OF_DYNAMIC)
+static int peci_of_match_node(struct device *dev, const void *data)
+{
+	return dev->of_node == data;
+}
+
+/* must call put_device() when done with returned peci_client device */
+static struct peci_client *peci_of_find_device(struct device_node *node)
+{
+	struct peci_client *client;
+	struct device *dev;
+
+	dev = bus_find_device(&peci_bus_type, NULL, node, peci_of_match_node);
+	if (!dev)
+		return NULL;
+
+	client = peci_verify_client(dev);
+	if (!client)
+		put_device(dev);
+
+	return client;
+}
+
+/* must call put_device() when done with returned peci_adapter device */
+static struct peci_adapter *peci_of_find_adapter(struct device_node *node)
+{
+	struct peci_adapter *adapter;
+	struct device *dev;
+
+	dev = bus_find_device(&peci_bus_type, NULL, node, peci_of_match_node);
+	if (!dev)
+		return NULL;
+
+	adapter = peci_verify_adapter(dev);
+	if (!adapter)
+		put_device(dev);
+
+	return adapter;
+}
+
+static int peci_of_notify(struct notifier_block *nb, ulong action, void *arg)
+{
+	struct of_reconfig_data *rd = arg;
+	struct peci_adapter *adapter;
+	struct peci_client *client;
+
+	switch (of_reconfig_get_state_change(action, rd)) {
+	case OF_RECONFIG_CHANGE_ADD:
+		adapter = peci_of_find_adapter(rd->dn->parent);
+		if (!adapter)
+			return NOTIFY_OK;	/* not for us */
+
+		if (of_node_test_and_set_flag(rd->dn, OF_POPULATED)) {
+			put_device(&adapter->dev);
+			return NOTIFY_OK;
+		}
+
+		client = peci_of_register_device(adapter, rd->dn);
+		put_device(&adapter->dev);
+
+		if (IS_ERR(client)) {
+			dev_err(&adapter->dev,
+				"failed to create client for '%pOF'\n", rd->dn);
+			of_node_clear_flag(rd->dn, OF_POPULATED);
+			return notifier_from_errno(PTR_ERR(client));
+		}
+		break;
+	case OF_RECONFIG_CHANGE_REMOVE:
+		/* already depopulated? */
+		if (!of_node_check_flag(rd->dn, OF_POPULATED))
+			return NOTIFY_OK;
+
+		/* find our device by node */
+		client = peci_of_find_device(rd->dn);
+		if (!client)
+			return NOTIFY_OK;	/* no? not meant for us */
+
+		/* unregister takes one ref away */
+		peci_unregister_device(client);
+
+		/* and put the reference of the find */
+		put_device(&client->dev);
+		break;
+	}
+
+	return NOTIFY_OK;
+}
+
+static struct notifier_block peci_of_notifier = {
+	.notifier_call = peci_of_notify,
+};
+#else /* CONFIG_OF_DYNAMIC */
+extern struct notifier_block peci_of_notifier;
+#endif /* CONFIG_OF_DYNAMIC */
+
+/**
+ * peci_alloc_adapter - allocate a PECI adapter
+ * @dev: the adapter, possibly using the platform_bus
+ * @size: how much zeroed driver-private data to allocate; the pointer to this
+ *	memory is in the driver_data field of the returned device,
+ *	accessible with peci_get_adapdata().
+ * Context: can sleep
+ *
+ * This call is used only by PECI adapter drivers, which are the only ones
+ * directly touching chip registers.  It's how they allocate a peci_adapter
+ * structure, prior to calling peci_add_adapter().
+ *
+ * This must be called from context that can sleep.
+ *
+ * The caller is responsible for initializing the adapter's methods before
+ * calling peci_add_adapter(); and (after errors while adding the device)
+ * calling put_device() to prevent a memory leak.
+ *
+ * Return: the peci_adapter structure on success, else NULL.
+ */
+struct peci_adapter *peci_alloc_adapter(struct device *dev, uint size)
+{
+	struct peci_adapter *adapter;
+
+	if (!dev)
+		return NULL;
+
+	adapter = kzalloc(size + sizeof(*adapter), GFP_KERNEL);
+	if (!adapter)
+		return NULL;
+
+	device_initialize(&adapter->dev);
+	adapter->dev.parent = dev;
+	adapter->dev.bus = &peci_bus_type;
+	adapter->dev.type = &peci_adapter_type;
+	peci_set_adapdata(adapter, &adapter[1]);
+
+	return adapter;
+}
+EXPORT_SYMBOL_GPL(peci_alloc_adapter);
+
+static int peci_register_adapter(struct peci_adapter *adapter)
+{
+	int ret = -EINVAL;
+
+	/* Can't register until after driver model init */
+	if (WARN_ON(!is_registered))
+		goto err_free_idr;
+
+	if (WARN(!adapter->name[0], "peci adapter has no name"))
+		goto err_free_idr;
+
+	if (WARN(!adapter->xfer, "peci adapter has no xfer function\n"))
+		goto err_free_idr;
+
+	mutex_init(&adapter->bus_lock);
+	mutex_init(&adapter->userspace_clients_lock);
+	INIT_LIST_HEAD(&adapter->userspace_clients);
+
+	dev_set_name(&adapter->dev, "peci-%d", adapter->nr);
+
+	ret = device_add(&adapter->dev);
+	if (ret) {
+		pr_err("adapter '%s': can't add device (%d)\n",
+		       adapter->name, ret);
+		goto err_free_idr;
+	}
+
+	dev_dbg(&adapter->dev, "adapter [%s] registered\n", adapter->name);
+
+	pm_runtime_no_callbacks(&adapter->dev);
+	pm_suspend_ignore_children(&adapter->dev, true);
+	pm_runtime_enable(&adapter->dev);
+
+	/* create pre-declared device nodes */
+	peci_of_register_devices(adapter);
+
+	return 0;
+
+err_free_idr:
+	mutex_lock(&core_lock);
+	idr_remove(&peci_adapter_idr, adapter->nr);
+	mutex_unlock(&core_lock);
+	return ret;
+}
+
+static int peci_add_numbered_adapter(struct peci_adapter *adapter)
+{
+	int id;
+
+	mutex_lock(&core_lock);
+	id = idr_alloc(&peci_adapter_idr, adapter,
+		       adapter->nr, adapter->nr + 1, GFP_KERNEL);
+	mutex_unlock(&core_lock);
+	if (WARN(id < 0, "couldn't get idr"))
+		return id == -ENOSPC ? -EBUSY : id;
+
+	return peci_register_adapter(adapter);
+}
+
+/**
+ * peci_add_adapter - add a PECI adapter
+ * @adapter: initialized adapter, originally from peci_alloc_adapter()
+ * Context: can sleep
+ *
+ * PECI adapters connect to their drivers using some non-PECI bus,
+ * such as the platform bus.  The final stage of probe() in that code
+ * includes calling peci_add_adapter() to hook up to this PECI bus glue.
+ *
+ * This must be called from context that can sleep.
+ *
+ * It returns zero on success, else a negative error code (dropping the
+ * adapter's refcount).  After a successful return, the caller is responsible
+ * for calling peci_del_adapter().
+ *
+ * Return: zero on success, else a negative error code.
+ */
+int peci_add_adapter(struct peci_adapter *adapter)
+{
+	struct device *dev = &adapter->dev;
+	int id;
+
+	id = of_alias_get_id(dev->of_node, "peci");
+	if (id >= 0) {
+		adapter->nr = id;
+		return peci_add_numbered_adapter(adapter);
+	}
+
+	mutex_lock(&core_lock);
+	id = idr_alloc(&peci_adapter_idr, adapter, 0, 0, GFP_KERNEL);
+	mutex_unlock(&core_lock);
+	if (WARN(id < 0, "couldn't get idr"))
+		return id;
+
+	adapter->nr = id;
+
+	return peci_register_adapter(adapter);
+}
+EXPORT_SYMBOL_GPL(peci_add_adapter);
+
+/**
+ * peci_del_adapter - delete a PECI adapter
+ * @adapter: the adpater being deleted
+ * Context: can sleep
+ *
+ * This call is used only by PECI adpater drivers, which are the only ones
+ * directly touching chip registers.
+ *
+ * This must be called from context that can sleep.
+ *
+ * Note that this function also drops a reference to the adapter.
+ */
+void peci_del_adapter(struct peci_adapter *adapter)
+{
+	struct peci_client *client, *next;
+	struct peci_adapter *found;
+	int nr;
+
+	/* First make sure that this adapter was ever added */
+	mutex_lock(&core_lock);
+	found = idr_find(&peci_adapter_idr, adapter->nr);
+	mutex_unlock(&core_lock);
+
+	if (found != adapter)
+		return;
+
+	/* Remove devices instantiated from sysfs */
+	mutex_lock(&adapter->userspace_clients_lock);
+	list_for_each_entry_safe(client, next, &adapter->userspace_clients,
+				 detected) {
+		dev_dbg(&adapter->dev, "Removing %s at 0x%x\n", client->name,
+			client->addr);
+		list_del(&client->detected);
+		peci_unregister_device(client);
+	}
+	mutex_unlock(&adapter->userspace_clients_lock);
+
+	/*
+	 * Detach any active clients. This can't fail, thus we do not
+	 * check the returned value.
+	 */
+	device_for_each_child(&adapter->dev, NULL, peci_unregister_client);
+
+	/* device name is gone after device_unregister */
+	dev_dbg(&adapter->dev, "adapter [%s] unregistered\n", adapter->name);
+
+	pm_runtime_disable(&adapter->dev);
+	nr = adapter->nr;
+	device_unregister(&adapter->dev);
+
+	/* free bus id */
+	mutex_lock(&core_lock);
+	idr_remove(&peci_adapter_idr, nr);
+	mutex_unlock(&core_lock);
+}
+EXPORT_SYMBOL_GPL(peci_del_adapter);
+
+int peci_for_each_dev(void *data, int (*fn)(struct device *, void *))
+{
+	int ret;
+
+	mutex_lock(&core_lock);
+	ret = bus_for_each_dev(&peci_bus_type, NULL, data, fn);
+	mutex_unlock(&core_lock);
+
+	return ret;
+}
+EXPORT_SYMBOL_GPL(peci_for_each_dev);
+
+/**
+ * peci_register_driver - register a PECI driver
+ * @owner: owner module of the driver being registered
+ * @driver: the driver being registered
+ * Context: can sleep
+ *
+ * Return: zero on success, else a negative error code.
+ */
+int peci_register_driver(struct module *owner, struct peci_driver *driver)
+{
+	int ret;
+
+	/* Can't register until after driver model init */
+	if (WARN_ON(!is_registered))
+		return -EAGAIN;
+
+	/* add the driver to the list of peci drivers in the driver core */
+	driver->driver.owner = owner;
+	driver->driver.bus = &peci_bus_type;
+
+	/*
+	 * When registration returns, the driver core
+	 * will have called probe() for all matching-but-unbound devices.
+	 */
+	ret = driver_register(&driver->driver);
+	if (ret)
+		return ret;
+
+	pr_debug("driver [%s] registered\n", driver->driver.name);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(peci_register_driver);
+
+/**
+ * peci_del_driver - unregister a PECI driver
+ * @driver: the driver being unregistered
+ * Context: can sleep
+ */
+void peci_del_driver(struct peci_driver *driver)
+{
+	driver_unregister(&driver->driver);
+	pr_debug("driver [%s] unregistered\n", driver->driver.name);
+}
+EXPORT_SYMBOL_GPL(peci_del_driver);
+
+static int __init peci_init(void)
+{
+	int ret;
+
+	ret = bus_register(&peci_bus_type);
+	if (ret < 0) {
+		pr_err("peci: Failed to register PECI bus type!\n");
+		return ret;
+	}
+
+	crc8_populate_msb(peci_crc8_table, PECI_CRC8_POLYNOMIAL);
+
+	if (IS_ENABLED(CONFIG_OF_DYNAMIC))
+		WARN_ON(of_reconfig_notifier_register(&peci_of_notifier));
+
+	is_registered = true;
+
+	return 0;
+}
+
+static void __exit peci_exit(void)
+{
+	if (IS_ENABLED(CONFIG_OF_DYNAMIC))
+		WARN_ON(of_reconfig_notifier_unregister(&peci_of_notifier));
+
+	bus_unregister(&peci_bus_type);
+}
+
+subsys_initcall(peci_init);
+module_exit(peci_exit);
+
+MODULE_AUTHOR("Jason M Biils <jason.m.bills@linux.intel.com>");
+MODULE_AUTHOR("Jae Hyun Yoo <jae.hyun.yoo@linux.intel.com>");
+MODULE_DESCRIPTION("PECI bus core module");
+MODULE_LICENSE("GPL v2");
diff --git a/drivers/peci/peci-dev.c b/drivers/peci/peci-dev.c
new file mode 100644
index 000000000000..f02666984ce7
--- /dev/null
+++ b/drivers/peci/peci-dev.c
@@ -0,0 +1,359 @@
+// SPDX-License-Identifier: GPL-2.0
+// Copyright (c) 2018-2019 Intel Corporation
+
+#include <linux/cdev.h>
+#include <linux/fs.h>
+#include <linux/list.h>
+#include <linux/module.h>
+#include <linux/notifier.h>
+#include <linux/peci.h>
+#include <linux/slab.h>
+#include <linux/uaccess.h>
+
+/*
+ * A peci_dev represents an peci_adapter ... an PECI or SMBus master, not a
+ * slave (peci_client) with which messages will be exchanged.  It's coupled
+ * with a character special file which is accessed by user mode drivers.
+ *
+ * The list of peci_dev structures is parallel to the peci_adapter lists
+ * maintained by the driver model, and is updated using bus notifications.
+ */
+struct peci_dev {
+	struct list_head	list;
+	struct peci_adapter	*adapter;
+	struct device		*dev;
+	struct cdev		cdev;
+};
+
+#define PECI_MINORS		MINORMASK
+
+static dev_t peci_devt;
+static LIST_HEAD(peci_dev_list);
+static DEFINE_SPINLOCK(peci_dev_list_lock);
+
+static struct peci_dev *peci_dev_get_by_minor(uint index)
+{
+	struct peci_dev *peci_dev;
+
+	spin_lock(&peci_dev_list_lock);
+	list_for_each_entry(peci_dev, &peci_dev_list, list) {
+		if (peci_dev->adapter->nr == index)
+			goto found;
+	}
+	peci_dev = NULL;
+found:
+	spin_unlock(&peci_dev_list_lock);
+
+	return peci_dev;
+}
+
+static struct peci_dev *peci_dev_alloc(struct peci_adapter *adapter)
+{
+	struct peci_dev *peci_dev;
+
+	if (adapter->nr >= PECI_MINORS) {
+		dev_err(&adapter->dev, "Out of device minors (%d)\n",
+			adapter->nr);
+		return ERR_PTR(-ENODEV);
+	}
+
+	peci_dev = kzalloc(sizeof(*peci_dev), GFP_KERNEL);
+	if (!peci_dev)
+		return ERR_PTR(-ENOMEM);
+	peci_dev->adapter = adapter;
+
+	spin_lock(&peci_dev_list_lock);
+	list_add_tail(&peci_dev->list, &peci_dev_list);
+	spin_unlock(&peci_dev_list_lock);
+
+	return peci_dev;
+}
+
+static void peci_dev_put(struct peci_dev *peci_dev)
+{
+	spin_lock(&peci_dev_list_lock);
+	list_del(&peci_dev->list);
+	spin_unlock(&peci_dev_list_lock);
+	kfree(peci_dev);
+}
+
+static ssize_t name_show(struct device *dev,
+			 struct device_attribute *attr, char *buf)
+{
+	struct peci_dev *peci_dev = peci_dev_get_by_minor(MINOR(dev->devt));
+
+	if (!peci_dev)
+		return -ENODEV;
+
+	return sprintf(buf, "%s\n", peci_dev->adapter->name);
+}
+static DEVICE_ATTR_RO(name);
+
+static struct attribute *peci_dev_attrs[] = {
+	&dev_attr_name.attr,
+	NULL,
+};
+ATTRIBUTE_GROUPS(peci_dev);
+
+static long peci_dev_ioctl(struct file *file, uint iocmd, ulong arg)
+{
+	struct peci_dev *peci_dev = file->private_data;
+	void __user *umsg = (void __user *)arg;
+	struct peci_xfer_msg *xmsg = NULL;
+	struct peci_xfer_msg uxmsg;
+	enum peci_cmd cmd;
+	u8 *msg = NULL;
+	uint msg_len;
+	int ret;
+
+	cmd = _IOC_NR(iocmd);
+	msg_len = _IOC_SIZE(iocmd);
+
+	switch (cmd) {
+	case PECI_CMD_XFER:
+		if (msg_len != sizeof(struct peci_xfer_msg)) {
+			ret = -EFAULT;
+			break;
+		}
+
+		if (copy_from_user(&uxmsg, umsg, msg_len)) {
+			ret = -EFAULT;
+			break;
+		}
+
+		xmsg = peci_get_xfer_msg(uxmsg.tx_len, uxmsg.rx_len);
+		if (!xmsg) {
+			ret = -ENOMEM;
+			break;
+		}
+
+		if (uxmsg.tx_len &&
+		    copy_from_user(xmsg->tx_buf, (__u8 __user *)uxmsg.tx_buf,
+				   uxmsg.tx_len)) {
+			ret = -EFAULT;
+			break;
+		}
+
+		xmsg->addr = uxmsg.addr;
+		xmsg->tx_len = uxmsg.tx_len;
+		xmsg->rx_len = uxmsg.rx_len;
+
+		/*
+		 * Send the command and copy the results back to user space on
+		 * either success or timeout to provide the completion code to
+		 * the caller.
+		 */
+		ret = peci_command(peci_dev->adapter, cmd, msg_len, xmsg);
+		if ((!ret || ret == -ETIMEDOUT) && xmsg->rx_len &&
+		    copy_to_user((__u8 __user *)uxmsg.rx_buf, xmsg->rx_buf,
+				 xmsg->rx_len))
+			ret = -EFAULT;
+
+		break;
+
+	default:
+		msg = memdup_user(umsg, msg_len);
+		if (IS_ERR(msg)) {
+			ret = PTR_ERR(msg);
+			break;
+		}
+
+		/*
+		 * Send the command and copy the results back to user space on
+		 * either success or timeout to provide the completion code to
+		 * the caller.
+		 */
+		ret = peci_command(peci_dev->adapter, cmd, msg_len, msg);
+		if ((!ret || ret == -ETIMEDOUT) &&
+		    copy_to_user(umsg, msg, msg_len))
+			ret = -EFAULT;
+
+		break;
+	}
+
+	peci_put_xfer_msg(xmsg);
+	if (!IS_ERR(msg))
+		kfree(msg);
+
+	return (long)ret;
+}
+
+static int peci_dev_open(struct inode *inode, struct file *file)
+{
+	struct peci_adapter *adapter;
+	struct peci_dev *peci_dev;
+
+	peci_dev = peci_dev_get_by_minor(iminor(inode));
+	if (!peci_dev)
+		return -ENODEV;
+
+	adapter = peci_get_adapter(peci_dev->adapter->nr);
+	if (!adapter)
+		return -ENODEV;
+
+	file->private_data = peci_dev;
+
+	return 0;
+}
+
+static int peci_dev_release(struct inode *inode, struct file *file)
+{
+	struct peci_dev *peci_dev = file->private_data;
+
+	peci_put_adapter(peci_dev->adapter);
+	file->private_data = NULL;
+
+	return 0;
+}
+
+static const struct file_operations peci_dev_fops = {
+	.owner		= THIS_MODULE,
+	.unlocked_ioctl	= peci_dev_ioctl,
+	.open		= peci_dev_open,
+	.release	= peci_dev_release,
+	.llseek		= no_llseek,
+};
+
+static struct class *peci_dev_class;
+
+static int peci_dev_attach_adapter(struct device *dev, void *dummy)
+{
+	struct peci_adapter *adapter;
+	struct peci_dev *peci_dev;
+	dev_t devt;
+	int ret;
+
+	if (dev->type != &peci_adapter_type)
+		return 0;
+
+	adapter = to_peci_adapter(dev);
+	peci_dev = peci_dev_alloc(adapter);
+	if (IS_ERR(peci_dev))
+		return PTR_ERR(peci_dev);
+
+	cdev_init(&peci_dev->cdev, &peci_dev_fops);
+	peci_dev->cdev.owner = THIS_MODULE;
+	devt = MKDEV(MAJOR(peci_devt), adapter->nr);
+
+	ret = cdev_add(&peci_dev->cdev, devt, 1);
+	if (ret)
+		goto err_put_dev;
+
+	/* register this peci device with the driver core */
+	peci_dev->dev = device_create(peci_dev_class, &adapter->dev, devt, NULL,
+				      "peci-%d", adapter->nr);
+	if (IS_ERR(peci_dev->dev)) {
+		ret = PTR_ERR(peci_dev->dev);
+		goto err_del_cdev;
+	}
+
+	dev_info(dev, "cdev of adapter [%s] registered as minor %d\n",
+		 adapter->name, adapter->nr);
+
+	return 0;
+
+err_del_cdev:
+	cdev_del(&peci_dev->cdev);
+err_put_dev:
+	peci_dev_put(peci_dev);
+
+	return ret;
+}
+
+static int peci_dev_detach_adapter(struct device *dev, void *dummy)
+{
+	struct peci_adapter *adapter;
+	struct peci_dev *peci_dev;
+	dev_t devt;
+
+	if (dev->type != &peci_adapter_type)
+		return 0;
+
+	adapter = to_peci_adapter(dev);
+	peci_dev = peci_dev_get_by_minor(adapter->nr);
+	if (!peci_dev)
+		return 0;
+
+	cdev_del(&peci_dev->cdev);
+	devt = peci_dev->dev->devt;
+	peci_dev_put(peci_dev);
+	device_destroy(peci_dev_class, devt);
+
+	dev_info(dev, "cdev of adapter [%s] unregistered\n", adapter->name);
+
+	return 0;
+}
+
+static int peci_dev_notifier_call(struct notifier_block *nb, ulong action,
+				  void *data)
+{
+	struct device *dev = data;
+
+	switch (action) {
+	case BUS_NOTIFY_ADD_DEVICE:
+		return peci_dev_attach_adapter(dev, NULL);
+	case BUS_NOTIFY_DEL_DEVICE:
+		return peci_dev_detach_adapter(dev, NULL);
+	}
+
+	return 0;
+}
+
+static struct notifier_block peci_dev_notifier = {
+	.notifier_call = peci_dev_notifier_call,
+};
+
+static int __init peci_dev_init(void)
+{
+	int ret;
+
+	pr_debug("peci /dev entries driver\n");
+
+	ret = alloc_chrdev_region(&peci_devt, 0, PECI_MINORS, "peci");
+	if (ret < 0) {
+		pr_err("peci: Failed to allocate chr dev region!\n");
+		bus_unregister(&peci_bus_type);
+		goto err;
+	}
+
+	peci_dev_class = class_create(THIS_MODULE, KBUILD_MODNAME);
+	if (IS_ERR(peci_dev_class)) {
+		ret = PTR_ERR(peci_dev_class);
+		goto err_unreg_chrdev;
+	}
+	peci_dev_class->dev_groups = peci_dev_groups;
+
+	/* Keep track of adapters which will be added or removed later */
+	ret = bus_register_notifier(&peci_bus_type, &peci_dev_notifier);
+	if (ret)
+		goto err_destroy_class;
+
+	/* Bind to already existing adapters right away */
+	peci_for_each_dev(NULL, peci_dev_attach_adapter);
+
+	return 0;
+
+err_destroy_class:
+	class_destroy(peci_dev_class);
+err_unreg_chrdev:
+	unregister_chrdev_region(peci_devt, PECI_MINORS);
+err:
+	pr_err("%s: Driver Initialization failed\n", __FILE__);
+
+	return ret;
+}
+
+static void __exit peci_dev_exit(void)
+{
+	bus_unregister_notifier(&peci_bus_type, &peci_dev_notifier);
+	peci_for_each_dev(NULL, peci_dev_detach_adapter);
+	class_destroy(peci_dev_class);
+	unregister_chrdev_region(peci_devt, PECI_MINORS);
+}
+
+module_init(peci_dev_init);
+module_exit(peci_dev_exit);
+
+MODULE_AUTHOR("Jae Hyun Yoo <jae.hyun.yoo@linux.intel.com>");
+MODULE_DESCRIPTION("PECI /dev entries driver");
+MODULE_LICENSE("GPL v2");
diff --git a/include/linux/mfd/intel-peci-client.h b/include/linux/mfd/intel-peci-client.h
new file mode 100644
index 000000000000..0a069b87f733
--- /dev/null
+++ b/include/linux/mfd/intel-peci-client.h
@@ -0,0 +1,163 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/* Copyright (c) 2018-2020 Intel Corporation */
+
+#ifndef __LINUX_MFD_INTEL_PECI_CLIENT_H
+#define __LINUX_MFD_INTEL_PECI_CLIENT_H
+
+#include <linux/peci.h>
+
+#if IS_ENABLED(CONFIG_X86)
+#include <asm/intel-family.h>
+#else
+/*
+ * Architectures other than x86 cannot include the header file so define these
+ * at here. These are needed for detecting type of client x86 CPUs behind a PECI
+ * connection.
+ */
+#define INTEL_FAM6_HASWELL_X		0x3F
+#define INTEL_FAM6_BROADWELL_X		0x4F
+#define INTEL_FAM6_SKYLAKE_X		0x55
+#define INTEL_FAM6_SKYLAKE_XD		0x56
+#define INTEL_FAM6_ICELAKE_X		0x6A
+#define INTEL_FAM6_ICELAKE_XD		0x6C
+#endif
+
+#define INTEL_FAM6             6 /* P6 (Pentium Pro and later) */
+
+#define CORE_MASK_BITS_ON_HSX  18
+#define CHAN_RANK_MAX_ON_HSX   8  /* Max number of channel ranks on Haswell */
+#define DIMM_IDX_MAX_ON_HSX    3  /* Max DIMM index per channel on Haswell */
+
+#define CORE_MASK_BITS_ON_BDX  24
+#define CHAN_RANK_MAX_ON_BDX   4  /* Max number of channel ranks on Broadwell */
+#define DIMM_IDX_MAX_ON_BDX    3  /* Max DIMM index per channel on Broadwell */
+
+#define CORE_MASK_BITS_ON_SKX  28
+#define CHAN_RANK_MAX_ON_SKX   6  /* Max number of channel ranks on Skylake */
+#define DIMM_IDX_MAX_ON_SKX    2  /* Max DIMM index per channel on Skylake */
+
+#define CORE_MASK_BITS_ON_SKXD 28
+#define CHAN_RANK_MAX_ON_SKXD  2  /* Max number of channel ranks on Skylake D */
+#define DIMM_IDX_MAX_ON_SKXD   2  /* Max DIMM index per channel on Skylake D */
+
+#define CORE_MASK_BITS_ON_ICX  64
+#define CHAN_RANK_MAX_ON_ICX   8  /* Max number of channel ranks on Icelake */
+#define DIMM_IDX_MAX_ON_ICX    2  /* Max DIMM index per channel on Icelake */
+
+#define CORE_MASK_BITS_ON_ICXD 64
+#define CHAN_RANK_MAX_ON_ICXD  4  /* Max number of channel ranks on Icelake D */
+#define DIMM_IDX_MAX_ON_ICXD   2  /* Max DIMM index per channel on Icelake D */
+
+#define CORE_MASK_BITS_MAX     CORE_MASK_BITS_ON_ICX
+#define CHAN_RANK_MAX          CHAN_RANK_MAX_ON_HSX
+#define DIMM_IDX_MAX           DIMM_IDX_MAX_ON_HSX
+#define DIMM_NUMS_MAX          (CHAN_RANK_MAX * DIMM_IDX_MAX)
+
+/**
+ * struct cpu_gen_info - CPU generation specific information
+ * @family: CPU family ID
+ * @model: CPU model
+ * @core_mask_bits: number of resolved core bits
+ * @chan_rank_max: max number of channel ranks
+ * @dimm_idx_max: max number of DIMM indices
+ *
+ * CPU generation specific information to identify maximum number of cores and
+ * DIMM slots.
+ */
+struct cpu_gen_info {
+	u16  family;
+	u8   model;
+	uint core_mask_bits;
+	uint chan_rank_max;
+	uint dimm_idx_max;
+};
+
+/**
+ * struct peci_client_manager - PECI client manager information
+ * @client; pointer to the PECI client
+ * @name: PECI client manager name
+ * @gen_info: CPU generation info of the detected CPU
+ *
+ * PECI client manager information for managing PECI sideband functions on a CPU
+ * client.
+ */
+struct peci_client_manager {
+	struct peci_client *client;
+	char name[PECI_NAME_SIZE];
+	const struct cpu_gen_info *gen_info;
+};
+
+/**
+ * peci_client_read_package_config - read from the Package Configuration Space
+ * @priv: driver private data structure
+ * @index: encoding index for the requested service
+ * @param: parameter to specify the exact data being requested
+ * @data: data buffer to store the result
+ * Context: can sleep
+ *
+ * A generic PECI command that provides read access to the
+ * "Package Configuration Space" that is maintained by the PCU, including
+ * various power and thermal management functions. Typical PCS read services
+ * supported by the processor may include access to temperature data, energy
+ * status, run time information, DIMM temperatures and so on.
+ *
+ * Return: zero on success, else a negative error code.
+ */
+static inline int
+peci_client_read_package_config(struct peci_client_manager *priv,
+				u8 index, u16 param, u8 *data)
+{
+	struct peci_rd_pkg_cfg_msg msg;
+	int ret;
+
+	msg.addr = priv->client->addr;
+	msg.index = index;
+	msg.param = param;
+	msg.rx_len = 4;
+	msg.domain_id = priv->client->domain_id;
+
+	ret = peci_command(priv->client->adapter, PECI_CMD_RD_PKG_CFG, sizeof(msg), &msg);
+	if (msg.cc != PECI_DEV_CC_SUCCESS)
+		ret = -EAGAIN;
+	if (ret)
+		return ret;
+
+	memcpy(data, msg.pkg_config, 4);
+
+	return 0;
+}
+
+/**
+ * peci_client_write_package_config - write to the Package Configuration Space
+ * @priv: driver private data structure
+ * @index: encoding index for the requested service
+ * @param: parameter to specify the exact data being requested
+ * @data: data to write
+ * Context: can sleep
+ *
+ * Return: zero on success, else a negative error code.
+ */
+static inline int
+peci_client_write_package_config(struct peci_client_manager *priv,
+				 u8 index, u16 param, u32 data)
+{
+	struct peci_wr_pkg_cfg_msg msg;
+	int ret;
+
+	msg.addr = priv->client->addr;
+	msg.index = index;
+	msg.param = param;
+	msg.tx_len = 4u;
+	msg.value = data;
+	msg.domain_id = priv->client->domain_id;
+
+	ret = peci_command(priv->client->adapter, PECI_CMD_WR_PKG_CFG, sizeof(msg), &msg);
+	if (!ret) {
+		if (msg.cc != PECI_DEV_CC_SUCCESS)
+			ret = -EAGAIN;
+	}
+
+	return ret;
+}
+
+#endif /* __LINUX_MFD_INTEL_PECI_CLIENT_H */
diff --git a/include/linux/peci.h b/include/linux/peci.h
new file mode 100644
index 000000000000..d9e77c5773be
--- /dev/null
+++ b/include/linux/peci.h
@@ -0,0 +1,153 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/* Copyright (c) 2018-2019 Intel Corporation */
+
+#ifndef __LINUX_PECI_H
+#define __LINUX_PECI_H
+
+#include <linux/device.h>
+#include <linux/mutex.h>
+#include <linux/peci-ioctl.h>
+
+#define PECI_NAME_SIZE   32
+
+struct peci_board_info {
+	char			type[PECI_NAME_SIZE];
+	u8			addr;	/* CPU client address */
+	u8			domain_id;
+	struct device_node	*of_node;
+};
+
+/**
+ * struct peci_adapter - represent a PECI adapter
+ * @owner: owner module of the PECI adpater
+ * @bus_lock: mutex for exclusion of multiple callers
+ * @dev: device interface to this driver
+ * @nr: the bus number to map
+ * @name: name of the adapter
+ * @userspace_clients_lock: mutex for exclusion of clients handling
+ * @userspace_clients: list of registered clients
+ * @xfer: low-level transfer function pointer of the adapter
+ * @cmd_mask: mask for supportable PECI commands
+ * @use_dma: flag for indicating that adapter uses DMA
+ *
+ * Each PECI adapter can communicate with one or more PECI client children.
+ * These make a small bus, sharing a single wired PECI connection.
+ */
+struct peci_adapter {
+	struct module		*owner;
+	struct mutex		bus_lock; /* mutex for bus locking */
+	struct device		dev;
+	int			nr;
+	char			name[PECI_NAME_SIZE];
+	struct mutex		userspace_clients_lock; /* clients list mutex */
+	struct list_head	userspace_clients;
+	int			(*xfer)(struct peci_adapter *adapter,
+					struct peci_xfer_msg *msg);
+	u32			cmd_mask;
+	bool			use_dma;
+	u8			peci_revision;
+};
+
+static inline struct peci_adapter *to_peci_adapter(void *d)
+{
+	return container_of(d, struct peci_adapter, dev);
+}
+
+static inline void *peci_get_adapdata(const struct peci_adapter *adapter)
+{
+	return dev_get_drvdata(&adapter->dev);
+}
+
+static inline void peci_set_adapdata(struct peci_adapter *adapter, void *data)
+{
+	dev_set_drvdata(&adapter->dev, data);
+}
+
+/**
+ * struct peci_client - represent a PECI client device
+ * @dev: driver model device node for the client
+ * @adapter: manages the bus segment hosting this PECI device
+ * @addr: address used on the PECI bus connected to the parent adapter
+ * @name: indicates the type of the device
+ * @detected: detected PECI clients list
+ *
+ * A peci_client identifies a single device (i.e. CPU) connected to a peci bus.
+ * The behaviour exposed to Linux is defined by the driver managing the device.
+ */
+struct peci_client {
+	struct device		dev;
+	struct peci_adapter	*adapter;
+	u8			addr;
+	u8			domain_id;
+	char			name[PECI_NAME_SIZE];
+	struct list_head	detected;
+};
+
+static inline struct peci_client *to_peci_client(void *d)
+{
+	return container_of(d, struct peci_client, dev);
+}
+
+struct peci_device_id {
+	char	name[PECI_NAME_SIZE];
+	ulong	driver_data;	/* Data private to the driver */
+};
+
+/**
+ * struct peci_driver - represent a PECI device driver
+ * @probe: callback for device binding
+ * @remove: callback for device unbinding
+ * @shutdown: callback for device shutdown
+ * @driver: device driver model driver
+ * @id_table: list of PECI devices supported by this driver
+ *
+ * The driver.owner field should be set to the module owner of this driver.
+ * The driver.name field should be set to the name of this driver.
+ */
+struct peci_driver {
+	int				(*probe)(struct peci_client *client);
+	int				(*remove)(struct peci_client *client);
+	void				(*shutdown)(struct peci_client *client);
+	struct device_driver		driver;
+	const struct peci_device_id	*id_table;
+};
+
+static inline struct peci_driver *to_peci_driver(void *d)
+{
+	return container_of(d, struct peci_driver, driver);
+}
+
+/**
+ * module_peci_driver - Helper macro for registering a modular PECI driver
+ * @__peci_driver: peci_driver struct
+ *
+ * Helper macro for PECI drivers which do not do anything special in module
+ * init/exit. This eliminates a lot of boilerplate. Each module may only
+ * use this macro once, and calling it replaces module_init() and module_exit()
+ */
+#define module_peci_driver(__peci_driver) \
+	module_driver(__peci_driver, peci_add_driver, peci_del_driver)
+
+/* use a define to avoid include chaining to get THIS_MODULE */
+#define peci_add_driver(driver) peci_register_driver(THIS_MODULE, driver)
+
+extern struct bus_type peci_bus_type;
+extern struct device_type peci_adapter_type;
+extern struct device_type peci_client_type;
+
+int  peci_register_driver(struct module *owner, struct peci_driver *drv);
+void peci_del_driver(struct peci_driver *driver);
+struct peci_client *peci_verify_client(struct device *dev);
+struct peci_adapter *peci_alloc_adapter(struct device *dev, uint size);
+struct peci_adapter *peci_get_adapter(int nr);
+void peci_put_adapter(struct peci_adapter *adapter);
+int  peci_add_adapter(struct peci_adapter *adapter);
+void peci_del_adapter(struct peci_adapter *adapter);
+struct peci_adapter *peci_verify_adapter(struct device *dev);
+int  peci_for_each_dev(void *data, int (*fn)(struct device *, void *));
+struct peci_xfer_msg *peci_get_xfer_msg(u8 tx_len, u8 rx_len);
+void peci_put_xfer_msg(struct peci_xfer_msg *msg);
+int  peci_command(struct peci_adapter *adpater, enum peci_cmd cmd, uint msg_len, void *vmsg);
+int  peci_get_cpu_id(struct peci_adapter *adapter, u8 addr, u8 domain_id, u32 *cpu_id);
+
+#endif /* __LINUX_PECI_H */
diff --git a/include/uapi/linux/peci-ioctl.h b/include/uapi/linux/peci-ioctl.h
new file mode 100644
index 000000000000..181559c0655d
--- /dev/null
+++ b/include/uapi/linux/peci-ioctl.h
@@ -0,0 +1,703 @@
+/* SPDX-License-Identifier: GPL-2.0 WITH Linux-syscall-note */
+/* Copyright (c) 2018-2020 Intel Corporation */
+
+#ifndef __PECI_IOCTL_H
+#define __PECI_IOCTL_H
+
+#include <linux/ioctl.h>
+#include <linux/types.h>
+
+/* The PECI client's default address of 0x30 */
+#define PECI_BASE_ADDR					0x30
+
+/* Max number of CPU clients */
+#define PECI_OFFSET_MAX					8
+
+/* Max number of domains per CPU */
+#define DOMAIN_OFFSET_MAX				16
+
+/* PECI read/write data buffer size max */
+#define PECI_BUFFER_SIZE				255
+
+/* Device Specific Completion Code (CC) Definition */
+#define PECI_DEV_CC_SUCCESS				0x40
+#define PECI_DEV_CC_NEED_RETRY				0x80
+#define PECI_DEV_CC_OUT_OF_RESOURCE			0x81
+#define PECI_DEV_CC_UNAVAIL_RESOURCE			0x82
+#define PECI_DEV_CC_INVALID_REQ				0x90
+#define PECI_DEV_CC_MCA_ERROR				0x91
+#define PECI_DEV_CC_CATASTROPHIC_MCA_ERROR		0x93
+#define PECI_DEV_CC_FATAL_MCA_DETECTED			0x94
+#define PECI_DEV_CC_PARITY_ERROR_ON_GPSB_OR_PMSB	0x98
+#define PECI_DEV_CC_PARITY_ERROR_ON_GPSB_OR_PMSB_IERR	0x9B
+#define PECI_DEV_CC_PARITY_ERROR_ON_GPSB_OR_PMSB_MCA	0x9C
+
+/* Completion Code mask to check retry needs */
+#define PECI_DEV_CC_RETRY_CHECK_MASK			0xf0
+
+#define PECI_DEV_RETRY_TIMEOUT				msecs_to_jiffies(700)
+#define PECI_DEV_RETRY_INTERVAL_MIN_USEC		100
+#define PECI_DEV_RETRY_INTERVAL_MAX_USEC		(128 * 1000)
+#define PECI_DEV_RETRY_BIT				0x01
+
+/**
+ * enum peci_cmd - PECI client commands
+ * @PECI_CMD_XFER: raw PECI transfer
+ * @PECI_CMD_PING: ping, a required message for all PECI devices
+ * @PECI_CMD_GET_DIB: get DIB (Device Info Byte)
+ * @PECI_CMD_GET_TEMP: get maximum die temperature
+ * @PECI_CMD_RD_PKG_CFG: read access to the PCS (Package Configuration Space)
+ * @PECI_CMD_WR_PKG_CFG: write access to the PCS (Package Configuration Space)
+ * @PECI_CMD_RD_IA_MSR: read access to MSRs (Model Specific Registers)
+ * @PECI_CMD_WR_IA_MSR: write access to MSRs (Model Specific Registers)
+ * @PECI_CMD_RD_IA_MSREX: read access to MSRs (Model Specific Registers)
+ * @PECI_CMD_RD_PCI_CFG: sideband read access to the PCI configuration space
+ *	maintained in downstream devices external to the processor
+ * @PECI_CMD_WR_PCI_CFG: sideband write access to the PCI configuration space
+ *	maintained in downstream devices external to the processor
+ * @PECI_CMD_RD_PCI_CFG_LOCAL: sideband read access to the PCI configuration
+ *	space that resides within the processor
+ * @PECI_CMD_WR_PCI_CFG_LOCAL: sideband write access to the PCI configuration
+ *	space that resides within the processor
+ *
+ * Available commands depend on client's PECI revision.
+ */
+enum peci_cmd {
+	PECI_CMD_XFER = 0,
+	PECI_CMD_PING,
+	PECI_CMD_GET_DIB,
+	PECI_CMD_GET_TEMP,
+	PECI_CMD_RD_PKG_CFG,
+	PECI_CMD_WR_PKG_CFG,
+	PECI_CMD_RD_IA_MSR,
+	PECI_CMD_WR_IA_MSR,
+	PECI_CMD_RD_IA_MSREX,
+	PECI_CMD_RD_PCI_CFG,
+	PECI_CMD_WR_PCI_CFG,
+	PECI_CMD_RD_PCI_CFG_LOCAL,
+	PECI_CMD_WR_PCI_CFG_LOCAL,
+	PECI_CMD_RD_END_PT_CFG,
+	PECI_CMD_WR_END_PT_CFG,
+	PECI_CMD_CRASHDUMP_DISC,
+	PECI_CMD_CRASHDUMP_GET_FRAME,
+	PECI_CMD_MAX
+};
+
+/**
+ * struct peci_xfer_msg - raw PECI transfer command
+ * @addr; address of the client
+ * @tx_len: number of data to be written in bytes
+ * @rx_len: number of data to be read in bytes
+ * @tx_buf: data to be written, or NULL
+ * @rx_buf: data to be read, or NULL
+ *
+ * raw PECI transfer
+ */
+struct peci_xfer_msg {
+	__u8	addr;
+	__u8	tx_len;
+	__u8	rx_len;
+	__u8	padding;
+	__u8	*tx_buf;
+	__u8	*rx_buf;
+} __attribute__((__packed__));
+
+/**
+ * struct peci_ping_msg - ping command
+ * @addr: address of the client
+ *
+ * Ping() is a required message for all PECI devices. This message is used to
+ * enumerate devices or determine if a device has been removed, been
+ * powered-off, etc.
+ */
+struct peci_ping_msg {
+	__u8	addr;
+	__u8	padding[3];
+} __attribute__((__packed__));
+
+/**
+ * struct peci_get_dib_msg - GetDIB command
+ * @addr: address of the client
+ * @dib: DIB data to be read
+ *
+ * The processor PECI client implementation of GetDIB() includes an 8-byte
+ * response and provides information regarding client revision number and the
+ * number of supported domains. All processor PECI clients support the GetDIB()
+ * command.
+ */
+struct peci_get_dib_msg {
+#define PECI_GET_DIB_WR_LEN	1
+#define PECI_GET_DIB_RD_LEN	8
+#define PECI_GET_DIB_CMD	0xf7
+
+	__u8	addr;
+	__u8	padding[3];
+	__u64	dib;
+} __attribute__((__packed__));
+
+/**
+ * struct peci_get_temp_msg - GetTemp command
+ * @addr: address of the client
+ * @temp_raw: raw temperature data to be read
+ *
+ * The GetTemp() command is used to retrieve the maximum die temperature from a
+ * target PECI address. The temperature is used by the external thermal
+ * management system to regulate the temperature on the die. The data is
+ * returned as a negative value representing the number of degrees centigrade
+ * below the maximum processor junction temperature.
+ */
+struct peci_get_temp_msg {
+#define PECI_GET_TEMP_WR_LEN	1
+#define PECI_GET_TEMP_RD_LEN	2
+#define PECI_GET_TEMP_CMD	0x01
+
+	__u8	addr;
+	__u8	padding;
+	__s16	temp_raw;
+} __attribute__((__packed__));
+
+/**
+ * struct peci_rd_pkg_cfg_msg - RdPkgConfig command
+ * @addr: address of the client
+ * @index: encoding index for the requested service
+ * @param: specific data being requested
+ * @rx_len: number of data to be read in bytes
+ * @cc: completion code
+ * @pkg_config: package config data to be read
+ * @domain_id: domain ID of the client
+ *
+ * The RdPkgConfig() command provides read access to the Package Configuration
+ * Space (PCS) within the processor, including various power and thermal
+ * management functions. Typical PCS read services supported by the processor
+ * may include access to temperature data, energy status, run time information,
+ * DIMM temperatures and so on.
+ */
+struct peci_rd_pkg_cfg_msg {
+#define PECI_RDPKGCFG_WRITE_LEN			5
+#define PECI_RDPKGCFG_READ_LEN_BASE		1
+#define PECI_RDPKGCFG_CMD			0xa1
+
+	__u8	addr;
+	__u8	index;
+#define PECI_MBX_INDEX_CPU_ID			0  /* Package Identifier Read */
+#define PECI_MBX_INDEX_VR_DEBUG			1  /* VR Debug */
+#define PECI_MBX_INDEX_PKG_TEMP_READ		2  /* Package Temperature Read */
+#define PECI_MBX_INDEX_ENERGY_COUNTER		3  /* Energy counter */
+#define PECI_MBX_INDEX_ENERGY_STATUS		4  /* DDR Energy Status */
+#define PECI_MBX_INDEX_WAKE_MODE_BIT		5  /* "Wake on PECI" Mode bit */
+#define PECI_MBX_INDEX_EPI			6  /* Efficient Performance Indication */
+#define PECI_MBX_INDEX_PKG_RAPL_PERF		8  /* Pkg RAPL Performance Status Read */
+#define PECI_MBX_INDEX_MODULE_TEMP		9  /* Module Temperature Read */
+#define PECI_MBX_INDEX_DTS_MARGIN		10 /* DTS thermal margin */
+#define PECI_MBX_INDEX_SKT_PWR_THRTL_DUR	11 /* Socket Power Throttled Duration */
+#define PECI_MBX_INDEX_CFG_TDP_CONTROL		12 /* TDP Config Control */
+#define PECI_MBX_INDEX_CFG_TDP_LEVELS		13 /* TDP Config Levels */
+#define PECI_MBX_INDEX_DDR_DIMM_TEMP		14 /* DDR DIMM Temperature */
+#define PECI_MBX_INDEX_CFG_ICCMAX		15 /* Configurable ICCMAX */
+#define PECI_MBX_INDEX_TEMP_TARGET		16 /* Temperature Target Read */
+#define PECI_MBX_INDEX_CURR_CFG_LIMIT		17 /* Current Config Limit */
+#define PECI_MBX_INDEX_DIMM_TEMP_READ		20 /* Package Thermal Status Read */
+#define PECI_MBX_INDEX_DRAM_IMC_TMP_READ	22 /* DRAM IMC Temperature Read */
+#define PECI_MBX_INDEX_DDR_CH_THERM_STAT	23 /* DDR Channel Thermal Status */
+#define PECI_MBX_INDEX_PKG_POWER_LIMIT1		26 /* Package Power Limit1 */
+#define PECI_MBX_INDEX_PKG_POWER_LIMIT2		27 /* Package Power Limit2 */
+#define PECI_MBX_INDEX_TDP			28 /* Thermal design power minimum */
+#define PECI_MBX_INDEX_TDP_HIGH			29 /* Thermal design power maximum */
+#define PECI_MBX_INDEX_TDP_UNITS		30 /* Units for power/energy registers */
+#define PECI_MBX_INDEX_RUN_TIME			31 /* Accumulated Run Time */
+#define PECI_MBX_INDEX_CONSTRAINED_TIME		32 /* Thermally Constrained Time Read */
+#define PECI_MBX_INDEX_TURBO_RATIO		33 /* Turbo Activation Ratio */
+#define PECI_MBX_INDEX_DDR_RAPL_PL1		34 /* DDR RAPL PL1 */
+#define PECI_MBX_INDEX_DDR_PWR_INFO_HIGH	35 /* DRAM Power Info Read (high) */
+#define PECI_MBX_INDEX_DDR_PWR_INFO_LOW		36 /* DRAM Power Info Read (low) */
+#define PECI_MBX_INDEX_DDR_RAPL_PL2		37 /* DDR RAPL PL2 */
+#define PECI_MBX_INDEX_DDR_RAPL_STATUS		38 /* DDR RAPL Performance Status */
+#define PECI_MBX_INDEX_DDR_HOT_ABSOLUTE		43 /* DDR Hottest Dimm Absolute Temp */
+#define PECI_MBX_INDEX_DDR_HOT_RELATIVE		44 /* DDR Hottest Dimm Relative Temp */
+#define PECI_MBX_INDEX_DDR_THROTTLE_TIME	45 /* DDR Throttle Time */
+#define PECI_MBX_INDEX_DDR_THERM_STATUS		46 /* DDR Thermal Status */
+#define PECI_MBX_INDEX_TIME_AVG_TEMP		47 /* Package time-averaged temperature */
+#define PECI_MBX_INDEX_TURBO_RATIO_LIMIT	49 /* Turbo Ratio Limit Read */
+#define PECI_MBX_INDEX_HWP_AUTO_OOB		53 /* HWP Autonomous Out-of-band */
+#define PECI_MBX_INDEX_DDR_WARM_BUDGET		55 /* DDR Warm Power Budget */
+#define PECI_MBX_INDEX_DDR_HOT_BUDGET		56 /* DDR Hot Power Budget */
+#define PECI_MBX_INDEX_PKG_PSYS_PWR_LIM3	57 /* Package/Psys Power Limit3 */
+#define PECI_MBX_INDEX_PKG_PSYS_PWR_LIM1	58 /* Package/Psys Power Limit1 */
+#define PECI_MBX_INDEX_PKG_PSYS_PWR_LIM2	59 /* Package/Psys Power Limit2 */
+#define PECI_MBX_INDEX_PKG_PSYS_PWR_LIM4	60 /* Package/Psys Power Limit4 */
+#define PECI_MBX_INDEX_PERF_LIMIT_REASON	65 /* Performance Limit Reasons */
+
+	__u16	param;
+/* When index is PECI_MBX_INDEX_CPU_ID */
+#define PECI_PKG_ID_CPU_ID			0x0000  /* CPUID Info */
+#define PECI_PKG_POWER_SKU_UNIT		0x0000 /* Time, Energy, Power units */
+#define PECI_PKG_ID_PLATFORM_ID			0x0001  /* Platform ID */
+#define PECI_PKG_ID_UNCORE_ID			0x0002  /* Uncore Device ID */
+#define PECI_PKG_ID_MAX_THREAD_ID		0x0003  /* Max Thread ID */
+#define PECI_PKG_ID_MICROCODE_REV		0x0004  /* CPU Microcode Update Revision */
+#define PECI_PKG_ID_MACHINE_CHECK_STATUS	0x0005  /* Machine Check Status */
+#define PECI_PKG_ID_CPU_PACKAGE		0x00ff  /* CPU package ID*/
+#define PECI_PKG_ID_DIMM			0x00ff  /* DIMM ID*/
+#define PECI_PKG_ID_PLATFORM			0x00fe  /* Entire platform ID */
+
+	__u8	rx_len;
+	__u8	cc;
+	__u8	padding[2];
+	__u8	pkg_config[4];
+	__u8	domain_id;
+	__u8	padding1[3];
+} __attribute__((__packed__));
+
+/**
+ * struct peci_wr_pkg_cfg_msg - WrPkgConfig command
+ * @addr: address of the client
+ * @index: encoding index for the requested service
+ * @param: specific data being requested
+ * @tx_len: number of data to be written in bytes
+ * @cc: completion code
+ * @value: package config data to be written
+ * @domain_id: domain ID of the client
+ *
+ * The WrPkgConfig() command provides write access to the Package Configuration
+ * Space (PCS) within the processor, including various power and thermal
+ * management functions. Typical PCS write services supported by the processor
+ * may include power limiting, thermal averaging constant programming and so
+ * on.
+ */
+struct peci_wr_pkg_cfg_msg {
+#define PECI_WRPKGCFG_WRITE_LEN_BASE	6
+#define PECI_WRPKGCFG_READ_LEN		1
+#define PECI_WRPKGCFG_CMD		0xa5
+
+	__u8	addr;
+	__u8	index;
+#define PECI_MBX_INDEX_DIMM_AMBIENT	19
+#define PECI_MBX_INDEX_DIMM_TEMP	24
+
+	__u16	param;
+	__u8	tx_len;
+	__u8	cc;
+	__u8	padding[2];
+	__u32	value;
+	__u8	domain_id;
+	__u8	padding1[3];
+} __attribute__((__packed__));
+
+/**
+ * struct peci_rd_ia_msr_msg - RdIAMSR command
+ * @addr: address of the client
+ * @thread_id: ID of the specific logical processor
+ * @address: address of MSR to read from
+ * @cc: completion code
+ * @value: data to be read
+ * @domain_id: domain ID of the client
+ *
+ * The RdIAMSR() PECI command provides read access to Model Specific Registers
+ * (MSRs) defined in the processor's Intel Architecture (IA).
+ */
+struct peci_rd_ia_msr_msg {
+#define PECI_RDIAMSR_WRITE_LEN		5
+#define PECI_RDIAMSR_READ_LEN		9
+#define PECI_RDIAMSR_CMD		0xb1
+
+	__u8	addr;
+	__u8	thread_id;
+	__u16	address;
+	__u8	cc;
+	__u8	padding[3];
+	__u64	value;
+	__u8	domain_id;
+	__u8	padding1[3];
+} __attribute__((__packed__));
+
+/**
+ * struct peci_wr_ia_msr_msg - WrIAMSR command
+ * @addr: address of the client
+ * @thread_id: ID of the specific logical processor
+ * @address: address of MSR to write to
+ * @tx_len: number of data to be written in bytes
+ * @cc: completion code
+ * @value: data to be written
+ * @domain_id: domain ID of the client
+ *
+ * The WrIAMSR() PECI command provides write access to Model Specific Registers
+ * (MSRs) defined in the processor's Intel Architecture (IA).
+ */
+struct peci_wr_ia_msr_msg {
+#define PECI_WRIAMSR_CMD		0xb5
+
+	__u8	addr;
+	__u8	thread_id;
+	__u16	address;
+	__u8	tx_len;
+	__u8	cc;
+	__u8	padding[2];
+	__u64	value;
+	__u8	domain_id;
+	__u8	padding1[3];
+} __attribute__((__packed__));
+
+/**
+ * struct peci_rd_ia_msrex_msg - RdIAMSREX command
+ * @addr: address of the client
+ * @thread_id: ID of the specific logical processor
+ * @address: address of MSR to read from
+ * @cc: completion code
+ * @value: data to be read
+ * @domain_id: domain ID of the client
+ *
+ * The RdIAMSREX() PECI command provides read access to Model Specific
+ * Registers (MSRs) defined in the processor's Intel Architecture (IA).
+ * The differences between RdIAMSREX() and RdIAMSR() are that:
+ * (1)RdIAMSR() can only read MC registers, RdIAMSREX() can read all MSRs
+ * (2)thread_id of RdIAMSR() is u8, thread_id of RdIAMSREX() is u16
+ */
+struct peci_rd_ia_msrex_msg {
+#define PECI_RDIAMSREX_WRITE_LEN	6
+#define PECI_RDIAMSREX_READ_LEN		9
+#define PECI_RDIAMSREX_CMD		0xd1
+
+	__u8	addr;
+	__u8	padding0;
+	__u16	thread_id;
+	__u16	address;
+	__u8	cc;
+	__u8	padding1;
+	__u64	value;
+	__u8	domain_id;
+	__u8	padding2[3];
+} __attribute__((__packed__));
+
+/**
+ * struct peci_rd_pci_cfg_msg - RdPCIConfig command
+ * @addr: address of the client
+ * @bus: PCI bus number
+ * @device: PCI device number
+ * @function: specific function to read from
+ * @reg: specific register to read from
+ * @cc: completion code
+ * @pci_config: config data to be read
+ * @domain_id: domain ID of the client
+ *
+ * The RdPCIConfig() command provides sideband read access to the PCI
+ * configuration space maintained in downstream devices external to the
+ * processor.
+ */
+struct peci_rd_pci_cfg_msg {
+#define PECI_RDPCICFG_WRITE_LEN		6
+#define PECI_RDPCICFG_READ_LEN		5
+#define PECI_RDPCICFG_READ_LEN_MAX	24
+#define PECI_RDPCICFG_CMD		0x61
+
+	__u8	addr;
+	__u8	bus;
+#define PECI_PCI_BUS0_CPU0		0x00
+#define PECI_PCI_BUS0_CPU1		0x80
+#define PECI_PCI_CPUBUSNO_BUS		0x00
+#define PECI_PCI_CPUBUSNO_DEV		0x08
+#define PECI_PCI_CPUBUSNO_FUNC		0x02
+#define PECI_PCI_CPUBUSNO		0xcc
+#define PECI_PCI_CPUBUSNO_1		0xd0
+#define PECI_PCI_CPUBUSNO_VALID		0xd4
+
+	__u8	device;
+	__u8	function;
+	__u16	reg;
+	__u8	cc;
+	__u8	padding[1];
+	__u8	pci_config[4];
+	__u8	domain_id;
+	__u8	padding1[3];
+} __attribute__((__packed__));
+
+/**
+ * struct peci_wr_pci_cfg_msg - WrPCIConfig command
+ * @addr: address of the client
+ * @bus: PCI bus number
+ * @device: PCI device number
+ * @function: specific function to write to
+ * @reg: specific register to write to
+ * @tx_len: number of data to be written in bytes
+ * @cc: completion code
+ * @pci_config: config data to be written
+ * @domain_id: domain ID of the client
+ *
+ * The RdPCIConfig() command provides sideband write access to the PCI
+ * configuration space maintained in downstream devices external to the
+ * processor.
+ */
+struct peci_wr_pci_cfg_msg {
+#define PECI_WRPCICFG_CMD		0x65
+
+	__u8	addr;
+	__u8	bus;
+	__u8	device;
+	__u8	function;
+	__u16	reg;
+	__u8	tx_len;
+	__u8	cc;
+	__u8	pci_config[4];
+	__u8	domain_id;
+	__u8	padding[3];
+} __attribute__((__packed__));
+
+/**
+ * struct peci_rd_pci_cfg_local_msg - RdPCIConfigLocal command
+ * @addr: address of the client
+ * @bus: PCI bus number
+ * @device: PCI device number
+ * @function: specific function to read from
+ * @reg: specific register to read from
+ * @rx_len: number of data to be read in bytes
+ * @cc: completion code
+ * @pci_config: config data to be read
+ * @domain_id: domain ID of the client
+ *
+ * The RdPCIConfigLocal() command provides sideband read access to the PCI
+ * configuration space that resides within the processor. This includes all
+ * processor IIO and uncore registers within the PCI configuration space.
+ */
+struct peci_rd_pci_cfg_local_msg {
+#define PECI_RDPCICFGLOCAL_WRITE_LEN		5
+#define PECI_RDPCICFGLOCAL_READ_LEN_BASE	1
+#define PECI_RDPCICFGLOCAL_CMD			0xe1
+
+	__u8	addr;
+	__u8	bus;
+	__u8	device;
+	__u8	function;
+	__u16	reg;
+	__u8	rx_len;
+	__u8	cc;
+	__u8	pci_config[4];
+	__u8	domain_id;
+	__u8	padding[3];
+} __attribute__((__packed__));
+
+/**
+ * struct peci_wr_pci_cfg_local_msg - WrPCIConfigLocal command
+ * @addr: address of the client
+ * @bus: PCI bus number
+ * @device: PCI device number
+ * @function: specific function to read from
+ * @reg: specific register to read from
+ * @tx_len: number of data to be written in bytes
+ * @cc: completion code
+ * @value: config data to be written
+ * @domain_id: domain ID of the client
+ *
+ * The WrPCIConfigLocal() command provides sideband write access to the PCI
+ * configuration space that resides within the processor. PECI originators can
+ * access this space even before BIOS enumeration of the system buses.
+ */
+struct peci_wr_pci_cfg_local_msg {
+#define PECI_WRPCICFGLOCAL_WRITE_LEN_BASE	6
+#define PECI_WRPCICFGLOCAL_READ_LEN		1
+#define PECI_WRPCICFGLOCAL_CMD			0xe5
+
+	__u8	addr;
+	__u8	bus;
+	__u8	device;
+	__u8	function;
+	__u16	reg;
+	__u8	tx_len;
+	__u8	cc;
+	__u32	value;
+	__u8	domain_id;
+	__u8	padding[3];
+} __attribute__((__packed__));
+
+struct peci_rd_end_pt_cfg_msg {
+#define PECI_RDENDPTCFG_PCI_WRITE_LEN		12
+#define PECI_RDENDPTCFG_MMIO_D_WRITE_LEN	14
+#define PECI_RDENDPTCFG_MMIO_Q_WRITE_LEN	18
+#define PECI_RDENDPTCFG_READ_LEN_BASE		1
+#define PECI_RDENDPTCFG_CMD			0xc1
+
+	__u8	addr;
+	__u8	msg_type;
+#define PECI_ENDPTCFG_TYPE_LOCAL_PCI		0x03
+#define PECI_ENDPTCFG_TYPE_PCI			0x04
+#define PECI_ENDPTCFG_TYPE_MMIO			0x05
+
+	union {
+		struct {
+			__u8	seg;
+			__u8	bus;
+			__u8	device;
+			__u8	function;
+			__u16	reg;
+		} pci_cfg;
+		struct {
+			__u8	seg;
+			__u8	bus;
+			__u8	device;
+			__u8	function;
+			__u8	bar;
+			__u8	addr_type;
+#define PECI_ENDPTCFG_ADDR_TYPE_PCI		0x04
+#define PECI_ENDPTCFG_ADDR_TYPE_MMIO_D		0x05
+#define PECI_ENDPTCFG_ADDR_TYPE_MMIO_Q		0x06
+
+			__u64	offset;
+		} mmio;
+	} params;
+	__u8	rx_len;
+	__u8	cc;
+	__u8	padding[2];
+	__u8	data[8];
+	__u8	domain_id;
+	__u8	padding1[3];
+} __attribute__((__packed__));
+
+struct peci_wr_end_pt_cfg_msg {
+#define PECI_WRENDPTCFG_PCI_WRITE_LEN_BASE	13
+#define PECI_WRENDPTCFG_MMIO_D_WRITE_LEN_BASE	15
+#define PECI_WRENDPTCFG_MMIO_Q_WRITE_LEN_BASE	19
+#define PECI_WRENDPTCFG_READ_LEN		1
+#define PECI_WRENDPTCFG_CMD			0xc5
+
+	__u8	addr;
+	__u8	msg_type;
+	/* See msg_type in struct peci_rd_end_pt_cfg_msg */
+
+	union {
+		struct {
+			__u8	seg;
+			__u8	bus;
+			__u8	device;
+			__u8	function;
+			__u16	reg;
+		} pci_cfg;
+		struct {
+			__u8	seg;
+			__u8	bus;
+			__u8	device;
+			__u8	function;
+			__u8	bar;
+			__u8	addr_type;
+			/* See addr_type in struct peci_rd_end_pt_cfg_msg */
+
+			__u64	offset;
+		} mmio;
+	} params;
+	__u8	tx_len;
+	__u8	cc;
+	__u8	padding[2];
+	__u64	value;
+	__u8	domain_id;
+	__u8	padding1[3];
+} __attribute__((__packed__));
+
+/* Crashdump Agent */
+#define PECI_CRASHDUMP_CORE		0x00
+#define PECI_CRASHDUMP_TOR		0x01
+
+/* Crashdump Agent Param */
+#define PECI_CRASHDUMP_PAYLOAD_SIZE	0x00
+
+/* Crashdump Agent Data Param */
+#define PECI_CRASHDUMP_AGENT_ID		0x00
+#define PECI_CRASHDUMP_AGENT_PARAM	0x01
+
+struct peci_crashdump_disc_msg {
+	__u8	addr;
+	__u8	subopcode;
+#define PECI_CRASHDUMP_ENABLED		0x00
+#define PECI_CRASHDUMP_NUM_AGENTS	0x01
+#define PECI_CRASHDUMP_AGENT_DATA	0x02
+
+	__u8	cc;
+	__u8	param0;
+	__u16	param1;
+	__u8	param2;
+	__u8	rx_len;
+	__u8	data[8];
+	__u8	domain_id;
+	__u8	padding[3];
+} __attribute__((__packed__));
+
+struct peci_crashdump_get_frame_msg {
+#define PECI_CRASHDUMP_DISC_WRITE_LEN		9
+#define PECI_CRASHDUMP_DISC_READ_LEN_BASE	1
+#define PECI_CRASHDUMP_DISC_VERSION		0
+#define PECI_CRASHDUMP_DISC_OPCODE		1
+#define PECI_CRASHDUMP_GET_FRAME_WRITE_LEN	10
+#define PECI_CRASHDUMP_GET_FRAME_READ_LEN_BASE	1
+#define PECI_CRASHDUMP_GET_FRAME_VERSION	0
+#define PECI_CRASHDUMP_GET_FRAME_OPCODE		3
+#define PECI_CRASHDUMP_CMD			0x71
+
+	__u8	addr;
+	__u8	padding0;
+	__u16	param0;
+	__u16	param1;
+	__u16	param2;
+	__u8	rx_len;
+	__u8	cc;
+	__u8	padding1[2];
+	__u8	data[16];
+	__u8	domain_id;
+	__u8	padding2[3];
+} __attribute__((__packed__));
+
+#define PECI_IOC_BASE	0xb8
+
+#define PECI_IOC_XFER \
+	_IOWR(PECI_IOC_BASE, PECI_CMD_XFER, struct peci_xfer_msg)
+
+#define PECI_IOC_PING \
+	_IOWR(PECI_IOC_BASE, PECI_CMD_PING, struct peci_ping_msg)
+
+#define PECI_IOC_GET_DIB \
+	_IOWR(PECI_IOC_BASE, PECI_CMD_GET_DIB, struct peci_get_dib_msg)
+
+#define PECI_IOC_GET_TEMP \
+	_IOWR(PECI_IOC_BASE, PECI_CMD_GET_TEMP, struct peci_get_temp_msg)
+
+#define PECI_IOC_RD_PKG_CFG \
+	_IOWR(PECI_IOC_BASE, PECI_CMD_RD_PKG_CFG, struct peci_rd_pkg_cfg_msg)
+
+#define PECI_IOC_WR_PKG_CFG \
+	_IOWR(PECI_IOC_BASE, PECI_CMD_WR_PKG_CFG, struct peci_wr_pkg_cfg_msg)
+
+#define PECI_IOC_RD_IA_MSR \
+	_IOWR(PECI_IOC_BASE, PECI_CMD_RD_IA_MSR, struct peci_rd_ia_msr_msg)
+
+#define PECI_IOC_WR_IA_MSR \
+	_IOWR(PECI_IOC_BASE, PECI_CMD_WR_IA_MSR, struct peci_wr_ia_msr_msg)
+
+#define PECI_IOC_RD_IA_MSREX \
+	_IOWR(PECI_IOC_BASE, PECI_CMD_RD_IA_MSREX, struct peci_rd_ia_msrex_msg)
+
+#define PECI_IOC_RD_PCI_CFG \
+	_IOWR(PECI_IOC_BASE, PECI_CMD_RD_PCI_CFG, struct peci_rd_pci_cfg_msg)
+
+#define PECI_IOC_WR_PCI_CFG \
+	_IOWR(PECI_IOC_BASE, PECI_CMD_WR_PCI_CFG, struct peci_wr_pci_cfg_msg)
+
+#define PECI_IOC_RD_PCI_CFG_LOCAL \
+	_IOWR(PECI_IOC_BASE, PECI_CMD_RD_PCI_CFG_LOCAL, \
+	      struct peci_rd_pci_cfg_local_msg)
+
+#define PECI_IOC_WR_PCI_CFG_LOCAL \
+	_IOWR(PECI_IOC_BASE, PECI_CMD_WR_PCI_CFG_LOCAL, \
+	      struct peci_wr_pci_cfg_local_msg)
+
+#define PECI_IOC_RD_END_PT_CFG \
+	_IOWR(PECI_IOC_BASE, PECI_CMD_RD_END_PT_CFG, \
+	      struct peci_rd_end_pt_cfg_msg)
+
+#define PECI_IOC_WR_END_PT_CFG \
+	_IOWR(PECI_IOC_BASE, PECI_CMD_WR_END_PT_CFG, \
+	      struct peci_wr_end_pt_cfg_msg)
+
+#define PECI_IOC_CRASHDUMP_DISC \
+	_IOWR(PECI_IOC_BASE, PECI_CMD_CRASHDUMP_DISC, \
+	      struct peci_crashdump_disc_msg)
+
+#define PECI_IOC_CRASHDUMP_GET_FRAME \
+	_IOWR(PECI_IOC_BASE, PECI_CMD_CRASHDUMP_GET_FRAME, \
+	      struct peci_crashdump_get_frame_msg)
+
+#endif /* __PECI_IOCTL_H */
-- 
2.17.1

